[
  {
    "objectID": "SEMs_with_lavaan/Jose_2013/Jose_2013.html",
    "href": "SEMs_with_lavaan/Jose_2013/Jose_2013.html",
    "title": "Mediation",
    "section": "",
    "text": "Jose, P. (2013). Doing statistical mediation and moderation. New York, NY: Guilford Press.\nThis example shows how to obtain a basic three-variable mediation analysis using lavaan, including how to obtain indirect and total effects. In Chapter 3 (Basic Mediation, pp. 43-92), Jose describes a basic mediation model involving three variables: Positive Life Events; Happiness; and Gratitude. Positive Life Events has a direct effect on Happiness, but also Positive Life Events has an indirect effect on Happiness via Gratitude.\n\nLoad relevant packages\nLoad the lavaan and haven packages.\n\nlibrary(lavaan)\nlibrary(haven)   # To read SPSS data files\n\n\n\nGet the data\nThe data are available at the Guilford Press site (note: the url on page 48 is no longer a valid link). The data are contained in an SPSS data file. I use the haven package to read SPSS data files. Examine the file structure, in particular, noting the variable names. These will be needed by lavaan.\n\nurl &lt;- \"http://www.guilford.com/add/jose/mediation_example.sav\"\ndataset &lt;- data.frame(haven::read_spss(url))\n\nstr(dataset)\nhead(dataset)\nsummary(dataset)\n\nThe names for the three variables are:\n\nple - Positive Life Events\ngrat - Gratitude\nshs - Happiness\n\n\n\nThe model\nThe model is given in Figure 3.3 (p. 46), reproduced below.\n\n\n\n\n\nIn lavaan, mediation effects can be estimated using the := operator. In the diagram, the effects are labelled a, b, and c\\('\\); in the model statement, they are labelled a, b, and cpr. The labels can then be used to obtain the indirect and total effects.\n\nmodel &lt;- \"\n  # direct effect\n  shs ~ cpr * ple\n\n  # effects via the mediator\n  grat ~ a * ple\n  shs ~ b * grat\n\n  # indirect effect (a*b)\n  indirect := a * b\n\n  # total effect\n  total := cpr + (a * b) \n\"\n\n\n\nFit the model and get the results\nI’ve requested unstandardised and standardised effects, and R2 values. For the standardised effects, see the “std.all” column in the output.\n\nfit &lt;- sem(model, data = dataset)\nsummary(fit, rsquare = TRUE, standardized = TRUE)   # Check with Tables 3.2-3.5\n\nJose conducts mediation analysis using regressions. The results are presented in Tables 3.2 to 3.5 (pp. 49-52). The unstandardised and standardised coefficients in the tables agree with the lavaan output.\nThe regression summary tables show the constants (that is, the intercepts). If intercepts are required, include meanstructure = TRUE in the sem() function.\n\nfit_intercepts &lt;- sem(model, data = dataset, meanstructure = TRUE)\nsummary(fit_intercepts, rsquare = TRUE, standardized = TRUE)\n\nOn pages 53 and 54, Jose shows how to calculate and test the statistical significance of Sobel’s z-value (that is, testing the significance of the indirect effect). Do not rely on that test. Also, do not rely of the t-test for the indirect effect given in the lavaan output. It is better to calculate confidence intervals, although the symmetric confidence interval presented in Table 3.7 (p. 55) is no better than the test for Sobel’s z-value. The asymmetric CI presented in Table 3.8 (p. 56) is possibly better. In lavaan, bootstrap CIs can be calculated.\n\nfit_boot &lt;- sem(model, data = dataset, se = \"bootstrap\", bootstrap = 2000)\nsummary(fit_boot, standardized = TRUE, ci = TRUE)\nparameterEstimates(fit_boot, boot.ci.type = \"perc\")\n\n\n\n\nR code with minimal commenting\n## Chapter 3 (Basic Mediation, pp. 43-92) in:\n##   Jose, P. (2013). Doing statistical mediation and moderation.\n##   New York, NY: Guilford Press.\n\n## Load packages\nlibrary(lavaan)\nlibrary(haven)   # To read SPSS data files\n\n## Get the data from Guilford Press web site\nurl &lt;- \"http://www.guilford.com/add/jose/mediation_example.sav\"\ndataset &lt;- data.frame(haven::read_spss(url))\n\nstr(dataset)\nhead(dataset)\nsummary(dataset)\n\n## The model\nmodel &lt;- \"\n  # direct effect\n  shs ~ cpr * ple\n\n  # effects via the mediator\n  grat ~ a * ple\n  shs ~ b * grat\n\n  # indirect effect (a*b)\n  indirect := a * b\n\n  # total effect\n  total := cpr + (a * b)\n\"\n\n## Fit the model and get the summary\nfit &lt;- sem(model, data = dataset)\nsummary(fit, rsquare = TRUE, standardized = TRUE)   # Check with Tables 3.2-3.5\n\n## To get intercepts\nfit_intercepts &lt;- sem(model, data = dataset, meanstructure = TRUE)\nsummary(fit_intercepts, rsquare = TRUE, standardized = TRUE)\n\n## To get bootstrap CIs\nfit_boot &lt;- sem(model, data = dataset, se = \"bootstrap\", bootstrap = 2000)\nsummary(fit_boot, standardized = TRUE, ci = TRUE)\nparameterEstimates(fit_boot, boot.ci.type = \"perc\")",
    "crumbs": [
      "SEMs with lavaan",
      "Mediation I"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Green_2023/one_way_MANOVA.html",
    "href": "SEMs_with_lavaan/Green_2023/one_way_MANOVA.html",
    "title": "One-Way MANOVA",
    "section": "",
    "text": "Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\nThis example shows the SEM approach to a one-way MANOVA. Results are reported in Table 21.5 (p. 399).\nThe data are described on pages 397 and 398.\n\nLoad package and get the data\nLoad the lavaan package, and run satisfactionII.r to get the data (satisfactionII.r is available at the end of this post).\n\nlibrary(lavaan)\n\nsource(\"satisfactionII.r\")\nhead(df)\n\nThe variables used in this example are:\n\nx - Coping Strategy (“a” - no strategy; “b” - discussion; “c” - exercise)\ny1, y2, y3, y4 - Multiple dependent variables (Life-Satisfaction scores)\n\n\n\nThe models\nThe SEM model for the one-way MANOVA is shown in Fig 21.2 (p. 400), and is reproduced below. The diagram shows the “Less Constrained” model. The means are represented by the labels on the arrows connecting the “1” to the dependent variables. The means for each variable are allowed to differ across the groups. The residual variances and covariances are constrained to equality.\n\n\n\n\n\nThe model statements are shown below. The “More Constrained” model constrains the means to equality. The “Less Constrained” model allows the means to differ across the groups. In both cases the residual variances and covariances are constrained to equality. The variancs and covariances can be set up separately - see vcov below. Then, vcov is added back into each model. Saves a little typing.\n\n# Variances and covariances (for both models)\nvcov &lt;-\n   \"y1 ~~ c(e1, e1, e1)*y1\n    y2 ~~ c(e2, e2, e2)*y2\n    y3 ~~ c(e3, e3, e3)*y3\n    y4 ~~ c(e4, e4, e4)*y4\n\n    y1 ~~ c(e12, e12, e12)*y2\n    y1 ~~ c(e13, e13, e13)*y3\n    y1 ~~ c(e14, e14, e14)*y4\n    y2 ~~ c(e23, e23, e23)*y3\n    y2 ~~ c(e24, e24, e24)*y4\n    y3 ~~ c(e34, e34, e34)*y4\"\n\nmodels &lt;- list(\n  \"More Constrained\" = c(\n    # Means\n    \"y1 ~ c(a1, a1, a1)*1\n     y2 ~ c(a2, a2, a2)*1\n     y3 ~ c(a3, a3, a3)*1\n     y4 ~ c(a4, a4, a4)*1\",\n     vcov),\n\n  \"Less Constrained\" =  c(\n    # Means\n    \"y1 ~ c(a1, b1, c1)*1\n     y2 ~ c(a2, b2, c2)*1\n     y3 ~ c(a3, b3, c3)*1\n     y4 ~ c(a4, b4, c4)*1\",\n     vcov)\n)\n\n\n\nFit the models and get the results\n\n# Fit the models \nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n# Get model summaries\nlapply(fit, summary)\n\n# Contrast model fits\nReduce(anova, fit)\n\nThe “SEM” section of Table 21.5 shows the \\(\\upchi\\)2 test.\nScroll through the summaries to find the “Intercepts”, or extract them from the list of estimates of model parameter.\n\n## Get list of estimates\nestimates &lt;- lapply(fit, lavInspect, \"est\"); estimates\n\n## Extract means - in element \"nu\"\nmeans &lt;- list()\nfor (i in names(models)) {\n   means[[i]] = estimates[[i]] |&gt;\n      sapply(\"[[\", \"nu\") |&gt;\n      round(2)\n   row.names(means[[i]]) = c(\"Y1\", \"Y2\", \"Y3\", \"Y4\")\n}\nmeans\n\nCompare with the means in Table 21.5.\nBy way of completeness, get the error SSCP matrices. (TLG state that, “the error SSCP matrices were perfectly reproduced by multiplying the variances and covariances in the SEM output by the total sample size” p. 398).\n\n# Note: In the list of estimates, co/variances are in element \"theta\"\nE &lt;- estimates |&gt;\n  lapply(\"[[\", \"a\") |&gt;           # Extract estimates for group \"a\"\n  lapply(\"[[\", \"theta\") |&gt;       # Extract \"theta\" element\n  lapply(matrix, nrow = 4) |&gt;    # Get the full matrix\n  lapply(\"*\", 200)               # Multiply by sample size\nE\n\n\n\nRelax homogeneity of variances and covariances assumption\nTowards the end of the section headed “Avoiding OLS assumptions for ANOVA/MANOVA designs using SEM” (pp. 398-401), TGL present the results for models in which the assumptions of homogeneity and normality are relaxed. That is, variances and covariances are not constrained to equality, and a robust ML method of estimation (MLM) is employed. Again, the variances and covariances are set up separately, then added back into each model. This time, there are no labels for the variances and covariances, meaning that lavaan will estimate each variance and covariance for each group.\n\n## Model statements\n# Variances and covariances (for both models)\nvcov &lt;- \n  \"y1 ~~ y1 + y2 + y3 + y4\n   y2 ~~ y2 + y3 + y4\n   y3 ~~ y3 + y4\n   y4 ~~ y4\" \n\nmodels &lt;- list(\n  \"Less Constrained\" =  c(\n    # Means\n    \"y1 ~ c(a1, b1, c1)*1\n     y2 ~ c(a2, b2, c2)*1\n     y3 ~ c(a3, b3, c3)*1\n     y4 ~ c(a4, b4, c4)*1\",\n     vcov),\n\n  \"More Constrained\" = c(\n    # Means\n    \"y1 ~ c(a1, a1, a1)*1\n     y2 ~ c(a2, a2, a2)*1\n     y3 ~ c(a3, a3, a3)*1\n     y4 ~ c(a4, a4, a4)*1\",\n     vcov)\n)\n\n## Fit the models\nfit &lt;- lapply(models, sem, data = df, estimator = \"mlm\", group = \"x\")\n\n## Get model summaries\nlapply(fit, summary)\n\n## Contrast model fits\nReduce(anova, fit)\n\nCompare with the \\(\\upchi\\)2 test on page 401.\n\n\n\nR code with minimal commenting\n## One-way MANOVA\n##\n## Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling\n## approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural\n## equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\n\n## Load package\nlibrary(lavaan)\n\n## Get the data\nsource(\"satisfactionII.r\")\nhead(df)\n\n## The models\n# Variances and covariances (for both models)\nvcov &lt;-\n   \"y1 ~~ c(e1, e1, e1)*y1\n    y2 ~~ c(e2, e2, e2)*y2\n    y3 ~~ c(e3, e3, e3)*y3\n    y4 ~~ c(e4, e4, e4)*y4\n\n    y1 ~~ c(e12, e12, e12)*y2\n    y1 ~~ c(e13, e13, e13)*y3\n    y1 ~~ c(e14, e14, e14)*y4\n    y2 ~~ c(e23, e23, e23)*y3\n    y2 ~~ c(e24, e24, e24)*y4\n    y3 ~~ c(e34, e34, e34)*y4\"\n\nmodels &lt;- list(\n  \"More Constrained\" = c(\n    # Means\n    \"y1 ~ c(a1, a1, a1)*1\n     y2 ~ c(a2, a2, a2)*1\n     y3 ~ c(a3, a3, a3)*1\n     y4 ~ c(a4, a4, a4)*1\",\n     vcov),\n\n  \"Less Constrained\" =  c(\n    # Means\n    \"y1 ~ c(a1, b1, c1)*1\n     y2 ~ c(a2, b2, c2)*1\n     y3 ~ c(a3, b3, c3)*1\n     y4 ~ c(a4, b4, c4)*1\",\n     vcov)\n)\n\n## Fit the models and get the results\n## Check means and chi square test in Table 21.5\n# Fit the models\nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n# Get model summaries\nlapply(fit, summary)\n\n# Contrast model fits\nReduce(anova, fit)\n\n## Extract means from list of estimates\n## Get list of estimates\nestimates &lt;- lapply(fit, lavInspect, \"est\"); estimates\n\n## Extract means - in element \"nu\"\nmeans &lt;- list()\nfor (i in names(models)) {\n   means[[i]] = estimates[[i]] |&gt;\n      sapply(\"[[\", \"nu\") |&gt;\n      round(2)\n   row.names(means[[i]]) = c(\"Y1\", \"Y2\", \"Y3\", \"Y4\")\n}\nmeans\n\n## Get the error SSCP matrices by hand\n# Note: In the list of estimates, co/variances are in element \"theta\"\nE &lt;- estimates |&gt;\n  lapply(\"[[\", \"a\") |&gt;           # Extract estimates for group \"a\"\n  lapply(\"[[\", \"theta\") |&gt;       # Extract \"theta\" element\n  lapply(matrix, nrow = 4) |&gt;    # Get the full matrix\n  lapply(\"*\", 200)               # Multiply by sample size\nE\n\n## Relax homogeneity of variances and covariances assumption\n## Check chi square on page 401\n## Model statements\n# Variances and covariances (for both models)\nvcov &lt;-\n  \"y1 ~~ y1 + y2 + y3 + y4\n   y2 ~~ y2 + y3 + y4\n   y3 ~~ y3 + y4\n   y4 ~~ y4\"\n\nmodels &lt;- list(\n  \"Less Constrained\" =  c(\n    # Means\n    \"y1 ~ c(a1, b1, c1)*1\n     y2 ~ c(a2, b2, c2)*1\n     y3 ~ c(a3, b3, c3)*1\n     y4 ~ c(a4, b4, c4)*1\",\n     vcov),\n\n  \"More Constrained\" = c(\n    # Means\n    \"y1 ~ c(a1, a1, a1)*1\n     y2 ~ c(a2, a2, a2)*1\n     y3 ~ c(a3, a3, a3)*1\n     y4 ~ c(a4, a4, a4)*1\",\n     vcov)\n)\n\n## Fit the models\nfit &lt;- lapply(models, sem, data = df, estimator = \"mlm\", group = \"x\")\n\n## Get model summaries\nlapply(fit, summary)\n\n## Contrast model fits\nReduce(anova, fit)\n\n\n\n\nR code to get data file - satisfactionII.r\n### Data for Tables 21.5 and 21.6 ###\n\ndf &lt;- structure(list(x = c(\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\"), x1 = c(1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L), x2 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L), x3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), y1 = c(18L, 24L, \n21L, 24L, 19L, 22L, 23L, 32L, 24L, 22L, 24L, 23L, 28L, 22L, 22L, \n23L, 19L, 28L, 25L, 25L, 27L, 21L, 33L, 24L, 23L, 28L, 29L, 24L, \n28L, 24L, 26L, 28L, 21L, 26L, 20L, 24L, 22L, 32L, 31L, 22L, 22L, \n27L, 22L, 26L, 24L, 24L, 25L, 27L, 26L, 24L, 22L, 18L, 25L, 27L, \n29L, 24L, 22L, 32L, 23L, 27L, 28L, 24L, 18L, 32L, 27L, 25L, 24L, \n25L, 29L, 21L, 29L, 25L, 25L, 25L, 19L, 32L, 29L, 22L, 18L, 26L, \n23L, 26L, 21L, 18L, 24L, 24L, 17L, 24L, 33L, 21L, 23L, 27L, 26L, \n28L, 20L, 27L, 25L, 25L, 25L, 18L, 27L, 25L, 22L, 23L, 26L, 23L, \n29L, 26L, 24L, 27L, 22L, 24L, 26L, 31L, 27L, 22L, 22L, 26L, 25L, \n21L, 26L, 25L, 24L, 26L, 28L, 27L, 26L, 26L, 19L, 22L, 25L, 26L, \n30L, 22L, 26L, 25L, 27L, 32L, 22L, 27L, 26L, 30L, 32L, 28L, 25L, \n23L, 21L, 14L, 26L, 28L, 29L, 25L, 27L, 25L, 26L, 21L, 23L, 25L, \n26L, 30L, 30L, 26L, 22L, 31L, 28L, 26L, 29L, 25L, 26L, 24L, 28L, \n22L, 35L, 26L, 34L, 29L, 26L, 27L, 32L, 16L, 26L, 22L, 25L, 30L, \n28L, 25L, 22L, 23L, 28L, 23L, 36L, 27L, 24L, 23L, 34L, 31L, 33L, \n26L, 27L, 22L), y2 = c(49L, 50L, 51L, 53L, 44L, 50L, 52L, 55L, \n53L, 48L, 48L, 51L, 57L, 51L, 48L, 51L, 48L, 53L, 59L, 55L, 51L, \n54L, 63L, 49L, 54L, 54L, 52L, 47L, 50L, 49L, 54L, 57L, 51L, 53L, \n49L, 53L, 53L, 57L, 58L, 49L, 53L, 55L, 59L, 57L, 55L, 53L, 55L, \n54L, 47L, 54L, 48L, 47L, 50L, 59L, 52L, 52L, 52L, 60L, 59L, 50L, \n55L, 59L, 55L, 59L, 61L, 48L, 55L, 55L, 60L, 50L, 62L, 54L, 56L, \n61L, 52L, 55L, 51L, 56L, 52L, 56L, 53L, 49L, 59L, 51L, 57L, 55L, \n48L, 54L, 56L, 53L, 47L, 54L, 52L, 54L, 50L, 54L, 52L, 54L, 59L, \n54L, 61L, 54L, 54L, 50L, 56L, 51L, 59L, 50L, 52L, 55L, 57L, 57L, \n62L, 55L, 53L, 51L, 50L, 60L, 51L, 52L, 52L, 56L, 52L, 55L, 56L, \n51L, 64L, 54L, 47L, 51L, 54L, 55L, 55L, 55L, 54L, 55L, 58L, 57L, \n56L, 60L, 55L, 54L, 61L, 55L, 50L, 53L, 60L, 49L, 58L, 61L, 55L, \n51L, 58L, 53L, 55L, 49L, 55L, 53L, 56L, 53L, 55L, 53L, 48L, 59L, \n56L, 52L, 55L, 58L, 54L, 54L, 59L, 49L, 60L, 62L, 57L, 59L, 57L, \n61L, 58L, 53L, 56L, 52L, 53L, 55L, 54L, 53L, 49L, 48L, 59L, 55L, \n61L, 59L, 50L, 55L, 58L, 63L, 53L, 56L, 55L, 54L), y3 = c(42L, \n42L, 46L, 39L, 39L, 37L, 38L, 43L, 36L, 37L, 40L, 45L, 46L, 39L, \n39L, 36L, 38L, 43L, 44L, 42L, 37L, 38L, 41L, 40L, 40L, 48L, 41L, \n37L, 42L, 32L, 38L, 43L, 38L, 41L, 45L, 39L, 40L, 41L, 49L, 40L, \n39L, 40L, 41L, 39L, 41L, 43L, 43L, 37L, 38L, 42L, 44L, 36L, 39L, \n44L, 41L, 38L, 40L, 49L, 41L, 39L, 46L, 45L, 40L, 50L, 45L, 43L, \n40L, 42L, 44L, 34L, 42L, 39L, 46L, 39L, 39L, 42L, 41L, 36L, 42L, \n46L, 39L, 39L, 37L, 36L, 42L, 32L, 37L, 43L, 42L, 42L, 46L, 47L, \n42L, 47L, 39L, 36L, 38L, 43L, 38L, 40L, 47L, 42L, 43L, 42L, 44L, \n42L, 45L, 41L, 39L, 45L, 42L, 41L, 46L, 44L, 43L, 38L, 42L, 44L, \n36L, 37L, 45L, 45L, 37L, 41L, 38L, 42L, 42L, 40L, 35L, 46L, 40L, \n42L, 48L, 42L, 42L, 44L, 44L, 48L, 38L, 43L, 42L, 40L, 48L, 39L, \n40L, 32L, 46L, 34L, 45L, 43L, 42L, 38L, 42L, 35L, 46L, 38L, 42L, \n39L, 43L, 43L, 50L, 41L, 42L, 43L, 44L, 35L, 44L, 42L, 41L, 47L, \n48L, 40L, 46L, 44L, 51L, 43L, 39L, 47L, 51L, 37L, 42L, 38L, 37L, \n38L, 43L, 40L, 36L, 40L, 46L, 43L, 50L, 42L, 42L, 40L, 43L, 46L, \n43L, 40L, 42L, 41L), y4 = c(29L, 31L, 34L, 36L, 26L, 30L, 34L, \n38L, 37L, 31L, 37L, 30L, 38L, 26L, 36L, 27L, 30L, 39L, 37L, 35L, \n39L, 33L, 35L, 32L, 34L, 40L, 32L, 31L, 38L, 38L, 34L, 42L, 30L, \n32L, 27L, 33L, 32L, 35L, 40L, 27L, 31L, 35L, 32L, 37L, 38L, 31L, \n29L, 28L, 33L, 35L, 31L, 22L, 34L, 37L, 27L, 33L, 35L, 47L, 30L, \n39L, 38L, 40L, 29L, 43L, 34L, 34L, 32L, 41L, 34L, 33L, 34L, 34L, \n32L, 32L, 30L, 34L, 32L, 38L, 25L, 35L, 34L, 24L, 34L, 33L, 26L, \n31L, 30L, 35L, 37L, 35L, 35L, 40L, 34L, 33L, 28L, 35L, 36L, 35L, \n40L, 34L, 39L, 33L, 28L, 34L, 31L, 29L, 39L, 40L, 35L, 37L, 36L, \n34L, 38L, 33L, 32L, 26L, 33L, 36L, 30L, 25L, 33L, 35L, 35L, 38L, \n36L, 39L, 32L, 34L, 35L, 34L, 36L, 28L, 35L, 30L, 31L, 38L, 35L, \n40L, 31L, 40L, 37L, 32L, 42L, 35L, 34L, 34L, 35L, 23L, 35L, 41L, \n39L, 37L, 34L, 26L, 35L, 34L, 35L, 33L, 31L, 40L, 38L, 32L, 29L, \n37L, 39L, 34L, 35L, 35L, 28L, 40L, 37L, 35L, 40L, 35L, 42L, 40L, \n42L, 37L, 39L, 32L, 38L, 31L, 34L, 39L, 38L, 35L, 32L, 33L, 39L, \n36L, 43L, 36L, 30L, 36L, 42L, 35L, 32L, 32L, 33L, 35L)), class = \"data.frame\", row.names = c(NA, \n-200L))\n\n\n\nhead(df)\n\n## x - Coping Strategy (a - No strategy; b - Discussion; c - Exercise)\n## y1, y2, y3, y4 - Multiple dependent variables (life-satisfaction scores)",
    "crumbs": [
      "SEMs with lavaan",
      "Means",
      "One-Way MANOVA"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Green_2023/index.html",
    "href": "SEMs_with_lavaan/Green_2023/index.html",
    "title": "Means",
    "section": "",
    "text": "Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\nThompson, Liu & Green (TLG) show an ordinary least squares (OLS) regression approach and a structural equation modeling (SEM) approach to:\n\nOne-way ANOVA\nOne-way ANCOVA\nTwo-way ANOVA\nOne-way MANOVA\nOne-way ANOVA of a latent variable\n\nThese examples show the SEM approaches only.",
    "crumbs": [
      "SEMs with lavaan",
      "Means"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Green_2023/one_way_LATENT.html",
    "href": "SEMs_with_lavaan/Green_2023/one_way_LATENT.html",
    "title": "One-Way ANOVA of Latent Variable",
    "section": "",
    "text": "Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\nThis example shows the SEM approach to a one-way ANOVA of a latent variable. Results are reported in Table 21.6 (p. 404).\nAny comparison of latent means assumes some level of measurement invariance. The first part of this example demonstrates SEM assuming strict measurement invariance. The second part demonstrates SEM under partial invariance of loadings and intercepts.\n\nLoad package and get the data\nLoad the lavaan package, and run satisfactionII.r to get the data.\n\nlibrary(lavaan)\n\nsource(\"satisfactionII.r\")\nhead(df)\n\nThe variables used in this example are:\n\nx - Coping Strategy (“a” - no strategy; “b” - discussion; “c” - exercise)\ny1, y2, y3, y4 - Multiple dependent variables (Life-Satisfaction scores)\n\n\n\nThe models\nThe SEM model for the one-way ANOVA of a latent variable is shown in Fig 21.3 (p. 403), and is reproduced below. The diagram shows the “Less Constrained” model.\n\n\n\n\n\nFor purposes of identification and scaling, the loading for the first indicator is constrained to one. (TLG claim that the loading for the 4th indicator is constrained to one. However, when the 4th loading is constrained to one, I do not get the same results as given in Table 21.6 (in particular the latent variance), nor do I get the means (given in the discussion on page 405); whereas I get agreement with the Table and the text when I constrain the 1st loading to one.)\nAlso for the purposes of identification and scaling, the latent mean for the first group is constrained to zero. For the “Less Constrained” model, the latent means for the other groups (a2 and a3) are freely estimated.\nTLG assume strict measurement invariance:\n\nthe loadings (\\(\\uplambda\\)) are constrained to equality across the groups;\nthe intercepts (\\(\\uptau\\)) are constrained to equality across the groups;\nthe indicator residual variances (e) and covariances are constrained to equality (covariances are set to zero by default, and thus they are equal);\nTLG impose one last constraint - latent error variances are constrained to equality across the groups (they do this to obtain a pooled variance to calculate an effect size for the differences between latent means).\n\nThe model statements are shown below. The only difference between the “More Constrained” model and the “Less Constrained” model is in the latent means. For purposess of identification and scaling, the latent mean for the first group is constrained to zero; in the “More Constrained” model, in which the means are constrained to equality, all three are constrained to zero. In the “Less Constrained” model, the means in the second and third groups are freely estimated.\nThe common parts of the two models are set up according to the bullet points above.\n\ncommon &lt;- \"\n   #  Measurement model\n   F =~ y1 + c(l2,l2,l2)*y2 + c(l3,l3,l3)*y3 + c(l4,l4,l4)*y4 \n\n   # Indicator intercepts\n   y1 ~ c(a1,a1,a1)*1\n   y2 ~ c(a2,a2,a2)*1\n   y3 ~ c(a3,a3,a3)*1\n   y4 ~ c(a4,a4,a4)*1\n\n   # Indicator residual variances\n   y1 ~~ c(e1,e1,e1)*y1\n   y2 ~~ c(e2,e2,e2)*y2\n   y3 ~~ c(e3,e3,e3)*y3\n   y4 ~~ c(e4,e4,e4)*y4\n\n   # Latent error variances\n   F ~~ c(d,d,d)*F\"\n\nmodels &lt;- list(\n  \"More Constrained\" = c(\n    \"# Latent means\n     F ~ c(m,m,m)*1\n\n     # Constraint\n     m == 0\",\n\n     common),\n\n  \"Less Constrained\" =  c(\n    \"# Latent means\n     F ~ c(m1,m2,m3)*1\n\n     # Constraint\n     m1 == 0\",\n\n     common)\n)\n\n\n\nFit the models and get the results\n\n## Fit the models \nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n## Get model summaries\nlapply(fit, summary)\n\n## Contrast model fits\nReduce(anova, fit)\n\nCompare with \\(\\upchi\\)2 test in the “All measures” row in Table 21.6.\nOne could scroll through the model summaries to find the latent means and error variances for the “Less Constrained” model, and compare them with Table 21.6. They are also needed to calculate effect sizes (given in the first column on page 405).\n\nd1 &lt;- (0.664 - 0) / sqrt(8.135); d1    # \"no strategy\" vs \"discussion\"\nd2 &lt;- (1.945 - 0) / sqrt(8.135); d2    # \"no strategy\" vs \"exercise\"\n\nBut it is probably safer to extract latent means and error variances from a list of parameter estimates, then substitute into the formula for effect size.\n\nestimates &lt;- lavInspect(fit[[\"Less Constrained\"]], \"est\"); estimates\n   # Note: latent means are in element \"alpha\"\n   #       latent error variances are in element \"psi\"\n\nLatentMeans &lt;- sapply(estimates, \"[[\", \"alpha\"); LatentMeans\nLatentVar   &lt;- sapply(estimates, \"[[\", \"psi\"); LatentVar\n\n   # \"no strategy\" vs \"discussion\"\nd1 &lt;- (LatentMeans[2] - LatentMeans[1]) / sqrt(LatentVar[1]); d1\n\n   # \"no strategy\" vs \"exercise\"\nd2 &lt;- (LatentMeans[3] - LatentMeans[1]) / sqrt(LatentVar[1]); d2\n\nCompare the effect sizes with those given on page 405, and the means and error variances with those in Table 21.6.\n\n\nMore Flexible Tests of Differences in Means on Latent Variables\nThe second and third rows of Table 21.6 follow after a discussion in the section headed “More Flexible Tests of Differences in Means on Latent Variables” (pp. 406-407).\nIn this section, TLG assume partial strong invariance:\n\nConstrain the loading for one indicator to equality across groups\nConstrain that indicator’s intercept to equality across groups\nThe other loadings and intercepts are freely estimated\n\nFor purposes of identification:\n\nFirst loading in each group is constrained to one\nLatent mean in the first group is constrained to zero\n\nNote that the residual variances are freely estimated across groups, as are the latent error variances. The indicator covariances are by default set to zero (unless there is good reason to have one or more estimated).\nFor the “More Constrained” model, the latent means are constrained to equality across the groups; for the “Less Constrained” model, the latent means differ.\nThe purpose of these examples is to demonstrate that “if a latent variable has only a single referent variable, the means and variances of the latent variable are a function of only the means and variances of this variable” (p. 406).\n\nModel that applies to the 2nd row in Table 21.6: “One measure - Y\\(_1\\)”\nThe selected indicator is the first - “y1”.\n\n# Model statements\ncommon &lt;- \n  \"# Measurement model\n   F =~ y1 + c(l12,l22,l32)*y2 + c(l13,l23,l33)*y3 + c(l14,l24,l34)*y4\n\n   # Indicator intercepts\n   y1 ~ c(a1,a1,a1)*1\n   y2 ~ c(a12,a22,a32)*1\n   y3 ~ c(a13,a23,a33)*1\n   y4 ~ c(a14,a24,a34)*1\n\n   # Indicator residual variances\n   y1 ~~ c(e11,e21,e31)*y1\n   y2 ~~ c(e12,e22,e32)*y2\n   y3 ~~ c(e13,e23,e33)*y3\n   y4 ~~ c(e14,e24,e34)*y4\n\n   # Latent error variances\n   F ~~ c(d1,d2,d3)*F\"\n\nmodels &lt;- list(\n  \"More Constrained\" = c(\n    \"# Latent means\n     F ~ c(m,m,m)*1\n\n     # Constraint\n     m == 0\",\n   \n     common),\n\n  \"Less Constrained\" =  c(\n    \"# Latent means\n     F ~ c(m1,m2,m3)*1\n\n     # Constraint\n     m1 == 0\",\n\n     common)\n)\n\nFit the models and get the latent means, latent error variances, and the \\(\\upchi\\)2 test.\n\n# Fit the models \nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n# Model summaries\nlapply(fit, summary)\n\n# Get the latent means and latent error variances for \"Less Constrained\" model\nestimates &lt;- lavInspect(fit[[\"Less Constrained\"]], \"est\"); estimates\nLatentMeans &lt;- sapply(estimates, \"[[\", \"alpha\"); LatentMeans\nLatentVar   &lt;- sapply(estimates, \"[[\", \"psi\"); LatentVar\n\n# Contrast model fits\nReduce(anova, fit)\n\nCompare with the latent means and error variances, and the \\(\\upchi\\)2 test in the 2nd row in Table 21.6.\nConsider the three columns of Table 21.6 dealing with means, variances and residual variances of one measure - in this case, “y1”.\nI need sample means and covariances - they can be extract from a list of sample statistics. I need estimated indicator intercepts and residual variances - they can be extracted from estimates. Also I need estimated latent means and error variances - they have already been extracted.\n\n# Get sample statistics\nsampstat &lt;- lavInspect(fit[[\"Less Constrained\"]], \"sampstat\"); sampstat\n   # Means are in element \"mean\"\n   # Variances are the diagonal elements in element \"cov\"\n\n# Get estimated model parameters\nestimates\n   # Residual variances for the measures are the diagonal elements in element \"theta\"\n   # Intercepts for the measures are in element \"nu\"\n\n\nMeans of the measures for each group (ie, the “y1” means).\n\nExtract the “y1” means from sampstats\nLatent means already extracted in LatentMeans\nThe differences between the “y1” means are the differences between the latent means\n\nAlternatively, the “y1” intercepts (which are constrained to equality) when added to the latent means give the “y1” means\n\n\n# Extract y1 means from sampstats\nMeansY1 &lt;- sapply(sampstat, \"[[\", \"mean\")\nMeansY1 &lt;- MeansY1[1,]; MeansY1   # Compare with 2nd row in Table 21.6\n\n# Differences between y1 means are differencs between latent means\nMeansY1[2] - MeansY1[1]\nMeansY1[3] - MeansY1[1]\n\n# Compare with latent means\nLatentMeans\n\n# Alternatively, the y1 intercepts (which are constrained to equality)\n# added to the latent means give the y1 means\nintercepts &lt;- sapply(estimates, \"[[\", \"nu\")[1,1]; intercepts\nintercepts + LatentMeans; MeansY1\n\n\n\nVariances of the measure for each group (ie, “y1” variances)\n\nExtract the “y1” variances from sampstats\nExtract residual variances for “y1” from estimates\nLatent error variances already extracted in LatentVar\nDifferences between “y1” variances and “y1” residual variances are the latent error variances\n\n\n# Extract y1 variances from sampstats\nVarY1 &lt;- sapply(lapply(sampstat, \"[[\", \"cov\"), diag)\nVarY1 &lt;- VarY1[1,]; VarY1  # Compare with 2nd row in Table 21.6\n\n# Extract residual variances for y1 from estimates\nResidVarY1 &lt;- sapply(lapply(estimates, \"[[\", \"theta\"), diag)\nResidVarY1 &lt;- ResidVarY1[1,]; ResidVarY1   # Compare with 2nd row in Table 21.6\n\n# Differences between y1 variances and y1 residual variances are latent error variances\nVarY1 - ResidVarY1\n\n# Compare with the latent error variances\nLatentVar\n\n\n\n\nModel that applies to the 3rd row in Table 21.6: “One measure - Y\\(_2\\)”\nThe selected indicator is the second - “y2”.\nThis is the same as before, except the constraints on the loadings and intercepts apply to the second indicator.\n\n# Model statements\ncommon &lt;- \n  \"# Measurement model\n   F =~ NA*c(l11,l21,l31)*y1 + 1*y2 + c(l13,l23,l33)*y3 + c(l14,l24,l34)*y4 \n\n   # Indicator intercepts \n   y1 ~ c(a11,a21,a31)*1\n   y2 ~ c(a2,a2,a2)*1\n   y3 ~ c(a13,a23,a33)*1\n   y4 ~ c(a14,a24,a34)*1\n\n   # Indicator residual variances\n   y1 ~~ c(e11,e21,e31)*y1\n   y2 ~~ c(e12,e22,e32)*y2\n   y3 ~~ c(e13,e23,e33)*y3\n   y4 ~~ c(e14,e24,e34)*y4\n\n   # Latent error variances\n   F ~~ c(d1,d2,d3)*F\"\n\nmodels &lt;- list(\n  \"Less Constrained\" =  c(\n    \"# Latent means\n     F ~ c(m1,m2,m3)*1\n\n     # Constraint\n     m1 == 0\",\n\n     common),\n\n  \"More Constrained\" = c(\n    \"# Latent means\n     F ~ c(m,m,m)*1\n\n     # Constraint\n     m == 0\",\n\n     common)\n)\n\nFit the models and get the latent means, latent error variances, and the \\(\\upchi\\)2 test.\n\n# Fit the models\nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n# Model summaries\nlapply(fit, summary)\n\n# Get the latent means and latent error variances for \"Less Constrained\" model\nestimates &lt;- lavInspect(fit[[\"Less Constrained\"]], \"est\"); estimates\nLatentMeans &lt;- sapply(estimates, \"[[\", \"alpha\"); LatentMeans\nLatentVar   &lt;- sapply(estimates, \"[[\", \"psi\"); LatentVar\n\n# Contrast model fits\nReduce(anova, fit)\n\nCompare with the latent means and error variances, and the \\(\\upchi\\)2 test in the 3rd row in Table 21.6.\nConsider the three columns of Table 21.6 dealing with means, variances and residual variances of one measure - in this case, “y2”.\nI need sample means and covariances - they can be extract from a list of sample statistics. I need estimated indicator intercepts and residual variances - they can be extracted from estimates. Also I need estimated latent means and error variances - they have already been extracted.\n\n# Get sample statistics\nsampstat &lt;- lavInspect(fit[[\"Less Constrained\"]], \"sampstat\"); sampstat\n   # Means are in element \"mean\"\n   # Variances are the diagonal elements in element \"cov\"\n\n# Get estimated model parameters\nestimates\n   # Residual variances for the measures are the diagonal elements in element \"theta\"\n   # Intercepts for the measures are in element \"nu\"\n\n\nThe means of the measures for each group (ie, the “y2” means).\n\nExtract the “y2” means from sampstats\nLatent means already extracted in LatentMeans\nThe differences between the “y2” means are the differences between the latent means\nAlternatively, the “y2” intercepts (which are constrained to equality) when added to the latent means give the “y2” means\n\n\n# Extract y2 Means from sampstats\nMeansY2 &lt;- sapply(sampstat, \"[[\", \"mean\")\nMeansY2 &lt;- MeansY2[2,]; MeansY2   # Compare with 3rd row in Table 21.6\n\n# Differences between y2 means are differencs between latent means\nMeansY2[2] - MeansY2[1]\nMeansY2[3] - MeansY2[1]\n\n# Compare with latent means\nLatentMeans\n\n# Alternatively, the y2 intercepts (which are constrained to equality)\n# added to the latent means give the Y2 means\nintercepts &lt;- sapply(estimates, \"[[\", \"nu\")[2,1]; intercepts\nintercepts + LatentMeans; MeansY2\n\n\n\nThe variances of the measure for each group (ie, “y2” variances)\n\nExtract the “y2” variances from sampstats\nExtract residual variances for “y2” from estimates\nLatent error variances already extracted in LatentVar\nDifferences between “y2” variances and “y2” residual variances are the latent error variances\n\n\n# Extract y2 variances from sampstats\nVarY2 &lt;- sapply(lapply(sampstat, \"[[\", \"cov\"), diag)\nVarY2 &lt;- VarY2[2,]; VarY2  # Compare with 3rd row in Table 21.6\n\n# Extract residual variances for y2 from estimates\nResidVarY2 &lt;- sapply(lapply(estimates, \"[[\", \"theta\"), diag)\nResidVarY2 &lt;- ResidVarY2[2, ]; ResidVarY2  # Compare with 3rd row in Table 21.6\n\n# Differences between y2 variances and y2 residual variances are latent error variances\nVarY2 - ResidVarY2\n\n# Compare with the latent error variances\nLatentVar\n\n\n\n\nR code with minimal commenting\n## One-way ANOVA of latent variable\n##\n## Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling\n## approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural\n## equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\n\n## Load package\nlibrary(lavaan)\n\n## Get the data\nsource(\"satisfactionII.r\")\nhead(df)\n\n## The models\ncommon &lt;- \"\n   #  Measurement model\n   F =~ y1 + c(l2,l2,l2)*y2 + c(l3,l3,l3)*y3 + c(l4,l4,l4)*y4\n\n   # Indicator intercepts\n   y1 ~ c(a1,a1,a1)*1\n   y2 ~ c(a2,a2,a2)*1\n   y3 ~ c(a3,a3,a3)*1\n   y4 ~ c(a4,a4,a4)*1\n\n   # Indicator residual variances\n   y1 ~~ c(e1,e1,e1)*y1\n   y2 ~~ c(e2,e2,e2)*y2\n   y3 ~~ c(e3,e3,e3)*y3\n   y4 ~~ c(e4,e4,e4)*y4\n\n   # Latent error variances\n   F ~~ c(d,d,d)*F\"\n\nmodels &lt;- list(\n  \"More Constrained\" = c(\n    \"# Latent means\n     F ~ c(m,m,m)*1\n\n     # Constraint\n     m == 0\",\n\n     common),\n\n  \"Less Constrained\" =  c(\n    \"# Latent means\n     F ~ c(m1,m2,m3)*1\n\n     # Constraint\n     m1 == 0\",\n\n     common)\n)\n\n## Fit the models and get the results\n## Check results in \"All measures\" row in Table 21.6\n## Fit the models\nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n## Get model summaries\nlapply(fit, summary)\n\n## Contrast model fits\nReduce(anova, fit)\n\n## Cut-and-paste means and variances to get effect sizes\n## Compare with values given on page 405\nd1 &lt;- (0.664 - 0) / sqrt(8.135); d1    # \"no strategy\" vs \"discussion\"\nd2 &lt;- (1.945 - 0) / sqrt(8.135); d2    # \"no strategy\" vs \"exercise\"\n\n## Extract latent means and error variances from \"Less Constrained\" model\n## Check with \"All measures\" row in Table 21.6\nestimates &lt;- lavInspect(fit[[\"Less Constrained\"]], \"est\"); estimates\n   # Note: latent means are in element \"alpha\"\n   #       latent error variances are in element \"psi\"\n\nLatentMeans &lt;- sapply(estimates, \"[[\", \"alpha\"); LatentMeans\nLatentVar   &lt;- sapply(estimates, \"[[\", \"psi\"); LatentVar\n\n## Effect sizes\n## Compare with values given on page 405\n   # \"no strategy\" vs \"discussion\"\nd1 &lt;- (LatentMeans[2] - LatentMeans[1]) / sqrt(LatentVar[1]); d1\n\n   # \"no strategy\" vs \"exercise\"\nd2 &lt;- (LatentMeans[3] - LatentMeans[1]) / sqrt(LatentVar[1]); d2\n\n## Relaxing some constraints\n## ANOVA model for 2nd row in Table 21.6\n# Model statements\ncommon &lt;-\n  \"# Measurement model\n   F =~ y1 + c(l12,l22,l32)*y2 + c(l13,l23,l33)*y3 + c(l14,l24,l34)*y4\n\n   # Indicator intercepts\n   y1 ~ c(a1,a1,a1)*1\n   y2 ~ c(a12,a22,a32)*1\n   y3 ~ c(a13,a23,a33)*1\n   y4 ~ c(a14,a24,a34)*1\n\n   # Indicator residual variances\n   y1 ~~ c(e11,e21,e31)*y1\n   y2 ~~ c(e12,e22,e32)*y2\n   y3 ~~ c(e13,e23,e33)*y3\n   y4 ~~ c(e14,e24,e34)*y4\n\n   # Latent error variances\n   F ~~ c(d1,d2,d3)*F\"\n\nmodels &lt;- list(\n  \"More Constrained\" = c(\n    \"# Latent means\n     F ~ c(m,m,m)*1\n\n     # Constraint\n     m == 0\",\n\n     common),\n\n  \"Less Constrained\" =  c(\n    \"# Latent means\n     F ~ c(m1,m2,m3)*1\n\n     # Constraint\n     m1 == 0\",\n\n     common)\n)\n\n## Fit the model and get the results\n## Check with means, error variance, and chi square in 2nd row in Table 21.6\n# Fit the models\nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n# Model summaries\nlapply(fit, summary)\n\n# Get the latent means and latent error variances for \"Less Constrained\" model\nestimates &lt;- lavInspect(fit[[\"Less Constrained\"]], \"est\"); estimates\nLatentMeans &lt;- sapply(estimates, \"[[\", \"alpha\"); LatentMeans\nLatentVar   &lt;- sapply(estimates, \"[[\", \"psi\"); LatentVar\n\n# Contrast model fits\nReduce(anova, fit)\n\n## Columns of Table 21.6 dealing with means, variances and residual variances of \"y1\"\n## Need sample statistics and model estimates\n# Get sample statistics\nsampstat &lt;- lavInspect(fit[[\"Less Constrained\"]], \"sampstat\"); sampstat\n   # Means are in element \"mean\"\n   # Variances are the diagonal elements in element \"cov\"\n\n# Get estimated model parameters\nestimates\n   # Residual variances for the measures are the diagonal elements in element \"theta\"\n   # Intercepts for the measures are in element \"nu\"\n\n# Extract y1 means from sampstats\nMeansY1 &lt;- sapply(sampstat, \"[[\", \"mean\")\nMeansY1 &lt;- MeansY1[1,]; MeansY1   # Compare with 2nd row in Table 21.6\n\n# Differences between y1 means are differencs between latent means\nMeansY1[2] - MeansY1[1]\nMeansY1[3] - MeansY1[1]\n\n# Compare with latent means\nLatentMeans\n\n# Alternatively, the y1 intercepts (which are constrained to equality)\n# added to the latent means give the y1 means\nintercepts &lt;- sapply(estimates, \"[[\", \"nu\")[1,1]; intercepts\nintercepts + LatentMeans; MeansY1\n\n# Extract y1 variances from sampstats\nVarY1 &lt;- sapply(lapply(sampstat, \"[[\", \"cov\"), diag)\nVarY1 &lt;- VarY1[1,]; VarY1  # Compare with 2nd row in Table 21.6\n\n# Extract residual variances for y1 from estimates\nResidVarY1 &lt;- sapply(lapply(estimates, \"[[\", \"theta\"), diag)\nResidVarY1 &lt;- ResidVarY1[1,]; ResidVarY1   # Compare with 2nd row in Table 21.6\n\n# Differences between y1 variances and y1 residual variances are latent error variances\nVarY1 - ResidVarY1\n\n# Compare with the latent error variances\nLatentVar\n\n## Relaxing some consyraints\n## ANOVA model for 3rd row in Table 21.6\n# Model statements\ncommon &lt;-\n  \"# Measurement model\n   F =~ NA*c(l11,l21,l31)*y1 + 1*y2 + c(l13,l23,l33)*y3 + c(l14,l24,l34)*y4\n\n   # Indicator intercepts\n   y1 ~ c(a11,a21,a31)*1\n   y2 ~ c(a2,a2,a2)*1\n   y3 ~ c(a13,a23,a33)*1\n   y4 ~ c(a14,a24,a34)*1\n\n   # Indicator residual variances\n   y1 ~~ c(e11,e21,e31)*y1\n   y2 ~~ c(e12,e22,e32)*y2\n   y3 ~~ c(e13,e23,e33)*y3\n   y4 ~~ c(e14,e24,e34)*y4\n\n   # Latent error variances\n   F ~~ c(d1,d2,d3)*F\"\n\nmodels &lt;- list(\n  \"Less Constrained\" =  c(\n    \"# Latent means\n     F ~ c(m1,m2,m3)*1\n\n     # Constraint\n     m1 == 0\",\n\n     common),\n\n  \"More Constrained\" = c(\n    \"# Latent means\n     F ~ c(m,m,m)*1\n\n     # Constraint\n     m == 0\",\n\n     common)\n)\n\n## Fit the model and get the results\n## Check with means, error variance, and chi square in 3rd row in Table 21.6\n# Fit the models\nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n# Model summaries\nlapply(fit, summary)\n\n# Get the latent means and latent error variances for \"Less Constrained\" model\nestimates &lt;- lavInspect(fit[[\"Less Constrained\"]], \"est\"); estimates\nLatentMeans &lt;- sapply(estimates, \"[[\", \"alpha\"); LatentMeans\nLatentVar   &lt;- sapply(estimates, \"[[\", \"psi\"); LatentVar\n\n# Contrast model fits\nReduce(anova, fit)\n\n## Columns of Table 21.6 dealing with means, variances and residual variances of \"y2\"\n## Need sample statistics and model estimates\n# Get sample statistics\nsampstat &lt;- lavInspect(fit[[\"Less Constrained\"]], \"sampstat\"); sampstat\n   # Means are in element \"mean\"\n   # Variances are the diagonal elements in element \"cov\"\n\n# Get estimated model parameters\nestimates\n   # Residual variances for the measures are the diagonal elements in element \"theta\"\n   # Intercepts for the measures are in element \"nu\"\n\n# Extract y2 Means from sampstats\nMeansY2 &lt;- sapply(sampstat, \"[[\", \"mean\")\nMeansY2 &lt;- MeansY2[2,]; MeansY2   # Compare with 3rd row in Table 21.6\n\n# Differences between y2 means are differencs between latent means\nMeansY2[2] - MeansY2[1]\nMeansY2[3] - MeansY2[1]\n\n# Compare with latent means\nLatentMeans\n\n# Alternatively, the y2 intercepts (which are constrained to equality)\n# added to the latent means give the Y2 means\nintercepts &lt;- sapply(estimates, \"[[\", \"nu\")[2,1]; intercepts\nintercepts + LatentMeans; MeansY2\n\n# Extract y2 variances from sampstats\nVarY2 &lt;- sapply(lapply(sampstat, \"[[\", \"cov\"), diag)\nVarY2 &lt;- VarY2[2,]; VarY2  # Compare with 3rd row in Table 21.6\n\n# Extract residual variances for y2 from estimates\nResidVarY2 &lt;- sapply(lapply(estimates, \"[[\", \"theta\"), diag)\nResidVarY2 &lt;- ResidVarY2[2, ]; ResidVarY2  # Compare with 3rd row in Table 21.6\n\n# Differences between y2 variances and y2 residual variances are latent error variances\nVarY2 - ResidVarY2\n\n# Compare with the latent error variances\nLatentVar\n\n\n\n\nR code to get data file - satisfactionII.r\n### Data for Tables 21.5 and 21.6 ###\n\ndf &lt;- structure(list(x = c(\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\"), x1 = c(1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L), x2 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L), x3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), y1 = c(18L, 24L, \n21L, 24L, 19L, 22L, 23L, 32L, 24L, 22L, 24L, 23L, 28L, 22L, 22L, \n23L, 19L, 28L, 25L, 25L, 27L, 21L, 33L, 24L, 23L, 28L, 29L, 24L, \n28L, 24L, 26L, 28L, 21L, 26L, 20L, 24L, 22L, 32L, 31L, 22L, 22L, \n27L, 22L, 26L, 24L, 24L, 25L, 27L, 26L, 24L, 22L, 18L, 25L, 27L, \n29L, 24L, 22L, 32L, 23L, 27L, 28L, 24L, 18L, 32L, 27L, 25L, 24L, \n25L, 29L, 21L, 29L, 25L, 25L, 25L, 19L, 32L, 29L, 22L, 18L, 26L, \n23L, 26L, 21L, 18L, 24L, 24L, 17L, 24L, 33L, 21L, 23L, 27L, 26L, \n28L, 20L, 27L, 25L, 25L, 25L, 18L, 27L, 25L, 22L, 23L, 26L, 23L, \n29L, 26L, 24L, 27L, 22L, 24L, 26L, 31L, 27L, 22L, 22L, 26L, 25L, \n21L, 26L, 25L, 24L, 26L, 28L, 27L, 26L, 26L, 19L, 22L, 25L, 26L, \n30L, 22L, 26L, 25L, 27L, 32L, 22L, 27L, 26L, 30L, 32L, 28L, 25L, \n23L, 21L, 14L, 26L, 28L, 29L, 25L, 27L, 25L, 26L, 21L, 23L, 25L, \n26L, 30L, 30L, 26L, 22L, 31L, 28L, 26L, 29L, 25L, 26L, 24L, 28L, \n22L, 35L, 26L, 34L, 29L, 26L, 27L, 32L, 16L, 26L, 22L, 25L, 30L, \n28L, 25L, 22L, 23L, 28L, 23L, 36L, 27L, 24L, 23L, 34L, 31L, 33L, \n26L, 27L, 22L), y2 = c(49L, 50L, 51L, 53L, 44L, 50L, 52L, 55L, \n53L, 48L, 48L, 51L, 57L, 51L, 48L, 51L, 48L, 53L, 59L, 55L, 51L, \n54L, 63L, 49L, 54L, 54L, 52L, 47L, 50L, 49L, 54L, 57L, 51L, 53L, \n49L, 53L, 53L, 57L, 58L, 49L, 53L, 55L, 59L, 57L, 55L, 53L, 55L, \n54L, 47L, 54L, 48L, 47L, 50L, 59L, 52L, 52L, 52L, 60L, 59L, 50L, \n55L, 59L, 55L, 59L, 61L, 48L, 55L, 55L, 60L, 50L, 62L, 54L, 56L, \n61L, 52L, 55L, 51L, 56L, 52L, 56L, 53L, 49L, 59L, 51L, 57L, 55L, \n48L, 54L, 56L, 53L, 47L, 54L, 52L, 54L, 50L, 54L, 52L, 54L, 59L, \n54L, 61L, 54L, 54L, 50L, 56L, 51L, 59L, 50L, 52L, 55L, 57L, 57L, \n62L, 55L, 53L, 51L, 50L, 60L, 51L, 52L, 52L, 56L, 52L, 55L, 56L, \n51L, 64L, 54L, 47L, 51L, 54L, 55L, 55L, 55L, 54L, 55L, 58L, 57L, \n56L, 60L, 55L, 54L, 61L, 55L, 50L, 53L, 60L, 49L, 58L, 61L, 55L, \n51L, 58L, 53L, 55L, 49L, 55L, 53L, 56L, 53L, 55L, 53L, 48L, 59L, \n56L, 52L, 55L, 58L, 54L, 54L, 59L, 49L, 60L, 62L, 57L, 59L, 57L, \n61L, 58L, 53L, 56L, 52L, 53L, 55L, 54L, 53L, 49L, 48L, 59L, 55L, \n61L, 59L, 50L, 55L, 58L, 63L, 53L, 56L, 55L, 54L), y3 = c(42L, \n42L, 46L, 39L, 39L, 37L, 38L, 43L, 36L, 37L, 40L, 45L, 46L, 39L, \n39L, 36L, 38L, 43L, 44L, 42L, 37L, 38L, 41L, 40L, 40L, 48L, 41L, \n37L, 42L, 32L, 38L, 43L, 38L, 41L, 45L, 39L, 40L, 41L, 49L, 40L, \n39L, 40L, 41L, 39L, 41L, 43L, 43L, 37L, 38L, 42L, 44L, 36L, 39L, \n44L, 41L, 38L, 40L, 49L, 41L, 39L, 46L, 45L, 40L, 50L, 45L, 43L, \n40L, 42L, 44L, 34L, 42L, 39L, 46L, 39L, 39L, 42L, 41L, 36L, 42L, \n46L, 39L, 39L, 37L, 36L, 42L, 32L, 37L, 43L, 42L, 42L, 46L, 47L, \n42L, 47L, 39L, 36L, 38L, 43L, 38L, 40L, 47L, 42L, 43L, 42L, 44L, \n42L, 45L, 41L, 39L, 45L, 42L, 41L, 46L, 44L, 43L, 38L, 42L, 44L, \n36L, 37L, 45L, 45L, 37L, 41L, 38L, 42L, 42L, 40L, 35L, 46L, 40L, \n42L, 48L, 42L, 42L, 44L, 44L, 48L, 38L, 43L, 42L, 40L, 48L, 39L, \n40L, 32L, 46L, 34L, 45L, 43L, 42L, 38L, 42L, 35L, 46L, 38L, 42L, \n39L, 43L, 43L, 50L, 41L, 42L, 43L, 44L, 35L, 44L, 42L, 41L, 47L, \n48L, 40L, 46L, 44L, 51L, 43L, 39L, 47L, 51L, 37L, 42L, 38L, 37L, \n38L, 43L, 40L, 36L, 40L, 46L, 43L, 50L, 42L, 42L, 40L, 43L, 46L, \n43L, 40L, 42L, 41L), y4 = c(29L, 31L, 34L, 36L, 26L, 30L, 34L, \n38L, 37L, 31L, 37L, 30L, 38L, 26L, 36L, 27L, 30L, 39L, 37L, 35L, \n39L, 33L, 35L, 32L, 34L, 40L, 32L, 31L, 38L, 38L, 34L, 42L, 30L, \n32L, 27L, 33L, 32L, 35L, 40L, 27L, 31L, 35L, 32L, 37L, 38L, 31L, \n29L, 28L, 33L, 35L, 31L, 22L, 34L, 37L, 27L, 33L, 35L, 47L, 30L, \n39L, 38L, 40L, 29L, 43L, 34L, 34L, 32L, 41L, 34L, 33L, 34L, 34L, \n32L, 32L, 30L, 34L, 32L, 38L, 25L, 35L, 34L, 24L, 34L, 33L, 26L, \n31L, 30L, 35L, 37L, 35L, 35L, 40L, 34L, 33L, 28L, 35L, 36L, 35L, \n40L, 34L, 39L, 33L, 28L, 34L, 31L, 29L, 39L, 40L, 35L, 37L, 36L, \n34L, 38L, 33L, 32L, 26L, 33L, 36L, 30L, 25L, 33L, 35L, 35L, 38L, \n36L, 39L, 32L, 34L, 35L, 34L, 36L, 28L, 35L, 30L, 31L, 38L, 35L, \n40L, 31L, 40L, 37L, 32L, 42L, 35L, 34L, 34L, 35L, 23L, 35L, 41L, \n39L, 37L, 34L, 26L, 35L, 34L, 35L, 33L, 31L, 40L, 38L, 32L, 29L, \n37L, 39L, 34L, 35L, 35L, 28L, 40L, 37L, 35L, 40L, 35L, 42L, 40L, \n42L, 37L, 39L, 32L, 38L, 31L, 34L, 39L, 38L, 35L, 32L, 33L, 39L, \n36L, 43L, 36L, 30L, 36L, 42L, 35L, 32L, 32L, 33L, 35L)), class = \"data.frame\", row.names = c(NA, \n-200L))\n\n\n\nhead(df)\n\n## x - Coping Strategy (a - No strategy; b - Discussion; c - Exercise)\n## y1, y2, y3, y4 - Multiple dependent variables (life-satisfaction scores)",
    "crumbs": [
      "SEMs with lavaan",
      "Means",
      "One-Way LATENT"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Kurbanoglu_2021/Kurbanoglu_2021.html",
    "href": "SEMs_with_lavaan/Kurbanoglu_2021/Kurbanoglu_2021.html",
    "title": "Mediation",
    "section": "",
    "text": "Kurbanoglu, N. & Takunyaci, M. (2021). A structural equation modeling on relationship between self-efficacy, physics laboratory anxiety and attitudes. Journal of Family, Counseling and Education, 6(1), 47-56.\nThis example shows how to obtain a basic three-variable mediation analysis using lavaan, and how to obtain indirect and total effects. The three variables are: Self-Efficacy; Physics Laboratory Attitudes; and Physics Laboratory Anxiety. Self-Efficacy has a direct effect on Anxiety, but also Self-Efficacy has an indirect effect on Anxiety via Attitudes. This example also shows how to use summary data when the raw sample data are not available; in particular, how to obtain a matrix of variances and covariances from the summary data (correlations and standard deviations), and then how to use the co/variance matrix to replicate the analysis.\nExcept in this case, the analysis cannot be replicated (see below). There are problems with the paper. Rather than being an examplar, this example is included to show how to run SEM using summary data in order to check published results.\n\nLoad relevant packages\nLoad the lavaan and semmcci packages.\n\nlibrary(lavaan)\nlibrary(semmcci)  # For Monte Carlo CIs\n\n\n\nGet the data\nSample data are not available, but Table 1 (p. 50) gives correlations, means, and standard deviations, and the sample size is given on page 49. From these, the co/variance matrix can be obtained. The correlations do not need to be in the form of a matrix. All that is required is a vector of the lower triangle of correlations with ones along the diagonal.\n\ncor &lt;- c(\n   1,\n   0.30,  1,\n  -0.42, -0.32,  1)\n\nsds &lt;- c(8.81, 7.95, 18.30)\nmeans &lt;- c(56.57, 40.39, 68.22)\nn &lt;- 513\n\nThe three variables need names, making sure the order is the same as in Table 1. The names used here are:\n\nSE - Self-Efficacy\nAtt - Physics Laboratory Attitudes\nAnx - Physics Laboratory Anxiety\n\n\nnames &lt;- c(\"Att\", \"SE\", \"Anx\")\n\nThe getCov() function from the lavaan package is used to get the co/variance matrix.\n\ncov &lt;- lavaan::getCov(cor, sds = sds, names = names)\n\n\n\nThe model\nThe model is given in Figure 1 (p. 51), reproduced below.\n\n\n\n\n\nKurbanoglu & Takunyaci (K&T) do not estimate the indirect effect; only the “a” and “b” paths. In lavaan, indirect effects can be estimated using the := operator. In the diagram, the effects are labelled a, b, and c\\('\\); in the model statement, they are labelled a, b, and cpr. The labels can then be used to obtain the indirect and total effects.\n\nmodel &lt;- \"\n  # direct effect\n  Anx ~ cpr * SE\n\n  # effects via the mediator\n  Att ~ a * SE\n  Anx ~ b * Att\n\n  # indirect effect (a * b)\n  ab := a * b\n\n  # total effect\n  total := cpr + (a * b)\n\"\n\n\n\nFit the model and get the results\nIn Figure 1, K&T present standardised estimates and R2 values; so they are requested here (for standardised estimates, see “std.all” column in the output).\n\nfit &lt;- sem(model, sample.cov = cov, sample.nobs = n)\nsummary(fit, rsquare = TRUE, standardized = TRUE, fit.measures = TRUE)\n\nI’ve requested a selection of fit measures. Why fit measures? Afterall, the model is saturated, and all fit measures should indicate a perfect fit. Something has gone awry for K&T. At the bottom of page 50, they state that the model is saturated. As a consequence, \\(\\upchi\\)2 and RMSEA should be zero, and GFI, AGF, CFI, NFI, RFI, and IFI should all be one; yet values are given (p. 50) to indicate a less than perfect fit. I’m not sure how this could have come about, or why the error was not picked up during review.\nIf the intercepts are required, include sample.mean = means in the sem() function.\n\nfit_intercepts &lt;- sem(model, sample.cov = cov, sample.nobs = n,\n   sample.mean = means)\nsummary(fit_intercepts, rsquare = TRUE, standardized = TRUE)\n\nDo not rely on the t-tests, especially for indirect effects. Often bootstrap confidence intervals are calculated, but bootstrapping requires the raw sample data. Instead of bootstrap CIs, Monte Carlo CIs can be calculated using the MC() function from the semmcci package.\n\nsemmcci::MC(fit, R = 50000, alpha = 0.05)\n\n\n\n\nR code with minimal commenting\n## Kurbanoglu, N. & Takunyaci, M. (2021). A structural equation modeling\n## on relationship between self-efficacy, physics laboratory anxiety\n## and attitudes. Journal of Family, Counseling and Education, 6(1), 47-56.\n\n## Load packages\nlibrary(lavaan)\nlibrary(semmcci)  # For Monte Carlo CIs\n\n## Get the data from Table 1\ncor &lt;- c(\n   1,\n   0.30,  1,\n  -0.42, -0.32,  1)\n\nsds &lt;- c(8.81, 7.95, 18.30)\nmeans &lt;- c(56.57, 40.39, 68.22)\nn &lt;- 513\n\n## Get the variable names\nnames &lt;- c(\"Att\", \"SE\", \"Anx\")\n\n## Get the co/variance matrix\ncov &lt;- lavaan::getCov(cor, sds = sds, names = names)\n\n## The model\nmodel &lt;- \"\n  # direct effect\n  Anx ~ cpr * SE\n\n  # effects via the mediator\n  Att ~ a * SE\n  Anx ~ b * Att\n\n  # indirect effect (a * b)\n  ab := a * b\n\n  # total effect\n  total := cpr + (a * b)\n\"\n\n## Fit the model and get the summary\n#  Compare with Figure 1\nfit &lt;- sem(model, sample.cov = cov, sample.nobs = n)\nsummary(fit, rsquare = TRUE, standardized = TRUE, fit.measures = TRUE)\n\n## To get intercepts\nfit_intercepts &lt;- sem(model, sample.cov = cov, sample.nobs = n,\n   sample.mean = means)\nsummary(fit_intercepts, rsquare = TRUE, standardized = TRUE)\n\n## To get Monte Carlo CIs\nsemmcci::MC(fit, R = 50000, alpha = 0.05)",
    "crumbs": [
      "SEMs with lavaan",
      "Mediation II"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Little_2006/Little_2006.html",
    "href": "SEMs_with_lavaan/Little_2006/Little_2006.html",
    "title": "Scaling",
    "section": "",
    "text": "Little, T., Slegers, D., & Card, N. (2006). A non-arbitrary method of identifying and scaling latent variables in SEM and MACS models. Structural Equation Modeling, 13(1), 59-72.\nThis example shows how to set constraints for different methods of identification and scaling in latent variable models, and, though invariance is not a topic of discussion, the example shows how to set constraints for strong metric invariance in a two-group model. Also, the example shows how to use summary data (correlations, standard deviations, and means) in a two-group model.\nThe methods of identification and scaling discussed by Little, Slegers & Card (LS&C) are:\nLS&C present a two-group (7th grade and 8th grade), two-construct (positive affect and negative affact) model. Each construct is assessed with three manifest indicators. The SEM diagram below shows the model as it might apply to the whole sample (i.e., ignoring the groups). This one-group model is presented to explain the symbols used in the paper, and to show how they apply in the model diagrams. First, POS and NEG are the constructs; and pos1, …, neg3 are the manifest indicators. The solid lines represent the covariance structure, and the gray lines represent the mean structure (ie, the means and intercepts).\nThe symbols are:",
    "crumbs": [
      "SEMs with lavaan",
      "Scaling"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Little_2006/Little_2006.html#reference-group-method",
    "href": "SEMs_with_lavaan/Little_2006/Little_2006.html#reference-group-method",
    "title": "Scaling",
    "section": "Reference-Group Method",
    "text": "Reference-Group Method\n\nThe model\nThe model with the constraints is shown below. Some points to note. There are two groups: Grade 7 and Grade 8. The corresponding loadings (\\(\\uplambda\\)) and intercepts (\\(\\uptau\\)) are equal across the groups. The latent variances (\\(\\upphi\\)7,11 and \\(\\upphi\\)7,22) and latent means (\\(\\upkappa\\)) are constrained to 1 and 0 respectively in the first group only. The residual variances (\\(\\uptheta\\)) are freely estimated in each group, and the latent covariances (\\(\\upphi\\)7,12 and \\(\\upphi\\)8,12) are freely estimated.\n\n\n\n\n\nWhen constructing the model statment, there are some points to be considered.\nFirst, the constraints applied to latent means and variances apply in the first group only. In the model statement, pre-multiply the mean or the variance by a vector containing the constraints; like this: c(1,NA) - the 1 forces the parameter in the first group to be constrained to 1; the NA forces the parameter in the second group to be estimated.\nSecond, LS&C state that the data display strong metric invariance (p. 63); that is, the corresponding loadings and intercepts are equal across the groups. There is no need to be concerned with these constraints when constructing the model statement - they will be set up in the next step. (Strictly, the intercepts do not even need to be mentioned in the model statement - lavaan will add them automatically when sample.means are in the model. But they are left in the statement below because intercepts are implicated in constraints in models to follow.)\nThird, strong metric invariance places no constraints on indicator variances - they are freely estimated in each group. But again, there is no need to be concerned with or even to mention them when constructing the model statement - lavaan will add them automatically.\nFinally, lavaan’s default marker-variable method has to be explicitely disabled by pre-multiplying the first indicator for both constructs by NA.\n\nm1 &lt;- \"\n  # Measurement Model\n  #   - Free the 1st loading so it can be estimated\n  POS =~ NA*pos1 + pos2 + pos3\n  NEG =~ NA*neg1 + neg2 + neg3\n\n  # Latent variances and covariance\n  #   - Constrain latent variances to 1 in first group\n  POS ~~ c(1,NA)*POS\n  NEG ~~ c(1,NA)*NEG\n  POS ~~ NEG\n\n  # Indicator intercepts\n  pos1 ~ 1\n  pos2 ~ 1\n  pos3 ~ 1\n  neg1 ~ 1\n  neg2 ~ 1\n  neg3 ~ 1\n\n  # Latent means\n  #   - Constrain latent means to 0 in first group\n  POS ~ c(0,NA)*1\n  NEG ~ c(0,NA)*1\n\"\n\n\n\nFit the model and get the results\nTo deal with strong metric invariance, set group.equal = c(\"loadings\", \"intercepts\") in the sem() function.\n\nm1_fit &lt;- sem(m1, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m1_fit, standardized = TRUE, fit.measures = TRUE)\n\nCompare the output with “Method 1” in Table 2 (pp. 64-65).\n\n\nA shortcut\nLavaan can do reference-group scaling automatically - set std.lv = TRUE in the sem() function. The constraints are the same as above - in the first group, latent variances are constrained to one, and latent means are constrained to zero.\n\nm1_short &lt;- \"\n  # Measurement Model\n  POS =~ pos1 + pos2 + pos3\n  NEG =~ neg1 + neg2 + neg3\n\"\n\nm1_short_fit &lt;- sem(m1_short, sample.cov = cov, sample.nobs = n, \n   sample.mean = mean, std.lv = TRUE,\n   group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m1_short_fit, standardized = TRUE, fit.measures = TRUE)\n\nCheck the output. It is the same as before except for one detail. It might be disconcerting for some that the latent means in the first group are not reported. Maybe it’s not important because they are zero (remember the constraint). To see them in the output, set remove.unused = FALSE in the summary() function.\n\nsummary(m1_short_fit, remove.unused = FALSE, standardized = TRUE,\n   fit.measures = TRUE)",
    "crumbs": [
      "SEMs with lavaan",
      "Scaling"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Little_2006/Little_2006.html#marker-variable-method",
    "href": "SEMs_with_lavaan/Little_2006/Little_2006.html#marker-variable-method",
    "title": "Scaling",
    "section": "Marker-Variable Method",
    "text": "Marker-Variable Method\n\nThe model\nThe model with the constraints is shown below.\n\n\n\n\n\nResults for three versions of Method 2 are presented in Table 2 - in each case, constraints are applied to different indicator variables. Here, only the third is considered - constraints apply to loadings and intercepts for the third indicator in the POS construct, and to the first indicator in the NEG construct.\nSome points to be considered.\nFirst, with strong metric invariance in place, the constraints applying to intercepts and loadings apply in both groups. In the model statement, pre-multiply the loadings by c(1,1), and the intercepts by c(0,0).\nSecond, again, the point concerning strong metric invariance - it will be set up in the next step.\nThird, again, there is no need to mention indicator variances - lavaan will add them automatically.\nFinally, lavaan’s default marker-variable method has to be explicitely disabled for the POS construct by pre-multiplying the first indicator be NA.\n\nm2c &lt;- \"\n  # Measurement Model\n  #   - Free the 1st loading in POS so it can be estimated\n  #   - Constrain 3rd loading in POS to 1 in both groups\n  #   - Constrain 1st loading in NEG to 1 in both groups\n  POS =~ NA*pos1 + pos2 + c(1,1)*pos3\n  NEG =~ c(1,1)*neg1 + neg2 + neg3\n\n  # Latent variances and covariance\n  POS ~~ POS\n  NEG ~~ NEG\n  POS ~~ NEG\n\n  # Indicator intercepts\n  #   - Constrain 3rd intercept in POS to 0 in both groups\n  #   - Constrain 1st intercept in NEG to 0 in both groups\n  pos1 ~ 1\n  pos2 ~ 1\n  pos3 ~ c(0,0)*1\n  neg1 ~ c(0,0)*1\n  neg2 ~ 1\n  neg3 ~ 1\n\n  # Latent means\n  POS ~ 1\n  NEG ~ 1\n\"\n\n\n\nFit the model and get the results\nAs before, the group.equal = c(\"loadings\", \"intercepts\") statement in the sem() function forces corresponding loadings and intercepts to be equal across the groups.\n\nm2c_fit &lt;- sem(m2c, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m2c_fit, standardized = TRUE, fit.measures = TRUE)\n\nCompare the output with “Method 2c” in Table 2 (pp. 64-65).\n\n\nLavaan default\nThis is not lavaan’s default method of scaling. The default method constrains the loadings for the first indicator to one for both constructs and, because of the strong metric invariance, in both groups. When there is a mean structure in the model, lavaan sets the latent means to zero (in the first group only). In the summary() function set remove.unused = FALSE to see the latent means.\n\nm2c_default &lt;- \"\n  # Measurement Model\n  POS =~ pos1 + pos2 + pos3\n  NEG =~ neg1 + neg2 + neg3\n\"\n\nm2c_default_fit &lt;- sem(m2c_default, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m2c_default_fit, remove.unused = FALSE,\n   standardized = TRUE, fit.measures = TRUE)",
    "crumbs": [
      "SEMs with lavaan",
      "Scaling"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Little_2006/Little_2006.html#effects-coding-method",
    "href": "SEMs_with_lavaan/Little_2006/Little_2006.html#effects-coding-method",
    "title": "Scaling",
    "section": "Effects-Coding Method",
    "text": "Effects-Coding Method\n\nThe model\nThe model with the equality constraints is shown below.\n\n\n\n\n\nIn the model statement, the loadings and the intercepts are labelled (see the “Measurement Model” and the “Indicator intercepts” sections in the model statement) so that the labels can be used to impose the constraints. Constraints are imposed on the loadings and the intercepts using the == operator - see the “Constraints” section in the model statement.\nSame points as before: lavaan will add indicator variances automatically; constraints concerning strong metric invariance will be attended to in the next step; and the default marker-variable method has to be explicitely disabled.\n\nm3 &lt;- \"\n  # Measurement Model\n  #   - Free the 1st loading so it can be estimated\n  #   - Label the loadings so they can be used in the constraints\n  POS =~ NA*p1*pos1 + p2*pos2 + p3*pos3\n  NEG =~ NA*n1*neg1 + n2*neg2 + n3*neg3\n\n  # Latent variances and covariance\n  POS ~~ POS\n  NEG ~~ NEG\n  POS ~~ NEG\n\n  # Indicator intercepts\n  #   - Label the intercepts so they can be used in the constraints\n  pos1 ~ ip1*1\n  pos2 ~ ip2*1\n  pos3 ~ ip3*1\n  neg1 ~ in1*1\n  neg2 ~ in2*1\n  neg3 ~ in3*1\n\n  # Latent means\n  POS ~ 1\n  NEG ~ 1\n\n  # Constraints\n  # For each construct:\n  #   The sum of the loadings equals the number of indicators\n  #   The sum of the intercepts equals zero\n  p1 + p2 + p3 == 3\n  n1 + n2 + n3 == 3\n\n  ip1 + ip2 + ip3 == 0\n  in1 + in2 + in3 == 0\n\"\n\n\n\nFit the model and get the summary\nAs before, the group.equal = c(\"loadings\", \"intercepts\") statement in the sem() function forces corresponding loadings and intercepts to be equal across the groups.\n\nm3_fit &lt;- sem(m3, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m3_fit, standardized = TRUE, fit.measures = TRUE)\n\nCompare the output with “Method 3” in Table 2 (pp. 64-65).\n\n\nA shortcut\nLavaan can do effects-scaling automatically - set effect.coding = TRUE in the sem() function.\n\nm3_short &lt;- \"\n  # Measurement Model\n  POS =~ pos1 + pos2 + pos3\n  NEG =~ neg1 + neg2 + neg3\n\"\n\nm3_short_fit &lt;- sem(m3_short, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, effect.coding = TRUE,\n   group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m3_short_fit, standardized = TRUE, fit.measures = TRUE)",
    "crumbs": [
      "SEMs with lavaan",
      "Scaling"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Little_2006/Little_2006.html#fit-measures",
    "href": "SEMs_with_lavaan/Little_2006/Little_2006.html#fit-measures",
    "title": "Scaling",
    "section": "Fit measures",
    "text": "Fit measures\nLS&C state that the models “produce overall model fit statistics that are identical” (p. 66). The following shows how to extract fit measures from all models presented here, and present them in a table.\n\n#  A function to extract fit measures\nGetFit &lt;- function(fit, ...) {\n   fitMeasures(fit, ...)\n}\n\n#  Add the fitted lavaan objects to a list\nmodels &lt;- list(\n   \"Method 1\"          = m1_fit,\n   \"Method 1 Shortcut\" = m1_short_fit,\n   \"Method 2c\"         = m2c_fit,\n   \"lavaan Default\"    = m2c_default_fit,\n   \"Method 3\"          = m3_fit,\n   \"Method 3 Shortcut\" = m3_short_fit)\n\n#  Select the fit measures\nmeasures &lt;- c(\"chisq\", \"df\", \"pvalue\", \"cfi\", \"tli\", \"rmsea\",\n   \"rmsea.ci.lower\", \"rmsea.ci.upper\")\n\n#  Get fit measures in a table\ntab &lt;- sapply(models, GetFit, measures)\ntab &lt;- t(round(tab, 4)); tab\n\nCompare the fit measures with those presented on page 66.\n\n\n\nR code with minimal commenting\n## Little, T., Slegers, D., & Card, N. (2006). A non-arbitrary method\n## of identifying and scaling latent variables in SEM and MACS models.\n## Structural Equation Modeling, 13(1), 59-72.\n\n## Load package\nlibrary(lavaan)\n\n## Get the data from Appendix A\n# 7th grade\ncor7 &lt;- c(\n   1.00000,\n   0.75854,  1.00000,\n   0.76214,  0.78705,  1.00000,\n   0.02766,  0.00973, -0.05762,  1.00000,\n  -0.06112, -0.06105, -0.14060,  0.78501,  1.00000,\n  -0.02222, -0.05180, -0.10250,  0.81616,  0.81076,  1.00000)\n\nmean7 &lt;- c(3.13552, 2.99061, 3.06945, 1.70069, 1.52705, 1.54483)\nsd7   &lt;- c(0.66770, 0.68506, 0.70672, 0.71418, 0.66320, 0.65276)\nn7    &lt;- 380\n\n# 8th grade\ncor8 &lt;- c(\n   1.00000,\n   0.81366,  1.00000,\n   0.84980,  0.83523,  1.00000,\n  -0.18804, -0.15524, -0.21520,  1.00000,\n  -0.28875, -0.24951, -0.33769,  0.78418,  1.00000,\n  -0.29342, -0.21022, -0.30553,  0.79952,  0.83156,  1.00000)\n\nmean8 &lt;- c(3.07338, 2.84716, 2.97882, 1.71700, 1.57955, 1.55001)\nsd8   &lt;- c(0.70299, 0.71780, 0.76208, 0.65011, 0.60168, 0.61420)\nn8    &lt;- 379\n\n## Get the variable names from Appendix A\nnames &lt;- c(\"pos1\", \"pos2\", \"pos3\", \"neg1\", \"neg2\", \"neg3\")\n\n## Combine into lists\ncor  &lt;- list(\"Grade 7\" = cor7, \"Grade 8\" = cor8)\nsd   &lt;- list(sd7, sd8)\nmean &lt;- list(mean7, mean8)\nn    &lt;- list(n7, n8)\n\n## Get the co/variance matrices\ncov &lt;- Map(getCov, x = cor, sds = sd, names = list(names, names))\n\n## The model - Reference-Group Method\nm1 &lt;- \"\n  # Measurement Model\n  #   - Free the 1st loading so it can be estimated\n  POS =~ NA*pos1 + pos2 + pos3\n  NEG =~ NA*neg1 + neg2 + neg3\n\n  # Latent variances and covariance\n  #   - Constrain latent variances to 1 in first group\n  POS ~~ c(1,NA)*POS\n  NEG ~~ c(1,NA)*NEG\n  POS ~~ NEG\n\n  # Indicator intercepts\n  pos1 ~ 1\n  pos2 ~ 1\n  pos3 ~ 1\n  neg1 ~ 1\n  neg2 ~ 1\n  neg3 ~ 1\n\n  # Latent means\n  #   - Constrain latent means to 0 in first group\n  POS ~ c(0,NA)*1\n  NEG ~ c(0,NA)*1\n\"\n\n## Fit the model and get the summary\n#  Compare with \"Method 1\" in Table 2\nm1_fit &lt;- sem(m1, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m1_fit, standardized = TRUE, fit.measures = TRUE)\n\n## Reference-Group Method - Shortcut\nm1_short &lt;- \"\n  # Measurement Model\n  POS =~ pos1 + pos2 + pos3\n  NEG =~ neg1 + neg2 + neg3\n\"\n\nm1_short_fit &lt;- sem(m1_short, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, std.lv = TRUE,\n   group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m1_short_fit, standardized = TRUE, fit.measures = TRUE)\n\n## To see all means including those set to zero\nsummary(m1_short_fit, remove.unused = FALSE, standardized = TRUE,\n   fit.measures = TRUE)\n\n## The model - Marker-Variable Method\nm2c &lt;- \"\n  # Measurement Model\n  #   - Free the 1st loading in POS so it can be estimated\n  #   - Constrain 3rd loading in POS to 1 in both groups\n  #   - Constrain 1st loading in NEG to 1 in both groups\n  POS =~ NA*pos1 + pos2 + c(1,1)*pos3\n  NEG =~ c(1,1)*neg1 + neg2 + neg3\n\n  # Latent variances and covariance\n  POS ~~ POS\n  NEG ~~ NEG\n  POS ~~ NEG\n\n  # Indicator intercepts\n  #   - Constrain 3rd intercept in POS to 0 in both groups\n  #   - Constrain 1st intercept in NEG to 0 in both groups\n  pos1 ~ 1\n  pos2 ~ 1\n  pos3 ~ c(0,0)*1\n  neg1 ~ c(0,0)*1\n  neg2 ~ 1\n  neg3 ~ 1\n\n  # Latent means\n  POS ~ 1\n  NEG ~ 1\n\"\n\n## Fit the model and get the summary\n#  Compare with \"Method 2c\" in Table 2\nm2c_fit &lt;- sem(m2c, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m2c_fit, standardized = TRUE, fit.measures = TRUE)\n\n## Lavaan default method of scaling\nm2c_default &lt;- \"\n  # Measurement Model\n  POS =~ pos1 + pos2 + pos3\n  NEG =~ neg1 + neg2 + neg3\n\"\n\nm2c_default_fit &lt;- sem(m2c_default, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m2c_default_fit, remove.unused = FALSE,\n   standardized = TRUE, fit.measures = TRUE)\n\n## The model - Effects-Scaling Method\nm3 &lt;- \"\n  # Measurement Model\n  #   - Free the 1st loading so it can be estimated\n  #   - Label the loadings so they can be used in the constraints\n  POS =~ NA*p1*pos1 + p2*pos2 + p3*pos3\n  NEG =~ NA*n1*neg1 + n2*neg2 + n3*neg3\n\n  # Latent variances and covariance\n  POS ~~ POS\n  NEG ~~ NEG\n  POS ~~ NEG\n\n  # Indicator intercepts\n  #   - Label the intercepts so they can be used in the constraints\n  pos1 ~ ip1*1\n  pos2 ~ ip2*1\n  pos3 ~ ip3*1\n  neg1 ~ in1*1\n  neg2 ~ in2*1\n  neg3 ~ in3*1\n\n  # Latent means\n  POS ~ 1\n  NEG ~ 1\n\n  # Constraints\n  # For each construct:\n  #   The sum of the loadings equals the number of indicators\n  #   The sum of the intercepts equals zero\n  p1 + p2 + p3 == 3\n  n1 + n2 + n3 == 3\n\n  ip1 + ip2 + ip3 == 0\n  in1 + in2 + in3 == 0\n\"\n\n## Fit the model and get the summary\n#  Compare with \"Method 3\" in Table 2\nm3_fit &lt;- sem(m3, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m3_fit, standardized = TRUE, fit.measures = TRUE)\n\n## Effects-Scaling Method - Shortcut\nm3_short &lt;- \"\n  # Measurement Model\n  POS =~ pos1 + pos2 + pos3\n  NEG =~ neg1 + neg2 + neg3\n\"\n\nm3_short_fit &lt;- sem(m3_short, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, effect.coding = TRUE,\n   group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m3_short_fit, standardized = TRUE, fit.measures = TRUE)\n\n## Get fit measures\n#  A function to extract fit measures\nGetFit &lt;- function(fit, ...) {\n   fitMeasures(fit, ...)\n}\n\n#  Add the fitted lavaan objects to a list\nmodels &lt;- list(\n   \"Method 1\"          = m1_fit,\n   \"Method 1 Shortcut\" = m1_short_fit,\n   \"Method 2c\"         = m2c_fit,\n   \"lavaan Default\"    = m2c_default_fit,\n   \"Method 3\"          = m3_fit,\n   \"Method 3 Shortcut\" = m3_short_fit)\n\n#  Select the fit measures\nmeasures &lt;- c(\"chisq\", \"df\", \"pvalue\", \"cfi\", \"tli\", \"rmsea\",\n   \"rmsea.ci.lower\", \"rmsea.ci.upper\")\n\n#  Get fit measures in a table\ntab &lt;- sapply(models, GetFit, measures)\ntab &lt;- t(round(tab, 4)); tab",
    "crumbs": [
      "SEMs with lavaan",
      "Scaling"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Green_2023/one_way_ANCOVA.html",
    "href": "SEMs_with_lavaan/Green_2023/one_way_ANCOVA.html",
    "title": "One-Way ANCOVA",
    "section": "",
    "text": "Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\nThis example shows the SEM approach to a one-way ANCOVA. Results are reported in Table 21.2 (p. 393).\nThe data file needs rearranging before it can be used: the format needs to be changed from “long” to “wide”, and the pre or before Life-Satisfaction scores need to be centered.\n\nLoad package and get the data\nLoad the lavaan packages, and run satisfactionI.r and ANOVA_data.r to get and rearrange the data.\n\nlibrary(lavaan)\n\nsource(\"satisfactionI.r\")\nhead(df)\n\nsource(\"ANOVA_data.r\")\nhead(df)\n\nThe variables used in this example are:\n\nx - Coping Strategy (“a” - no strategy; “b” - discussion; “c” - exercise)\ny - dependent variable (“after” Life-Satisfaction scores)\npreC - pre-Life-Satisfaction grand mean centered\n\nThe steps are the same as with the one_way_ANOVA. The only difference is the addition of the covariate, preC.\n\n\nThe models\nThe SEM model for one-way ANCOVA is shown below. The diagram shows the “Less Constrained” model - the three means, represented by the labels on the arrows connecting the “1” to the dependent variable, differ. To be consistent with the ANCOVA assumptions of homogeneity of variances and homogeneity of regression slopes, the residual variances and the coefficients for the covariate (preC) are each constrained to equality.\n\n\n\n\n\nThe model statements are shown below. The “More Constrained” model constrains the means to equality. The “Less Constrained” model allows the means to differ across the groups. In both cases the residual variances and the coefficients for the covariate are constrained to equality.\n\nmodels &lt;- list(\n  \"More Constrained\" =\n    \"y ~  c(a, a, a)*1        # Means\n     y ~  c(b, b, b)*preC     # Regression slopes\n     y ~~ c(e, e, e)*y        # Variances\",\n\n  \"Less Constrained\" =\n    \"y ~  c(a1, a2, a3)*1\n     y ~  c(b, b, b)*preC\n     y ~~ c(e, e, e)*y\"\n)\n\n\n\nFit the models and get the results\nThe lapply() function applies the sem() function to the two elements of the models list (with data set to df, and group set to the \"x\" variable).\n\nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\nlapply(fit, summary)\n\nThe “SEM” sections of Table 21.2 show the means, pooled error variances, and the \\(\\upchi\\)2 test; the footnote to Table 21.2 gives the regression coefficients.\nScroll through the summaries to find the “Intercepts”, “Variances”, and “Regressions”; or extract them from the list of estimates of model parameters.\n\n## Get list of estimates\nestimates &lt;- lapply(fit, lavInspect, \"est\"); estimates\n\n## Extract means - in element \"alpha\"\nmeans &lt;- list()\nfor (i in names(models)){\n   means[[i]] &lt;- estimates[[i]] |&gt;\n      lapply(\"[[\", \"alpha\") |&gt;       # Means for Y and preC\n      sapply(\"[[\", 1)                # Means for Y\n}\nmeans &lt;- do.call(cbind, means); means\n\n## Extract error variances -  in element \"psi\"\nErrorVar &lt;- list()\nfor (i in names(models)){\n   ErrorVar[[i]] &lt;- estimates[[i]] |&gt;\n      lapply(\"[[\", \"psi\")  |&gt;        # Extract \"psi\" element\n      sapply(\"[[\", 1, 1)             # 1st row, 1st column of \"psi\"\n}\nErrorVar &lt;- do.call(cbind, ErrorVar); ErrorVar\n\n## Extract regression coefficients -  in element \"beta\"\nRegCoef &lt;- list()\nfor (i in names(models)){\n   RegCoef[[i]] &lt;- estimates[[i]] |&gt;\n      lapply(\"[[\", \"beta\")  |&gt;       # Extract \"beta\" element\n      sapply(\"[[\", 1, 2)             # 1st row, 2nd column of \"beta\"\n}\nRegCoef &lt;- do.call(cbind, RegCoef); RegCoef\n\nTo perform the \\(\\upchi\\)2 test (to compare the fit of the two models), apply the anova() function to the two models.\n\nReduce(anova, fit)\n\nCompare with the \\(\\upchi\\)2 statistic and p value in Table 21.2.\nIn Equation 21.9 (p. 394), TLG give calculations for R2. As was the case with the one-way ANOVA, the relevant SSEs can be obtained from the error variances (see ErrorVar) by multiplying error variance by sample size. But again, the multiplication is not needed because sample size will cancel out; that is, substitute the error variances into Equation 21.9.\n\nRsquare &lt;- ErrorVar[\"a\", ] |&gt;\n   Reduce(function(mc, lc) (mc - lc)/mc, x = _)  # Substitute into Eq 21.9\nRsquare\n\n\n\n\nR code with minimal commenting\n## One-way ANCOVA\n##\n## Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling\n## approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural\n## equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\n\n## Load package\nlibrary(lavaan)\n\n## Get the data\nsource(\"satisfactionI.r\")\nhead(df)\n\n## Rearrange the data file\nsource(\"ANOVA_data.r\")\nhead(df)\n\n## The models\nmodels &lt;- list(\n  \"More Constrained\" =\n    \"y ~  c(a, a, a)*1        # Means\n     y ~  c(b, b, b)*preC     # Regression slopes\n     y ~~ c(e, e, e)*y        # Variances\",\n\n  \"Less Constrained\" =\n    \"y ~  c(a1, a2, a3)*1\n     y ~  c(b, b, b)*preC\n     y ~~ c(e, e, e)*y\"\n)\n\n## Fit the models\nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n## Get model summaries\n## Check results with \"SEM\" section of Table 21.2\nlapply(fit, summary)\n\n## Extract means, variances, and regression coefficients from list of estimates\n## Get list of estimates\nestimates &lt;- lapply(fit, lavInspect, \"est\"); estimates\n\n## Extract means - in element \"alpha\"\nmeans &lt;- list()\nfor (i in names(models)){\n   means[[i]] &lt;- estimates[[i]] |&gt;\n      lapply(\"[[\", \"alpha\") |&gt;       # Means for Y and preC\n      sapply(\"[[\", 1)                # Means for Y\n}\nmeans &lt;- do.call(cbind, means); means\n\n## Extract error variances -  in element \"psi\"\nErrorVar &lt;- list()\nfor (i in names(models)){\n   ErrorVar[[i]] &lt;- estimates[[i]] |&gt;\n      lapply(\"[[\", \"psi\")  |&gt;        # Extract \"psi\" element\n      sapply(\"[[\", 1, 1)             # 1st row, 1st column of \"psi\"\n}\nErrorVar &lt;- do.call(cbind, ErrorVar); ErrorVar\n\n## Extract regression coefficients -  in element \"beta\"\nRegCoef &lt;- list()\nfor (i in names(models)){\n   RegCoef[[i]] &lt;- estimates[[i]] |&gt;\n      lapply(\"[[\", \"beta\")  |&gt;       # Extract \"beta\" element\n      sapply(\"[[\", 1, 2)             # 1st row, 2nd column of \"beta\"\n}\nRegCoef &lt;- do.call(cbind, RegCoef); RegCoef\n\n## Contrast model fits\n## Check with chi sq statistic and p value in Table 21.2\nReduce(anova, fit)\n\n## R square\n## Check with Equation 21.9\nRsquare &lt;- ErrorVar[\"a\", ] |&gt;\n   Reduce(function(mc, lc) (mc - lc)/mc, x = _)  # Substitute into Eq 21.9\nRsquare\n\n\n\n\nR code to get data file - satisfactionI.r\n### Data for Tables 21.1, 21.2, 21.3, 21.4 ###\n\ndf &lt;- structure(list(x = c(\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\"), g = c(\"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \n\"m\", \"m\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \n\"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \n\"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\"), \n    c = c(\"before\", \"before\", \"before\", \"before\", \"before\", \"before\", \n    \"before\", \"before\", \"before\", \"after\", \"after\", \"after\", \n    \"after\", \"after\", \"after\", \"after\", \"after\", \"after\", \"before\", \n    \"before\", \"before\", \"before\", \"before\", \"before\", \"after\", \n    \"after\", \"after\", \"after\", \"after\", \"after\", \"before\", \"before\", \n    \"before\", \"before\", \"before\", \"before\", \"before\", \"before\", \n    \"before\", \"after\", \"after\", \"after\", \"after\", \"after\", \"after\", \n    \"after\", \"after\", \"after\"), y = c(21, 19, 22, 21, 24, 23, \n    21, 24, 23, 22, 22, 24, 25, 27, 30, 22, 23, 24, 23, 23, 21, \n    19, 22, 21, 30, 26, 22, 25, 26, 27, 27, 25, 24, 25, 23, 22, \n    23, 28, 26, 34, 30, 26, 26, 27, 28, 29, 40, 42)), class = \"data.frame\", row.names = c(NA, \n-48L))\n\n\nhead(df)\n\n## x - Coping Strategy (a - No strategy; b - Discussion; c - Exercise)\n## g - Gender\n## c - before/after \n## y - dependent variable (Life Satisfaction)\n\n\n\n\nR code to rearrange data file - ANOVA_data.r\n### Data for Tables 21.1, 21.2, 21.3, 21.4 ###\n\n## Reshape data - long to wide\ntab &lt;- 0.5 * table(df$x)  # in each condition\ndf$id &lt;- c(rep(1:tab[1], 2), rep(1:tab[2], 2), rep(1:tab[3], 2))  # id variable \n\ndf &lt;- reshape(df, timevar = \"c\", idvar = c(\"id\", \"x\", \"g\"), varying = c(\"pre\", \"y\"), \n   direction = \"wide\")\n\n\ndf &lt;- within(df, {\n## Grand mean centered \"pre\" - the before scores\n   preC &lt;- scale(pre, scale = FALSE)\n\n## Dummy variables for \"Coping Startegy\"\n   x1 &lt;- ifelse(x == \"a\", 1, 0)\n   x2 &lt;- ifelse(x == \"b\", 1, 0)\n   x3 &lt;- ifelse(x == \"c\", 1, 0)\n\n## Drop the id variable\n   id &lt;- NULL\n\n## Gender X Coping Strategy interaction\n  sg &lt;- interaction(x, g, sep = \"\")\n\n## Dummy variables for interaction\n  dummies &lt;- model.matrix(~ sg - 1)\n})\n\n## Unnest the nested 'dummies' matrix, and rename its colomns\ndf &lt;- do.call(data.frame, df)\nnames(df) &lt;- gsub(\"dummies.sg\", \"\", names(df))",
    "crumbs": [
      "SEMs with lavaan",
      "Means",
      "One-Way ANCOVA"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Green_2023/one_way_ANOVA.html",
    "href": "SEMs_with_lavaan/Green_2023/one_way_ANOVA.html",
    "title": "One-Way ANOVA",
    "section": "",
    "text": "Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\nThis example shows the SEM approach to a one-way ANOVA. Results are reported in Table 21.1 (p. 389).\nThe data are described at the top of page 388. Thompson, Lie & Green (TLG) claim that the data are available in supplementary materials but I’m unable to locate it. However, the data are available in Mplus data files in supplementary materials for the 1st edition. I’ve collected the data into a more convenient format (see the next section for getting the data), but it is in a “long” format. It needs to be rearranged from “long” to “wide”.\n\nLoad package and get the data\nLoad the lavaan package, and run satisfactionI.r and ANOVA_data.r to get and rearrange the data (satisfactionI.r and ANOVA_data.r are available at the end of this post). The data will be in the df data frame.\n\nlibrary(lavaan)\n\nsource(\"satisfactionI.r\")\nhead(df)\n\nsource(\"ANOVA_data.r\")\nhead(df)\n\nThe variables used in this example are:\n\nx - Coping Strategy (“a” - no strategy; “b” - discussion; “c” - exercise)\ny - dependent variable (“after” Life-Satisfaction scores)\n\n\n\nThe models\nThe SEM model for one-way ANOVA is shown in Fig 21.1 (p. 391), and is reproduced below. The diagram shows the “Less Constrained” model - the three means, represented by the labels on the arrows connecting the “1” to the dependent variable, differ. To be consistent with the ANOVA assumption of homogeneity of variances, the residual variances are constrained to be equal.\n\n\n\n\n\nTwo models are fitted. The model statements are shown below. The “More Constrained” model constrains the means (each with the same label “a”) to equality. The “Less Constrained” model allows the means (represented by the labels “a1”, “a2”, and “a3”) to differ across the groups. (Alternatively, this line could have been written as y ~ 1; that is, with no label, the means are freely estimated in each group. I leave the labels in to be consistent with the diagram of the model.) In both models the residual variances (each with the same label “e”) are constrained to equality.\nIn what follows, I use lists. The model statements are placed into a list, then I use the lapply() or sapply() function to perform operations on each element in the list (such as sem() to run the analyses, or summary() to return summaries of the analyses, or [[ to extract elements); and I use the Reduce() function when I need to perform operations across the two models (such as anova() to constrast the fit of the two models).\n\nmodels &lt;- list(\n  \"More Constrained\" =\n    \"y ~  c(a, a, a)*1     # Means\n     y ~~ c(e, e, e)*y     # Variances\",\n\n  \"Less Constrained\" =\n    \"y ~  c(a1, a2, a3)*1\n     y ~~ c(e, e, e)*y\"\n)\n\n\n\nFit the models and get the results\nThe lapply() function applies the sem() function to the two elements of the models list (with data set to df, and group set to the \"x\" variable).\n\nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\nlapply(fit, summary)\n\nThe “SEM” sections of Table 21.1 show the means, pooled error variances, and the \\(\\upchi\\)2 test.\nThe summaries show “Intercepts” (that is, the estimated means) and “Variances” (that is, the error variances) for each “Coping Strategy” group for both models. Compare with means and pooled error variances in the SEM section in Table 21.1.\nRather than, or perhaps, as well as, searching through the model summaries for the means and variances, they can be extracted from a list of estimates of model parameters.\n\n## Get list of estimates\nestimates &lt;- lapply(fit, lavInspect, \"est\"); estimates\n\n## Extract means - in element \"nu\"\nmeans &lt;- list()\nfor (i in names(models)) {\n   means[[i]] &lt;- estimates[[i]] |&gt;\n      sapply(\"[[\", \"nu\")\n}\nmeans &lt;- do.call(cbind, means); means\n\n## Extract error variances - in element \"theta\"\nErrorVar &lt;- list()\nfor (i in names(models)) {\n   ErrorVar[[i]] &lt;- estimates[[i]] |&gt;\n      sapply(\"[[\", \"theta\")\n}\nErrorVar &lt;- do.call(cbind, ErrorVar); ErrorVar\n\nTo perform the \\(\\upchi\\)2 test (to compare the fit of the two models), apply the anova() function to the two models.\n\nReduce(anova, fit)\n\nCompare with the \\(\\upchi\\)2 statistic and p value in Table 21.1.\nOn page 390, TLG give model fit statistics for both models. These are available in the anova output above, or they can be extracted separately from the list of fit measures. First, a function to extract the \\(\\upchi\\)2 statistic, degrees of freedom, and the p value, then that function is applied to both models.\n\nGetFit &lt;- function(fit) {\n   tab &lt;- fitMeasures(fit, c(\"chisq\", \"df\", \"pvalue\"))\n   tab &lt;- round(tab, 3)\n   return(tab)\n}\n\nsapply(fit, GetFit)\n\nNote: Neither model fits well.\nTLG mention the calculation for R2 (p. 390). The relevant SSEs can be obtained from the error variances (see ErrorVar) by multiplying error variance by sample size. However, note that multiplication is not needed because sample size will cancel out; that is, substitute the error variances into Equation 21.4.\n\nRsquare &lt;- ErrorVar[\"a\", ] |&gt;\n   Reduce(function(mc, lc) (mc - lc)/mc, x = _)  # Substitute into Eq 21.4\nRsquare\n\n\n\nRelaxing assumption of homogeneity of variances\nTLG do not run these models though they make reference to them. The model statements when the homogeneity of variances assumption is relaxed are shown below.\n\nmodels &lt;- list(\n  \"More Constrained\" =\n    \"y ~  c(a, a, a)*1         # Means\n     y ~~ c(e1, e2, e3)*y      # Variances\",\n\n  \"Less Constrained\" =\n    \"y ~  c(a1, a2, a3)*1\n     y ~~ c(e1, e2, e3)*y\"\n)\n\nRun the models and get the summaries. In this analysis I use the “mlm” estimator, a robust ML estimator; that is, the normality assumption is relaxed also.\n\nfit &lt;- lapply(models, sem, data = df, group = \"x\", estimator = \"mlm\")\nlapply(fit, summary)\n\nThis time, the “Less Constrained” model is just identified - a perfect fit.\n\n\n\nR code with minimal commenting\n## One-way ANOVA\n##\n## Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling\n## approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural\n## equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\n\n## Load package\nlibrary(lavaan)\n\n## Get the data\nsource(\"satisfactionI.r\")\nhead(df)\n\n## Rearrange the data file\nsource(\"ANOVA_data.r\")\nhead(df)\n\n## The models\nmodels &lt;- list(\n  \"More Constrained\" =\n    \"y ~  c(a, a, a)*1     # Means\n     y ~~ c(e, e, e)*y     # Variances\",\n\n  \"Less Constrained\" =\n    \"y ~  c(a1, a2, a3)*1\n     y ~~ c(e, e, e)*y\"\n)\n\n## Fit the models\nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n## Get model summaries\n## Check results with \"SEM\" section of Table 21.1\nlapply(fit, summary)\n\n## Extract means and variances from list of estimates\n## Get list of estimates\nestimates &lt;- lapply(fit, lavInspect, \"est\"); estimates\n\n## Extract means - in element \"nu\"\nmeans &lt;- list()\nfor (i in names(models)) {\n   means[[i]] &lt;- estimates[[i]] |&gt;\n      sapply(\"[[\", \"nu\")\n}\nmeans &lt;- do.call(cbind, means); means\n\n## Extract error variances - in element \"theta\"\nErrorVar &lt;- list()\nfor (i in names(models)) {\n   ErrorVar[[i]] &lt;- estimates[[i]] |&gt;\n      sapply(\"[[\", \"theta\")\n}\nErrorVar &lt;- do.call(cbind, ErrorVar); ErrorVar\n\n## Contrast model fits\n## Check with chi sq statistic and p value in Table 21.1\nReduce(anova, fit)\n\n## Fit for each model - Chi squares\n## Check with values on page 390\n## First, a function to extract chi squares\nGetFit &lt;- function(fit) {\n   tab &lt;- fitMeasures(fit, c(\"chisq\", \"df\", \"pvalue\"))\n   tab &lt;- round(tab, 3)\n   return(tab)\n}\n\nsapply(fit, GetFit)\n\n## R square\n## Check with Equation 21.4\nRsquare &lt;- ErrorVar[\"a\", ] |&gt;\n   Reduce(function(mc, lc) (mc - lc)/mc, x = _)  # Substitute into Eq 21.4\nRsquare\n\n## Relax homogeneity of variances assumption\nmodels &lt;- list(\n  \"More Constrained\" =\n    \"y ~  c(a, a, a)*1         # Means\n     y ~~ c(e1, e2, e3)*y      # Variances\",\n\n  \"Less Constrained\" =\n    \"y ~  c(a1, a2, a3)*1\n     y ~~ c(e1, e2, e3)*y\"\n)\n\n## Run the model and get the summary\nfit &lt;- lapply(models, sem, data = df, group = \"x\", estimator = \"mlm\")\nlapply(fit, summary)\n\n\n\n\nR code to get data file - satisfactionI.r\n### Data for Tables 21.1, 21.2, 21.3, 21.4 ###\n\ndf &lt;- structure(list(x = c(\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\"), g = c(\"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \n\"m\", \"m\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \n\"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \n\"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\"), \n    c = c(\"before\", \"before\", \"before\", \"before\", \"before\", \"before\", \n    \"before\", \"before\", \"before\", \"after\", \"after\", \"after\", \n    \"after\", \"after\", \"after\", \"after\", \"after\", \"after\", \"before\", \n    \"before\", \"before\", \"before\", \"before\", \"before\", \"after\", \n    \"after\", \"after\", \"after\", \"after\", \"after\", \"before\", \"before\", \n    \"before\", \"before\", \"before\", \"before\", \"before\", \"before\", \n    \"before\", \"after\", \"after\", \"after\", \"after\", \"after\", \"after\", \n    \"after\", \"after\", \"after\"), y = c(21, 19, 22, 21, 24, 23, \n    21, 24, 23, 22, 22, 24, 25, 27, 30, 22, 23, 24, 23, 23, 21, \n    19, 22, 21, 30, 26, 22, 25, 26, 27, 27, 25, 24, 25, 23, 22, \n    23, 28, 26, 34, 30, 26, 26, 27, 28, 29, 40, 42)), class = \"data.frame\", row.names = c(NA, \n-48L))\n\n\nhead(df)\n\n## x - Coping Strategy (a - No strategy; b - Discussion; c - Exercise)\n## g - Gender\n## c - before/after \n## y - dependent variable (Life Satisfaction)\n\n\n\n\nR code to rearrange data file - ANOVA_data.r\n### Data for Tables 21.1, 21.2, 21.3, 21.4 ###\n\n## Reshape data - long to wide\ntab &lt;- 0.5 * table(df$x)  # in each condition\ndf$id &lt;- c(rep(1:tab[1], 2), rep(1:tab[2], 2), rep(1:tab[3], 2))  # id variable \n\ndf &lt;- reshape(df, timevar = \"c\", idvar = c(\"id\", \"x\", \"g\"), varying = c(\"pre\", \"y\"), \n   direction = \"wide\")\n\n\ndf &lt;- within(df, {\n## Grand mean centered \"pre\" - the before scores\n   preC &lt;- scale(pre, scale = FALSE)\n\n## Dummy variables for \"Coping Startegy\"\n   x1 &lt;- ifelse(x == \"a\", 1, 0)\n   x2 &lt;- ifelse(x == \"b\", 1, 0)\n   x3 &lt;- ifelse(x == \"c\", 1, 0)\n\n## Drop the id variable\n   id &lt;- NULL\n\n## Gender X Coping Strategy interaction\n  sg &lt;- interaction(x, g, sep = \"\")\n\n## Dummy variables for interaction\n  dummies &lt;- model.matrix(~ sg - 1)\n})\n\n## Unnest the nested 'dummies' matrix, and rename its colomns\ndf &lt;- do.call(data.frame, df)\nnames(df) &lt;- gsub(\"dummies.sg\", \"\", names(df))",
    "crumbs": [
      "SEMs with lavaan",
      "Means",
      "One-Way ANOVA"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Green_2023/two_way_ANOVA.html",
    "href": "SEMs_with_lavaan/Green_2023/two_way_ANOVA.html",
    "title": "Two-Way ANOVA",
    "section": "",
    "text": "Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\nThis example shows the SEM approach to a two-way ANOVA. Results are reported in Tables 21.3 and 21.4 (pp. 395, 396).\nThe data file needs rearranging before it can be used: the format needs to be changed from “long” to “wide”, and the Gender X Coping Strategy interaction needs a grouping variable set up.\n\nLoad packages and get the data\nLoad the relevant packages, and run satisfactionI.r and ANOVA_data.r to get and rearrange the data.\n\nlibrary(lavaan)\nlibrary(DescTools)    # Cramer's V\n\nsource(\"satisfactionI.r\")\nhead(df)\n\nsource(\"ANOVA_data.r\")\nhead(df)\n\nThe variables used in this example are:\n\nx - Coping Strategy (“a” - no strategy; “b” - discussion; “c” - exercise)\ng - Gender\ny - dependent variable (“after” Life-Satisfaction scores)\nsg - Gender X Coping Strategy interaction\n\n\n\nPreliminary results - Cramer’s V\nOn page 394, TLG give Cramer’s V for the Gender X Coping Strategy crosstabulation. As far as I know, Cramer’s V is not available in base R, but DescTools is one of possibly many packages that has a function for Cramer’s V.\n\nDescTools::CramerV(df$g, df$x)\n\nHowever, it is easy to calculate Cramer’s V without the need for the extra package, given the formula:\n\\[\n\\mathsf{Cramer's ~ V} = \\sqrt{\\frac{\\upchi^2 / n}{\\min(r-1, ~ c-1)}}\n\\]\nwhere \\(n\\) is the sample size, \\(r\\) is the number of rows, and \\(c\\) is the number of columns.\n\nchisq &lt;- unname(chisq.test(df$g, df$x)$statistic)\nn &lt;- nrow(df)               # Sample size\nr &lt;- length(unique(df$g))   # Number of rows\nc &lt;- length(unique(df$x))   # Number of columns\n\nCV &lt;- sqrt((chisq/n)/min(r-1, c-1)); CV\n\nStandardised residuals will give the direction of the relationship (p. 394).\n\nchisq.test(df$g, df$x)$stdres\n\n\n\nPreliminary results - Gender X Coping Strategy crosstabulation\nTable 21.3 (p. 395) gives the cell means and frequecies, and the weighted and unweighted marginal means.\nGet the cell means and frequencies.\n\nmeans &lt;- with(df, tapply(y, list(g, x), mean)); means     # Cell means\nfreq  &lt;- with(df, table(g, x)); freq                      # Cell frequencies\n\nGet the unweighted and weighted marginal means.\n\n# Unweighted marginal means\napply(means, 1, mean)      # Gender\napply(means, 2, mean)      # Coping Strategy\n \n# Weighted marginal means\nwith(df, tapply(y, g, mean))     # Gender\nwith(df, tapply(y, x, mean))     # Coping Strategy\n\n\n\nThe models\nThe SEM model for two-way ANOVA is shown below. The diagram shows the “Less Constrained” model - the six means, represented by the label on the arrows connecting the “1” to the dependent variable, differ. To be consistent with the ANOVA assumption of homogeneity of variances, the residual variances are constrained to be equal.\n\n\n\n\n\nThe model statements are shown below. The “Less Constrained” model allows the means (represented by the labels, am, af, …, cf) to differ across the groups. The constraints statements are added to the “Less Constrained” statement to give the “More Constrained” models. The “More Constrained” models are contrasted with the “Less Constrained” model to test for the Gender and Coping Strategy main effects (weighted and unweighted) and the Gender X Coping Strategy interaction. In each case the residual variances are constrained to equality.\nConstraint for the unweighted Gender main effect - Restrict the mean for males to equal the mean for females. But there are three means for females, one for each Coping Strategy group. Similarly, there are three means for males. Simply constrain the sum of the three means for males to equal the sum of the three means for females.\nConstraints for the unweighted Coping Strategy main effect - Restrict the mean for “a” strategy to equal the mean for “b” strategy to equal the mean for “c” strategy. That is, constrain the sum of the two “a” means to equal the sum of the two “b” means; and the sum of the two “b” means to equal the sum of the two “c” means.\nTo test for the main effects applied to weighted means, the constraints are set the same way as before except the means are weighted in proportion to the cell frequencies.\nConstraints for the Gender X Coping Strategy interaction - The “More Constrained” model needs the means to be constrained so that the difference between the mean for “female” and the mean for “male” remains constant across levels of “Coping Strategy”. That is: the difference between “female” mean and “male” mean for the “a” strategy equals the difference between “female” mean and “male” mean for the “b” strategy; and the difference between “female” mean and “male” mean for the “b” strategy equals the difference between “female” mean and “male” mean for the “c” strategy.\n\n## Less Constrained model\nlc &lt;- \"y ~  c(am, af, bm, bf, cm, cf)*1      # Means\n       y ~~ c(e, e, e, e, e, e)*y            # Variances\"\n\nlc.fit &lt;- sem(lc, data = df, group = \"sg\")\nsummary(lc.fit)\n\n## Gender main effect - unweighted means\nconstraints &lt;- \"af + bf + cf == am + bm + cm\"\ngend_unw &lt;- c(lc, constraints)\n\ngend_unw.fit &lt;- sem(gend_unw, data = df, group = \"sg\")\nsummary(gend_unw.fit)\n\nanova(gend_unw.fit, lc.fit)   # Compare the two models\n\n## Coping Strategy main effect - unweighted means\nconstraints &lt;- \n  \"af + am == bf + bm \n   af + am == cf + cm\"\nstrat_unw &lt;- c(lc, constraints)\n\nstrat_unw.fit &lt;- sem(strat_unw, data = df, group = \"sg\")\nsummary(strat_unw.fit)\n\nanova(strat_unw.fit, lc.fit)   # Compare the two models\n\n## Gender main effect - weighted means\nfreq                     # To assist with constructing constraints\nconstraints &lt;- \"(3*af + 3*bf + 6*cf)/12 == (6*am + 3*bm + 3*cm)/12\"\ngend_w &lt;- c(lc, constraints)\n\ngend_w.fit &lt;- sem(gend_w, data = df, group = \"sg\")\nsummary(gend_w.fit)\n\nanova(gend_w.fit, lc.fit)   # Compare the two models\n\n## Coping Strategy main effect - weighted means\n## Compare with SEM section in Table 21.4\nfreq\nconstraints &lt;- \n  \"(3*af + 6*am)/9 == (3*bf + 3*bm)/6 \n   (3*bf + 3*bm)/6 == (6*cf + 3*cm)/9\"\nstrat_w &lt;- c(lc, constraints)\n\nstrat_w.fit &lt;- sem(strat_w, data = df, group = \"sg\")\nsummary(strat_w.fit)\n\nanova(strat_w.fit, lc.fit)   # Compare the two models\n\n## Gender X Coping Strategy interaction\nconstraints &lt;- \n  \"(af - am) == (bf - bm)\n   (bf - bm) == (cf - cm)\"\ninter &lt;- c(lc, constraints)\n\ninter.fit &lt;- sem(inter, data = df, group = \"sg\")\nsummary(inter.fit)\n\nanova(inter.fit, lc.fit)     # Compare the two models\n\n\n\n\nR code with minimal commenting\n## Two-way ANOVA\n##\n## Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling\n## approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural\n## equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\n\n## Load packages\nlibrary(lavaan)\nlibrary(DescTools)    # Cramer's V\n\n## Get the data\nsource(\"satisfactionI.r\")\nhead(df)\n\n## Rearrange the data file\nsource(\"ANOVA_data.r\")\nhead(df)\n\n## Cramer's V\n## Check with page 394\nDescTools::CramerV(df$g, df$x)\n\n## Cramer's V by hand\nchisq &lt;- unname(chisq.test(df$g, df$x)$statistic)\nn &lt;- nrow(df)               # Sample size\nr &lt;- length(unique(df$g))   # Number of rows\nc &lt;- length(unique(df$x))   # Number of columns\n\nCV &lt;- sqrt((chisq/n)/min(r-1, c-1)); CV\n\n## Direction of the relationship\nchisq.test(df$g, df$x)$stdres\n\n## Cell means and cell frequencies\n## Check cell means and frequencies in Table 21.3\nmeans &lt;- with(df, tapply(y, list(g, x), mean)); means     # Cell means\nfreq  &lt;- with(df, table(g, x)); freq                      # Cell frequencies\n\n## Check unweighted and weighted means in Table 21.3\n# Unweighted marginal means\napply(means, 1, mean)      # Gender\napply(means, 2, mean)      # Coping Strategy\n\n# Weighted marginal means\nwith(df, tapply(y, g, mean))     # Gender\nwith(df, tapply(y, x, mean))     # Coping Strategy\n\n## Less Constrained model\nlc &lt;- \"y ~  c(am, af, bm, bf, cm, cf)*1      # Means\n       y ~~ c(e, e, e, e, e, e)*y            # Variances\"\n\nlc.fit &lt;- sem(lc, data = df, group = \"sg\")\nsummary(lc.fit)\n\n## Gender main effect - unweighted means\nconstraints &lt;- \"af + bf + cf == am + bm + cm\"\ngend_unw &lt;- c(lc, constraints)\n\ngend_unw.fit &lt;- sem(gend_unw, data = df, group = \"sg\")\nsummary(gend_unw.fit)\n\nanova(gend_unw.fit, lc.fit)   # Compare the two models\n\n## Coping Strategy main effect - unweighted means\nconstraints &lt;-\n  \"af + am == bf + bm\n   af + am == cf + cm\"\nstrat_unw &lt;- c(lc, constraints)\n\nstrat_unw.fit &lt;- sem(strat_unw, data = df, group = \"sg\")\nsummary(strat_unw.fit)\n\nanova(strat_unw.fit, lc.fit)   # Compare the two models\n\n## Gender main effect - weighted means\nfreq                     # To assist with constructing constraints\nconstraints &lt;- \"(3*af + 3*bf + 6*cf)/12 == (6*am + 3*bm + 3*cm)/12\"\ngend_w &lt;- c(lc, constraints)\n\ngend_w.fit &lt;- sem(gend_w, data = df, group = \"sg\")\nsummary(gend_w.fit)\n\nanova(gend_w.fit, lc.fit)   # Compare the two models\n\n## Coping Strategy main effect - weighted means\n## Compare with SEM section in Table 21.4\nfreq\nconstraints &lt;-\n  \"(3*af + 6*am)/9 == (3*bf + 3*bm)/6\n   (3*bf + 3*bm)/6 == (6*cf + 3*cm)/9\"\nstrat_w &lt;- c(lc, constraints)\n\nstrat_w.fit &lt;- sem(strat_w, data = df, group = \"sg\")\nsummary(strat_w.fit)\n\nanova(strat_w.fit, lc.fit)   # Compare the two models\n\n## Gender X Coping Strategy interaction\nconstraints &lt;-\n  \"(af - am) == (bf - bm)\n   (bf - bm) == (cf - cm)\"\ninter &lt;- c(lc, constraints)\n\ninter.fit &lt;- sem(inter, data = df, group = \"sg\")\nsummary(inter.fit)\n\nanova(inter.fit, lc.fit)     # Compare the two models\n\n\n\n\nR code to get data file - satisfactionI.r\n### Data for Tables 21.1, 21.2, 21.3, 21.4 ###\n\ndf &lt;- structure(list(x = c(\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\"), g = c(\"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \n\"m\", \"m\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \n\"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \n\"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\"), \n    c = c(\"before\", \"before\", \"before\", \"before\", \"before\", \"before\", \n    \"before\", \"before\", \"before\", \"after\", \"after\", \"after\", \n    \"after\", \"after\", \"after\", \"after\", \"after\", \"after\", \"before\", \n    \"before\", \"before\", \"before\", \"before\", \"before\", \"after\", \n    \"after\", \"after\", \"after\", \"after\", \"after\", \"before\", \"before\", \n    \"before\", \"before\", \"before\", \"before\", \"before\", \"before\", \n    \"before\", \"after\", \"after\", \"after\", \"after\", \"after\", \"after\", \n    \"after\", \"after\", \"after\"), y = c(21, 19, 22, 21, 24, 23, \n    21, 24, 23, 22, 22, 24, 25, 27, 30, 22, 23, 24, 23, 23, 21, \n    19, 22, 21, 30, 26, 22, 25, 26, 27, 27, 25, 24, 25, 23, 22, \n    23, 28, 26, 34, 30, 26, 26, 27, 28, 29, 40, 42)), class = \"data.frame\", row.names = c(NA, \n-48L))\n\n\nhead(df)\n\n## x - Coping Strategy (a - No strategy; b - Discussion; c - Exercise)\n## g - Gender\n## c - before/after \n## y - dependent variable (Life Satisfaction)\n\n\n\n\nR code to rearrange data file - ANOVA_data.r\n### Data for Tables 21.1, 21.2, 21.3, 21.4 ###\n\n## Reshape data - long to wide\ntab &lt;- 0.5 * table(df$x)  # in each condition\ndf$id &lt;- c(rep(1:tab[1], 2), rep(1:tab[2], 2), rep(1:tab[3], 2))  # id variable \n\ndf &lt;- reshape(df, timevar = \"c\", idvar = c(\"id\", \"x\", \"g\"), varying = c(\"pre\", \"y\"), \n   direction = \"wide\")\n\n\ndf &lt;- within(df, {\n## Grand mean centered \"pre\" - the before scores\n   preC &lt;- scale(pre, scale = FALSE)\n\n## Dummy variables for \"Coping Startegy\"\n   x1 &lt;- ifelse(x == \"a\", 1, 0)\n   x2 &lt;- ifelse(x == \"b\", 1, 0)\n   x3 &lt;- ifelse(x == \"c\", 1, 0)\n\n## Drop the id variable\n   id &lt;- NULL\n\n## Gender X Coping Strategy interaction\n  sg &lt;- interaction(x, g, sep = \"\")\n\n## Dummy variables for interaction\n  dummies &lt;- model.matrix(~ sg - 1)\n})\n\n## Unnest the nested 'dummies' matrix, and rename its colomns\ndf &lt;- do.call(data.frame, df)\nnames(df) &lt;- gsub(\"dummies.sg\", \"\", names(df))",
    "crumbs": [
      "SEMs with lavaan",
      "Means",
      "Two-Way ANOVA"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/index.html",
    "href": "SEMs_with_lavaan/index.html",
    "title": "",
    "section": "",
    "text": "Reproducing published Structural Equation Models with lavaan\n\n\n\n\n\n\n\nThis post presents R scripts to reproduce published Structural Equation Modeling analyses using lavaan.\n\nThe publications\n\nJose, P. (2013). Doing statistical mediation and moderation. New York, NY: Guilford Press.  A basic three-variable mediation analysis.\nKurbanoglu, N. & Takunyaci, M. (2021). A structural equation modeling on relationship between self-efficacy, physics laboratory anxiety and attitudes. Journal of Family, Counseling and Education, 6(1), 47-56.  A basic three-variable mediation analysis using summary data.\nLittle, T., Slegers, D., & Card, N. (2006). A non-arbitrary method of identifying and scaling latent variables in SEM and MACS models. Structural Equation Modeling, 13(1), 59-72.  Methods of scaling and identification in latent variable models.\nThompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.  SEM approaches to ANOVA and MANOVA models.",
    "crumbs": [
      "SEMs with lavaan"
    ]
  },
  {
    "objectID": "Drawing_SEMs/index.html",
    "href": "Drawing_SEMs/index.html",
    "title": "",
    "section": "",
    "text": "Drawing Structural Equation Models with TikZ\n\n\n\n\n\n\n\nThis post presents TikZ scripts to draw diagrams of Structural Equation Models."
  }
]