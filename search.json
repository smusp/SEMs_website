[
  {
    "objectID": "Data_from_PDFs/index.html",
    "href": "Data_from_PDFs/index.html",
    "title": "",
    "section": "",
    "text": "Getting data out of PDF files into R\n\n\n\n\n\n\n\nThis post presents R scripts to get data out of PDF files into R.",
    "crumbs": [
      "Data from PDFs"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/index.html",
    "href": "SEMs_with_lavaan/index.html",
    "title": "SEMs with lavaan",
    "section": "",
    "text": "Reproducing published Structural Equation Models with lavaan\n\n\n\n\n\n\n\nThis post presents R scripts to reproduce published Structural Equation Modeling analyses using lavaan.\n\nThe publications\n\nJose, P. (2013). Doing statistical mediation and moderation. New York, NY: Guilford Press.  A basic three-variable mediation analysis.\nKurbanoglu, N. & Takunyaci, M. (2021). A structural equation modeling on relationship between self-efficacy, physics laboratory anxiety and attitudes. Journal of Family, Counseling and Education, 6(1), 47-56.  A basic three-variable mediation analysis using summary data.\nLittle, T., Slegers, D., & Card, N. (2006). A non-arbitrary method of identifying and scaling latent variables in SEM and MACS models. Structural Equation Modeling, 13(1), 59-72.  Methods of scaling and identification in latent variable models.\nThompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.  SEM approaches to ANOVA and MANOVA models.",
    "crumbs": [
      "SEMs with lavaan"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Green_2023/two_way_ANOVA.html",
    "href": "SEMs_with_lavaan/Green_2023/two_way_ANOVA.html",
    "title": "Two-Way ANOVA",
    "section": "",
    "text": "Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\nThis example shows the SEM approach to a two-way ANOVA. Results are reported in Tables 21.3 and 21.4 (pp. 395, 396).\nThe data file needs rearranging before it can be used: the format needs to be changed from “long” to “wide”, and the Gender X Coping Strategy interaction needs a grouping variable set up.\n\nLoad packages and get the data\nLoad the relevant packages, and run satisfactionI.r and ANOVA_data.r to get and rearrange the data.\n\nlibrary(lavaan)\nlibrary(DescTools)    # Cramer's V\n\nsource(\"satisfactionI.r\")\nhead(df)\n\nsource(\"ANOVA_data.r\")\nhead(df)\n\nThe variables used in this example are:\n\nx - Coping Strategy (“a” - no strategy; “b” - discussion; “c” - exercise)\ng - Gender\ny - dependent variable (“after” Life-Satisfaction scores)\nsg - Gender X Coping Strategy interaction\n\n\n\nPreliminary results - Cramer’s V\nOn page 394, TLG give Cramer’s V for the Gender X Coping Strategy crosstabulation. As far as I know, Cramer’s V is not available in base R, but DescTools is one of possibly many packages that has a function for Cramer’s V.\n\nDescTools::CramerV(df$g, df$x)\n\nHowever, it is easy to calculate Cramer’s V without the need for the extra package, given the formula:\n\\[\n\\mathsf{Cramer's ~ V} = \\sqrt{\\frac{\\upchi^2 / n}{\\min(r-1, ~ c-1)}}\n\\]\nwhere \\(n\\) is the sample size, \\(r\\) is the number of rows, and \\(c\\) is the number of columns.\n\nchisq &lt;- unname(chisq.test(df$g, df$x)$statistic)\nn &lt;- nrow(df)               # Sample size\nr &lt;- length(unique(df$g))   # Number of rows\nc &lt;- length(unique(df$x))   # Number of columns\n\nCV &lt;- sqrt((chisq/n)/min(r-1, c-1)); CV\n\nStandardised residuals will give the direction of the relationship (p. 394).\n\nchisq.test(df$g, df$x)$stdres\n\n\n\nPreliminary results - Gender X Coping Strategy crosstabulation\nTable 21.3 (p. 395) gives the cell means and frequecies, and the weighted and unweighted marginal means.\nGet the cell means and frequencies.\n\nmeans &lt;- with(df, tapply(y, list(g, x), mean)); means     # Cell means\nfreq  &lt;- with(df, table(g, x)); freq                      # Cell frequencies\n\nGet the unweighted and weighted marginal means.\n\n# Unweighted marginal means\napply(means, 1, mean)      # Gender\napply(means, 2, mean)      # Coping Strategy\n \n# Weighted marginal means\nwith(df, tapply(y, g, mean))     # Gender\nwith(df, tapply(y, x, mean))     # Coping Strategy\n\n\n\nThe models\nThe SEM model for two-way ANOVA is shown below. The diagram shows the “Less Constrained” model - the six means, represented by the label on the arrows connecting the “1” to the dependent variable, differ. To be consistent with the ANOVA assumption of homogeneity of variances, the residual variances are constrained to be equal.\n\n\n\n\n\nThe model statements are shown below. The “Less Constrained” model allows the means (represented by the labels, am, af, …, cf) to differ across the groups. The constraints statements are added to the “Less Constrained” statement to give the “More Constrained” models. The “More Constrained” models are contrasted with the “Less Constrained” model to test for the Gender and Coping Strategy main effects (weighted and unweighted) and the Gender X Coping Strategy interaction. In each case the residual variances are constrained to equality.\nConstraint for the unweighted Gender main effect - Restrict the mean for males to equal the mean for females. But there are three means for females, one for each Coping Strategy group. Similarly, there are three means for males. Simply constrain the sum of the three means for males to equal the sum of the three means for females.\nConstraints for the unweighted Coping Strategy main effect - Restrict the mean for “a” strategy to equal the mean for “b” strategy to equal the mean for “c” strategy. That is, constrain the sum of the two “a” means to equal the sum of the two “b” means; and the sum of the two “b” means to equal the sum of the two “c” means.\nTo test for the main effects applied to weighted means, the constraints are set the same way as before except the means are weighted in proportion to the cell frequencies.\nConstraints for the Gender X Coping Strategy interaction - The “More Constrained” model needs the means to be constrained so that the difference between the mean for “female” and the mean for “male” remains constant across levels of “Coping Strategy”. That is: the difference between “female” mean and “male” mean for the “a” strategy equals the difference between “female” mean and “male” mean for the “b” strategy; and the difference between “female” mean and “male” mean for the “b” strategy equals the difference between “female” mean and “male” mean for the “c” strategy.\n\n## Less Constrained model\nlc &lt;- \"y ~  c(am, af, bm, bf, cm, cf)*1      # Means\n       y ~~ c(e, e, e, e, e, e)*y            # Variances\"\n\nlc.fit &lt;- sem(lc, data = df, group = \"sg\")\nsummary(lc.fit)\n\n## Gender main effect - unweighted means\nconstraints &lt;- \"af + bf + cf == am + bm + cm\"\ngend_unw &lt;- c(lc, constraints)\n\ngend_unw.fit &lt;- sem(gend_unw, data = df, group = \"sg\")\nsummary(gend_unw.fit)\n\nanova(gend_unw.fit, lc.fit)   # Compare the two models\n\n## Coping Strategy main effect - unweighted means\nconstraints &lt;- \n  \"af + am == bf + bm \n   af + am == cf + cm\"\nstrat_unw &lt;- c(lc, constraints)\n\nstrat_unw.fit &lt;- sem(strat_unw, data = df, group = \"sg\")\nsummary(strat_unw.fit)\n\nanova(strat_unw.fit, lc.fit)   # Compare the two models\n\n## Gender main effect - weighted means\nfreq                     # To assist with constructing constraints\nconstraints &lt;- \"(3*af + 3*bf + 6*cf)/12 == (6*am + 3*bm + 3*cm)/12\"\ngend_w &lt;- c(lc, constraints)\n\ngend_w.fit &lt;- sem(gend_w, data = df, group = \"sg\")\nsummary(gend_w.fit)\n\nanova(gend_w.fit, lc.fit)   # Compare the two models\n\n## Coping Strategy main effect - weighted means\n## Compare with SEM section in Table 21.4\nfreq\nconstraints &lt;- \n  \"(3*af + 6*am)/9 == (3*bf + 3*bm)/6 \n   (3*bf + 3*bm)/6 == (6*cf + 3*cm)/9\"\nstrat_w &lt;- c(lc, constraints)\n\nstrat_w.fit &lt;- sem(strat_w, data = df, group = \"sg\")\nsummary(strat_w.fit)\n\nanova(strat_w.fit, lc.fit)   # Compare the two models\n\n## Gender X Coping Strategy interaction\nconstraints &lt;- \n  \"(af - am) == (bf - bm)\n   (bf - bm) == (cf - cm)\"\ninter &lt;- c(lc, constraints)\n\ninter.fit &lt;- sem(inter, data = df, group = \"sg\")\nsummary(inter.fit)\n\nanova(inter.fit, lc.fit)     # Compare the two models\n\n\n\n\nR code with minimal commenting\n## Two-way ANOVA\n##\n## Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling\n## approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural\n## equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\n\n## Load packages\nlibrary(lavaan)\nlibrary(DescTools)    # Cramer's V\n\n## Get the data\nsource(\"satisfactionI.r\")\nhead(df)\n\n## Rearrange the data file\nsource(\"ANOVA_data.r\")\nhead(df)\n\n## Cramer's V\n## Check with page 394\nDescTools::CramerV(df$g, df$x)\n\n## Cramer's V by hand\nchisq &lt;- unname(chisq.test(df$g, df$x)$statistic)\nn &lt;- nrow(df)               # Sample size\nr &lt;- length(unique(df$g))   # Number of rows\nc &lt;- length(unique(df$x))   # Number of columns\n\nCV &lt;- sqrt((chisq/n)/min(r-1, c-1)); CV\n\n## Direction of the relationship\nchisq.test(df$g, df$x)$stdres\n\n## Cell means and cell frequencies\n## Check cell means and frequencies in Table 21.3\nmeans &lt;- with(df, tapply(y, list(g, x), mean)); means     # Cell means\nfreq  &lt;- with(df, table(g, x)); freq                      # Cell frequencies\n\n## Check unweighted and weighted means in Table 21.3\n# Unweighted marginal means\napply(means, 1, mean)      # Gender\napply(means, 2, mean)      # Coping Strategy\n\n# Weighted marginal means\nwith(df, tapply(y, g, mean))     # Gender\nwith(df, tapply(y, x, mean))     # Coping Strategy\n\n## Less Constrained model\nlc &lt;- \"y ~  c(am, af, bm, bf, cm, cf)*1      # Means\n       y ~~ c(e, e, e, e, e, e)*y            # Variances\"\n\nlc.fit &lt;- sem(lc, data = df, group = \"sg\")\nsummary(lc.fit)\n\n## Gender main effect - unweighted means\nconstraints &lt;- \"af + bf + cf == am + bm + cm\"\ngend_unw &lt;- c(lc, constraints)\n\ngend_unw.fit &lt;- sem(gend_unw, data = df, group = \"sg\")\nsummary(gend_unw.fit)\n\nanova(gend_unw.fit, lc.fit)   # Compare the two models\n\n## Coping Strategy main effect - unweighted means\nconstraints &lt;-\n  \"af + am == bf + bm\n   af + am == cf + cm\"\nstrat_unw &lt;- c(lc, constraints)\n\nstrat_unw.fit &lt;- sem(strat_unw, data = df, group = \"sg\")\nsummary(strat_unw.fit)\n\nanova(strat_unw.fit, lc.fit)   # Compare the two models\n\n## Gender main effect - weighted means\nfreq                     # To assist with constructing constraints\nconstraints &lt;- \"(3*af + 3*bf + 6*cf)/12 == (6*am + 3*bm + 3*cm)/12\"\ngend_w &lt;- c(lc, constraints)\n\ngend_w.fit &lt;- sem(gend_w, data = df, group = \"sg\")\nsummary(gend_w.fit)\n\nanova(gend_w.fit, lc.fit)   # Compare the two models\n\n## Coping Strategy main effect - weighted means\n## Compare with SEM section in Table 21.4\nfreq\nconstraints &lt;-\n  \"(3*af + 6*am)/9 == (3*bf + 3*bm)/6\n   (3*bf + 3*bm)/6 == (6*cf + 3*cm)/9\"\nstrat_w &lt;- c(lc, constraints)\n\nstrat_w.fit &lt;- sem(strat_w, data = df, group = \"sg\")\nsummary(strat_w.fit)\n\nanova(strat_w.fit, lc.fit)   # Compare the two models\n\n## Gender X Coping Strategy interaction\nconstraints &lt;-\n  \"(af - am) == (bf - bm)\n   (bf - bm) == (cf - cm)\"\ninter &lt;- c(lc, constraints)\n\ninter.fit &lt;- sem(inter, data = df, group = \"sg\")\nsummary(inter.fit)\n\nanova(inter.fit, lc.fit)     # Compare the two models\n\n\n\n\nR code to get data file - satisfactionI.r\n### Data for Tables 21.1, 21.2, 21.3, 21.4 ###\n\ndf &lt;- structure(list(x = c(\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\"), g = c(\"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \n\"m\", \"m\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \n\"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \n\"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\"), \n    c = c(\"before\", \"before\", \"before\", \"before\", \"before\", \"before\", \n    \"before\", \"before\", \"before\", \"after\", \"after\", \"after\", \n    \"after\", \"after\", \"after\", \"after\", \"after\", \"after\", \"before\", \n    \"before\", \"before\", \"before\", \"before\", \"before\", \"after\", \n    \"after\", \"after\", \"after\", \"after\", \"after\", \"before\", \"before\", \n    \"before\", \"before\", \"before\", \"before\", \"before\", \"before\", \n    \"before\", \"after\", \"after\", \"after\", \"after\", \"after\", \"after\", \n    \"after\", \"after\", \"after\"), y = c(21, 19, 22, 21, 24, 23, \n    21, 24, 23, 22, 22, 24, 25, 27, 30, 22, 23, 24, 23, 23, 21, \n    19, 22, 21, 30, 26, 22, 25, 26, 27, 27, 25, 24, 25, 23, 22, \n    23, 28, 26, 34, 30, 26, 26, 27, 28, 29, 40, 42)), class = \"data.frame\", row.names = c(NA, \n-48L))\n\n\nhead(df)\n\n## x - Coping Strategy (a - No strategy; b - Discussion; c - Exercise)\n## g - Gender\n## c - before/after \n## y - dependent variable (Life Satisfaction)\n\n\n\n\nR code to rearrange data file - ANOVA_data.r\n### Data for Tables 21.1, 21.2, 21.3, 21.4 ###\n\n## Reshape data - long to wide\ntab &lt;- 0.5 * table(df$x)  # in each condition\ndf$id &lt;- c(rep(1:tab[1], 2), rep(1:tab[2], 2), rep(1:tab[3], 2))  # id variable \n\ndf &lt;- reshape(df, timevar = \"c\", idvar = c(\"id\", \"x\", \"g\"), varying = c(\"pre\", \"y\"), \n   direction = \"wide\")\n\n\ndf &lt;- within(df, {\n## Grand mean centered \"pre\" - the before scores\n   preC &lt;- scale(pre, scale = FALSE)\n\n## Dummy variables for \"Coping Startegy\"\n   x1 &lt;- ifelse(x == \"a\", 1, 0)\n   x2 &lt;- ifelse(x == \"b\", 1, 0)\n   x3 &lt;- ifelse(x == \"c\", 1, 0)\n\n## Drop the id variable\n   id &lt;- NULL\n\n## Gender X Coping Strategy interaction\n  sg &lt;- interaction(x, g, sep = \"\")\n\n## Dummy variables for interaction\n  dummies &lt;- model.matrix(~ sg - 1)\n})\n\n## Unnest the nested 'dummies' matrix, and rename its colomns\ndf &lt;- do.call(data.frame, df)\nnames(df) &lt;- gsub(\"dummies.sg\", \"\", names(df))",
    "crumbs": [
      "SEMs with lavaan",
      "Means",
      "Two-Way ANOVA"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Green_2023/one_way_ANOVA.html",
    "href": "SEMs_with_lavaan/Green_2023/one_way_ANOVA.html",
    "title": "One-Way ANOVA",
    "section": "",
    "text": "Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\nThis example shows the SEM approach to a one-way ANOVA. Results are reported in Table 21.1 (p. 389).\nThe data are described at the top of page 388. Thompson, Lie & Green (TLG) claim that the data are available in supplementary materials but I’m unable to locate it. However, the data are available in Mplus data files in supplementary materials for the 1st edition. I’ve collected the data into a more convenient format (see the next section for getting the data), but it is in a “long” format. It needs to be rearranged from “long” to “wide”.\n\nLoad package and get the data\nLoad the lavaan package, and run satisfactionI.r and ANOVA_data.r to get and rearrange the data (satisfactionI.r and ANOVA_data.r are available at the end of this post). The data will be in the df data frame.\n\nlibrary(lavaan)\n\nsource(\"satisfactionI.r\")\nhead(df)\n\nsource(\"ANOVA_data.r\")\nhead(df)\n\nThe variables used in this example are:\n\nx - Coping Strategy (“a” - no strategy; “b” - discussion; “c” - exercise)\ny - dependent variable (“after” Life-Satisfaction scores)\n\n\n\nThe models\nThe SEM model for one-way ANOVA is shown in Fig 21.1 (p. 391), and is reproduced below. The diagram shows the “Less Constrained” model - the three means, represented by the labels on the arrows connecting the “1” to the dependent variable, differ. To be consistent with the ANOVA assumption of homogeneity of variances, the residual variances are constrained to be equal.\n\n\n\n\n\nTwo models are fitted. The model statements are shown below. The “More Constrained” model constrains the means (each with the same label “a”) to equality. The “Less Constrained” model allows the means (represented by the labels “a1”, “a2”, and “a3”) to differ across the groups. (Alternatively, this line could have been written as y ~ 1; that is, with no label, the means are freely estimated in each group. I leave the labels in to be consistent with the diagram of the model.) In both models the residual variances (each with the same label “e”) are constrained to equality.\nIn what follows, I use lists. The model statements are placed into a list, then I use the lapply() or sapply() function to perform operations on each element in the list (such as sem() to run the analyses, or summary() to return summaries of the analyses, or [[ to extract elements); and I use the Reduce() function when I need to perform operations across the two models (such as anova() to constrast the fit of the two models).\n\nmodels &lt;- list(\n  \"More Constrained\" =\n    \"y ~  c(a, a, a)*1     # Means\n     y ~~ c(e, e, e)*y     # Variances\",\n\n  \"Less Constrained\" =\n    \"y ~  c(a1, a2, a3)*1\n     y ~~ c(e, e, e)*y\"\n)\n\n\n\nFit the models and get the results\nThe lapply() function applies the sem() function to the two elements of the models list (with data set to df, and group set to the \"x\" variable).\n\nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\nlapply(fit, summary)\n\nThe “SEM” sections of Table 21.1 show the means, pooled error variances, and the \\(\\upchi\\)2 test.\nThe summaries show “Intercepts” (that is, the estimated means) and “Variances” (that is, the error variances) for each “Coping Strategy” group for both models. Compare with means and pooled error variances in the SEM section in Table 21.1.\nRather than, or perhaps, as well as, searching through the model summaries for the means and variances, they can be extracted from a list of estimates of model parameters.\n\n## Get list of estimates\nestimates &lt;- lapply(fit, lavInspect, \"est\"); estimates\n\n## Extract means - in element \"nu\"\nmeans &lt;- list()\nfor (i in names(models)) {\n   means[[i]] &lt;- estimates[[i]] |&gt;\n      sapply(\"[[\", \"nu\")\n}\nmeans &lt;- do.call(cbind, means); means\n\n## Extract error variances - in element \"theta\"\nErrorVar &lt;- list()\nfor (i in names(models)) {\n   ErrorVar[[i]] &lt;- estimates[[i]] |&gt;\n      sapply(\"[[\", \"theta\")\n}\nErrorVar &lt;- do.call(cbind, ErrorVar); ErrorVar\n\nTo perform the \\(\\upchi\\)2 test (to compare the fit of the two models), apply the anova() function to the two models.\n\nReduce(anova, fit)\n\nCompare with the \\(\\upchi\\)2 statistic and p value in Table 21.1.\nOn page 390, TLG give model fit statistics for both models. These are available in the anova output above, or they can be extracted separately from the list of fit measures. First, a function to extract the \\(\\upchi\\)2 statistic, degrees of freedom, and the p value, then that function is applied to both models.\n\nGetFit &lt;- function(fit) {\n   tab &lt;- fitMeasures(fit, c(\"chisq\", \"df\", \"pvalue\"))\n   tab &lt;- round(tab, 3)\n   return(tab)\n}\n\nsapply(fit, GetFit)\n\nNote: Neither model fits well.\nTLG mention the calculation for R2 (p. 390). The relevant SSEs can be obtained from the error variances (see ErrorVar) by multiplying error variance by sample size. However, note that multiplication is not needed because sample size will cancel out; that is, substitute the error variances into Equation 21.4.\n\nRsquare &lt;- ErrorVar[\"a\", ] |&gt;\n   Reduce(function(mc, lc) (mc - lc)/mc, x = _)  # Substitute into Eq 21.4\nRsquare\n\n\n\nRelaxing assumption of homogeneity of variances\nTLG do not run these models though they make reference to them. The model statements when the homogeneity of variances assumption is relaxed are shown below.\n\nmodels &lt;- list(\n  \"More Constrained\" =\n    \"y ~  c(a, a, a)*1         # Means\n     y ~~ c(e1, e2, e3)*y      # Variances\",\n\n  \"Less Constrained\" =\n    \"y ~  c(a1, a2, a3)*1\n     y ~~ c(e1, e2, e3)*y\"\n)\n\nRun the models and get the summaries. In this analysis I use the “mlm” estimator, a robust ML estimator; that is, the normality assumption is relaxed also.\n\nfit &lt;- lapply(models, sem, data = df, group = \"x\", estimator = \"mlm\")\nlapply(fit, summary)\n\nThis time, the “Less Constrained” model is just identified - a perfect fit.\n\n\n\nR code with minimal commenting\n## One-way ANOVA\n##\n## Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling\n## approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural\n## equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\n\n## Load package\nlibrary(lavaan)\n\n## Get the data\nsource(\"satisfactionI.r\")\nhead(df)\n\n## Rearrange the data file\nsource(\"ANOVA_data.r\")\nhead(df)\n\n## The models\nmodels &lt;- list(\n  \"More Constrained\" =\n    \"y ~  c(a, a, a)*1     # Means\n     y ~~ c(e, e, e)*y     # Variances\",\n\n  \"Less Constrained\" =\n    \"y ~  c(a1, a2, a3)*1\n     y ~~ c(e, e, e)*y\"\n)\n\n## Fit the models\nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n## Get model summaries\n## Check results with \"SEM\" section of Table 21.1\nlapply(fit, summary)\n\n## Extract means and variances from list of estimates\n## Get list of estimates\nestimates &lt;- lapply(fit, lavInspect, \"est\"); estimates\n\n## Extract means - in element \"nu\"\nmeans &lt;- list()\nfor (i in names(models)) {\n   means[[i]] &lt;- estimates[[i]] |&gt;\n      sapply(\"[[\", \"nu\")\n}\nmeans &lt;- do.call(cbind, means); means\n\n## Extract error variances - in element \"theta\"\nErrorVar &lt;- list()\nfor (i in names(models)) {\n   ErrorVar[[i]] &lt;- estimates[[i]] |&gt;\n      sapply(\"[[\", \"theta\")\n}\nErrorVar &lt;- do.call(cbind, ErrorVar); ErrorVar\n\n## Contrast model fits\n## Check with chi sq statistic and p value in Table 21.1\nReduce(anova, fit)\n\n## Fit for each model - Chi squares\n## Check with values on page 390\n## First, a function to extract chi squares\nGetFit &lt;- function(fit) {\n   tab &lt;- fitMeasures(fit, c(\"chisq\", \"df\", \"pvalue\"))\n   tab &lt;- round(tab, 3)\n   return(tab)\n}\n\nsapply(fit, GetFit)\n\n## R square\n## Check with Equation 21.4\nRsquare &lt;- ErrorVar[\"a\", ] |&gt;\n   Reduce(function(mc, lc) (mc - lc)/mc, x = _)  # Substitute into Eq 21.4\nRsquare\n\n## Relax homogeneity of variances assumption\nmodels &lt;- list(\n  \"More Constrained\" =\n    \"y ~  c(a, a, a)*1         # Means\n     y ~~ c(e1, e2, e3)*y      # Variances\",\n\n  \"Less Constrained\" =\n    \"y ~  c(a1, a2, a3)*1\n     y ~~ c(e1, e2, e3)*y\"\n)\n\n## Run the model and get the summary\nfit &lt;- lapply(models, sem, data = df, group = \"x\", estimator = \"mlm\")\nlapply(fit, summary)\n\n\n\n\nR code to get data file - satisfactionI.r\n### Data for Tables 21.1, 21.2, 21.3, 21.4 ###\n\ndf &lt;- structure(list(x = c(\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\"), g = c(\"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \n\"m\", \"m\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \n\"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \n\"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\"), \n    c = c(\"before\", \"before\", \"before\", \"before\", \"before\", \"before\", \n    \"before\", \"before\", \"before\", \"after\", \"after\", \"after\", \n    \"after\", \"after\", \"after\", \"after\", \"after\", \"after\", \"before\", \n    \"before\", \"before\", \"before\", \"before\", \"before\", \"after\", \n    \"after\", \"after\", \"after\", \"after\", \"after\", \"before\", \"before\", \n    \"before\", \"before\", \"before\", \"before\", \"before\", \"before\", \n    \"before\", \"after\", \"after\", \"after\", \"after\", \"after\", \"after\", \n    \"after\", \"after\", \"after\"), y = c(21, 19, 22, 21, 24, 23, \n    21, 24, 23, 22, 22, 24, 25, 27, 30, 22, 23, 24, 23, 23, 21, \n    19, 22, 21, 30, 26, 22, 25, 26, 27, 27, 25, 24, 25, 23, 22, \n    23, 28, 26, 34, 30, 26, 26, 27, 28, 29, 40, 42)), class = \"data.frame\", row.names = c(NA, \n-48L))\n\n\nhead(df)\n\n## x - Coping Strategy (a - No strategy; b - Discussion; c - Exercise)\n## g - Gender\n## c - before/after \n## y - dependent variable (Life Satisfaction)\n\n\n\n\nR code to rearrange data file - ANOVA_data.r\n### Data for Tables 21.1, 21.2, 21.3, 21.4 ###\n\n## Reshape data - long to wide\ntab &lt;- 0.5 * table(df$x)  # in each condition\ndf$id &lt;- c(rep(1:tab[1], 2), rep(1:tab[2], 2), rep(1:tab[3], 2))  # id variable \n\ndf &lt;- reshape(df, timevar = \"c\", idvar = c(\"id\", \"x\", \"g\"), varying = c(\"pre\", \"y\"), \n   direction = \"wide\")\n\n\ndf &lt;- within(df, {\n## Grand mean centered \"pre\" - the before scores\n   preC &lt;- scale(pre, scale = FALSE)\n\n## Dummy variables for \"Coping Startegy\"\n   x1 &lt;- ifelse(x == \"a\", 1, 0)\n   x2 &lt;- ifelse(x == \"b\", 1, 0)\n   x3 &lt;- ifelse(x == \"c\", 1, 0)\n\n## Drop the id variable\n   id &lt;- NULL\n\n## Gender X Coping Strategy interaction\n  sg &lt;- interaction(x, g, sep = \"\")\n\n## Dummy variables for interaction\n  dummies &lt;- model.matrix(~ sg - 1)\n})\n\n## Unnest the nested 'dummies' matrix, and rename its colomns\ndf &lt;- do.call(data.frame, df)\nnames(df) &lt;- gsub(\"dummies.sg\", \"\", names(df))",
    "crumbs": [
      "SEMs with lavaan",
      "Means",
      "One-Way ANOVA"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Green_2023/one_way_ANCOVA.html",
    "href": "SEMs_with_lavaan/Green_2023/one_way_ANCOVA.html",
    "title": "One-Way ANCOVA",
    "section": "",
    "text": "Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\nThis example shows the SEM approach to a one-way ANCOVA. Results are reported in Table 21.2 (p. 393).\nThe data file needs rearranging before it can be used: the format needs to be changed from “long” to “wide”, and the pre or before Life-Satisfaction scores need to be centered.\n\nLoad package and get the data\nLoad the lavaan packages, and run satisfactionI.r and ANOVA_data.r to get and rearrange the data.\n\nlibrary(lavaan)\n\nsource(\"satisfactionI.r\")\nhead(df)\n\nsource(\"ANOVA_data.r\")\nhead(df)\n\nThe variables used in this example are:\n\nx - Coping Strategy (“a” - no strategy; “b” - discussion; “c” - exercise)\ny - dependent variable (“after” Life-Satisfaction scores)\npreC - pre-Life-Satisfaction grand mean centered\n\nThe steps are the same as with the one_way_ANOVA. The only difference is the addition of the covariate, preC.\n\n\nThe models\nThe SEM model for one-way ANCOVA is shown below. The diagram shows the “Less Constrained” model - the three means, represented by the labels on the arrows connecting the “1” to the dependent variable, differ. To be consistent with the ANCOVA assumptions of homogeneity of variances and homogeneity of regression slopes, the residual variances and the coefficients for the covariate (preC) are each constrained to equality.\n\n\n\n\n\nThe model statements are shown below. The “More Constrained” model constrains the means to equality. The “Less Constrained” model allows the means to differ across the groups. In both cases the residual variances and the coefficients for the covariate are constrained to equality.\n\nmodels &lt;- list(\n  \"More Constrained\" =\n    \"y ~  c(a, a, a)*1        # Means\n     y ~  c(b, b, b)*preC     # Regression slopes\n     y ~~ c(e, e, e)*y        # Variances\",\n\n  \"Less Constrained\" =\n    \"y ~  c(a1, a2, a3)*1\n     y ~  c(b, b, b)*preC\n     y ~~ c(e, e, e)*y\"\n)\n\n\n\nFit the models and get the results\nThe lapply() function applies the sem() function to the two elements of the models list (with data set to df, and group set to the \"x\" variable).\n\nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\nlapply(fit, summary)\n\nThe “SEM” sections of Table 21.2 show the means, pooled error variances, and the \\(\\upchi\\)2 test; the footnote to Table 21.2 gives the regression coefficients.\nScroll through the summaries to find the “Intercepts”, “Variances”, and “Regressions”; or extract them from the list of estimates of model parameters.\n\n## Get list of estimates\nestimates &lt;- lapply(fit, lavInspect, \"est\"); estimates\n\n## Extract means - in element \"alpha\"\nmeans &lt;- list()\nfor (i in names(models)){\n   means[[i]] &lt;- estimates[[i]] |&gt;\n      lapply(\"[[\", \"alpha\") |&gt;       # Means for Y and preC\n      sapply(\"[[\", 1)                # Means for Y\n}\nmeans &lt;- do.call(cbind, means); means\n\n## Extract error variances -  in element \"psi\"\nErrorVar &lt;- list()\nfor (i in names(models)){\n   ErrorVar[[i]] &lt;- estimates[[i]] |&gt;\n      lapply(\"[[\", \"psi\")  |&gt;        # Extract \"psi\" element\n      sapply(\"[[\", 1, 1)             # 1st row, 1st column of \"psi\"\n}\nErrorVar &lt;- do.call(cbind, ErrorVar); ErrorVar\n\n## Extract regression coefficients -  in element \"beta\"\nRegCoef &lt;- list()\nfor (i in names(models)){\n   RegCoef[[i]] &lt;- estimates[[i]] |&gt;\n      lapply(\"[[\", \"beta\")  |&gt;       # Extract \"beta\" element\n      sapply(\"[[\", 1, 2)             # 1st row, 2nd column of \"beta\"\n}\nRegCoef &lt;- do.call(cbind, RegCoef); RegCoef\n\nTo perform the \\(\\upchi\\)2 test (to compare the fit of the two models), apply the anova() function to the two models.\n\nReduce(anova, fit)\n\nCompare with the \\(\\upchi\\)2 statistic and p value in Table 21.2.\nIn Equation 21.9 (p. 394), TLG give calculations for R2. As was the case with the one-way ANOVA, the relevant SSEs can be obtained from the error variances (see ErrorVar) by multiplying error variance by sample size. But again, the multiplication is not needed because sample size will cancel out; that is, substitute the error variances into Equation 21.9.\n\nRsquare &lt;- ErrorVar[\"a\", ] |&gt;\n   Reduce(function(mc, lc) (mc - lc)/mc, x = _)  # Substitute into Eq 21.9\nRsquare\n\n\n\n\nR code with minimal commenting\n## One-way ANCOVA\n##\n## Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling\n## approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural\n## equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\n\n## Load package\nlibrary(lavaan)\n\n## Get the data\nsource(\"satisfactionI.r\")\nhead(df)\n\n## Rearrange the data file\nsource(\"ANOVA_data.r\")\nhead(df)\n\n## The models\nmodels &lt;- list(\n  \"More Constrained\" =\n    \"y ~  c(a, a, a)*1        # Means\n     y ~  c(b, b, b)*preC     # Regression slopes\n     y ~~ c(e, e, e)*y        # Variances\",\n\n  \"Less Constrained\" =\n    \"y ~  c(a1, a2, a3)*1\n     y ~  c(b, b, b)*preC\n     y ~~ c(e, e, e)*y\"\n)\n\n## Fit the models\nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n## Get model summaries\n## Check results with \"SEM\" section of Table 21.2\nlapply(fit, summary)\n\n## Extract means, variances, and regression coefficients from list of estimates\n## Get list of estimates\nestimates &lt;- lapply(fit, lavInspect, \"est\"); estimates\n\n## Extract means - in element \"alpha\"\nmeans &lt;- list()\nfor (i in names(models)){\n   means[[i]] &lt;- estimates[[i]] |&gt;\n      lapply(\"[[\", \"alpha\") |&gt;       # Means for Y and preC\n      sapply(\"[[\", 1)                # Means for Y\n}\nmeans &lt;- do.call(cbind, means); means\n\n## Extract error variances -  in element \"psi\"\nErrorVar &lt;- list()\nfor (i in names(models)){\n   ErrorVar[[i]] &lt;- estimates[[i]] |&gt;\n      lapply(\"[[\", \"psi\")  |&gt;        # Extract \"psi\" element\n      sapply(\"[[\", 1, 1)             # 1st row, 1st column of \"psi\"\n}\nErrorVar &lt;- do.call(cbind, ErrorVar); ErrorVar\n\n## Extract regression coefficients -  in element \"beta\"\nRegCoef &lt;- list()\nfor (i in names(models)){\n   RegCoef[[i]] &lt;- estimates[[i]] |&gt;\n      lapply(\"[[\", \"beta\")  |&gt;       # Extract \"beta\" element\n      sapply(\"[[\", 1, 2)             # 1st row, 2nd column of \"beta\"\n}\nRegCoef &lt;- do.call(cbind, RegCoef); RegCoef\n\n## Contrast model fits\n## Check with chi sq statistic and p value in Table 21.2\nReduce(anova, fit)\n\n## R square\n## Check with Equation 21.9\nRsquare &lt;- ErrorVar[\"a\", ] |&gt;\n   Reduce(function(mc, lc) (mc - lc)/mc, x = _)  # Substitute into Eq 21.9\nRsquare\n\n\n\n\nR code to get data file - satisfactionI.r\n### Data for Tables 21.1, 21.2, 21.3, 21.4 ###\n\ndf &lt;- structure(list(x = c(\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\"), g = c(\"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \n\"m\", \"m\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \n\"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \n\"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\"), \n    c = c(\"before\", \"before\", \"before\", \"before\", \"before\", \"before\", \n    \"before\", \"before\", \"before\", \"after\", \"after\", \"after\", \n    \"after\", \"after\", \"after\", \"after\", \"after\", \"after\", \"before\", \n    \"before\", \"before\", \"before\", \"before\", \"before\", \"after\", \n    \"after\", \"after\", \"after\", \"after\", \"after\", \"before\", \"before\", \n    \"before\", \"before\", \"before\", \"before\", \"before\", \"before\", \n    \"before\", \"after\", \"after\", \"after\", \"after\", \"after\", \"after\", \n    \"after\", \"after\", \"after\"), y = c(21, 19, 22, 21, 24, 23, \n    21, 24, 23, 22, 22, 24, 25, 27, 30, 22, 23, 24, 23, 23, 21, \n    19, 22, 21, 30, 26, 22, 25, 26, 27, 27, 25, 24, 25, 23, 22, \n    23, 28, 26, 34, 30, 26, 26, 27, 28, 29, 40, 42)), class = \"data.frame\", row.names = c(NA, \n-48L))\n\n\nhead(df)\n\n## x - Coping Strategy (a - No strategy; b - Discussion; c - Exercise)\n## g - Gender\n## c - before/after \n## y - dependent variable (Life Satisfaction)\n\n\n\n\nR code to rearrange data file - ANOVA_data.r\n### Data for Tables 21.1, 21.2, 21.3, 21.4 ###\n\n## Reshape data - long to wide\ntab &lt;- 0.5 * table(df$x)  # in each condition\ndf$id &lt;- c(rep(1:tab[1], 2), rep(1:tab[2], 2), rep(1:tab[3], 2))  # id variable \n\ndf &lt;- reshape(df, timevar = \"c\", idvar = c(\"id\", \"x\", \"g\"), varying = c(\"pre\", \"y\"), \n   direction = \"wide\")\n\n\ndf &lt;- within(df, {\n## Grand mean centered \"pre\" - the before scores\n   preC &lt;- scale(pre, scale = FALSE)\n\n## Dummy variables for \"Coping Startegy\"\n   x1 &lt;- ifelse(x == \"a\", 1, 0)\n   x2 &lt;- ifelse(x == \"b\", 1, 0)\n   x3 &lt;- ifelse(x == \"c\", 1, 0)\n\n## Drop the id variable\n   id &lt;- NULL\n\n## Gender X Coping Strategy interaction\n  sg &lt;- interaction(x, g, sep = \"\")\n\n## Dummy variables for interaction\n  dummies &lt;- model.matrix(~ sg - 1)\n})\n\n## Unnest the nested 'dummies' matrix, and rename its colomns\ndf &lt;- do.call(data.frame, df)\nnames(df) &lt;- gsub(\"dummies.sg\", \"\", names(df))",
    "crumbs": [
      "SEMs with lavaan",
      "Means",
      "One-Way ANCOVA"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Little_2006/Little_2006.html",
    "href": "SEMs_with_lavaan/Little_2006/Little_2006.html",
    "title": "Scaling",
    "section": "",
    "text": "Little, T., Slegers, D., & Card, N. (2006). A non-arbitrary method of identifying and scaling latent variables in SEM and MACS models. Structural Equation Modeling, 13(1), 59-72.\nThis example shows how to set constraints for different methods of identification and scaling in latent variable models, and, though invariance is not a topic of discussion, the example shows how to set constraints for strong metric invariance in a two-group model. Also, the example shows how to use summary data (correlations, standard deviations, and means) in a two-group model.\nThe methods of identification and scaling discussed by Little, Slegers & Card (LS&C) are:\nLS&C present a two-group (7th grade and 8th grade), two-construct (positive affect and negative affact) model. Each construct is assessed with three manifest indicators. The SEM diagram below shows the model as it might apply to the whole sample (i.e., ignoring the groups). This one-group model is presented to explain the symbols used in the paper, and to show how they apply in the model diagrams. First, POS and NEG are the constructs; and pos1, …, neg3 are the manifest indicators. The solid lines represent the covariance structure, and the gray lines represent the mean structure (ie, the means and intercepts).\nThe symbols are:",
    "crumbs": [
      "SEMs with lavaan",
      "Scaling"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Little_2006/Little_2006.html#reference-group-method",
    "href": "SEMs_with_lavaan/Little_2006/Little_2006.html#reference-group-method",
    "title": "Scaling",
    "section": "Reference-Group Method",
    "text": "Reference-Group Method\n\nThe model\nThe model with the constraints is shown below. Some points to note. There are two groups: Grade 7 and Grade 8. The corresponding loadings (\\(\\uplambda\\)) and intercepts (\\(\\uptau\\)) are equal across the groups. The latent variances (\\(\\upphi\\)7,11 and \\(\\upphi\\)7,22) and latent means (\\(\\upkappa\\)) are constrained to 1 and 0 respectively in the first group only. The residual variances (\\(\\uptheta\\)) are freely estimated in each group, and the latent covariances (\\(\\upphi\\)7,12 and \\(\\upphi\\)8,12) are freely estimated.\n\n\n\n\n\nWhen constructing the model statment, there are some points to be considered.\nFirst, the constraints applied to latent means and variances apply in the first group only. In the model statement, pre-multiply the mean or the variance by a vector containing the constraints; like this: c(1,NA) - the 1 forces the parameter in the first group to be constrained to 1; the NA forces the parameter in the second group to be estimated.\nSecond, LS&C state that the data display strong metric invariance (p. 63); that is, the corresponding loadings and intercepts are equal across the groups. There is no need to be concerned with these constraints when constructing the model statement - they will be set up in the next step. (Strictly, the intercepts do not even need to be mentioned in the model statement - lavaan will add them automatically when sample.means are in the model. But they are left in the statement below because intercepts are implicated in constraints in models to follow.)\nThird, strong metric invariance places no constraints on indicator variances - they are freely estimated in each group. But again, there is no need to be concerned with or even to mention them when constructing the model statement - lavaan will add them automatically.\nFinally, lavaan’s default marker-variable method has to be explicitely disabled by pre-multiplying the first indicator for both constructs by NA.\n\nm1 &lt;- \"\n  # Measurement Model\n  #   - Free the 1st loading so it can be estimated\n  POS =~ NA*pos1 + pos2 + pos3\n  NEG =~ NA*neg1 + neg2 + neg3\n\n  # Latent variances and covariance\n  #   - Constrain latent variances to 1 in first group\n  POS ~~ c(1,NA)*POS\n  NEG ~~ c(1,NA)*NEG\n  POS ~~ NEG\n\n  # Indicator intercepts\n  pos1 ~ 1\n  pos2 ~ 1\n  pos3 ~ 1\n  neg1 ~ 1\n  neg2 ~ 1\n  neg3 ~ 1\n\n  # Latent means\n  #   - Constrain latent means to 0 in first group\n  POS ~ c(0,NA)*1\n  NEG ~ c(0,NA)*1\n\"\n\n\n\nFit the model and get the results\nTo deal with strong metric invariance, set group.equal = c(\"loadings\", \"intercepts\") in the sem() function.\n\nm1_fit &lt;- sem(m1, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m1_fit, standardized = TRUE, fit.measures = TRUE)\n\nCompare the output with “Method 1” in Table 2 (pp. 64-65).\n\n\nA shortcut\nLavaan can do reference-group scaling automatically - set std.lv = TRUE in the sem() function. The constraints are the same as above - in the first group, latent variances are constrained to one, and latent means are constrained to zero.\n\nm1_short &lt;- \"\n  # Measurement Model\n  POS =~ pos1 + pos2 + pos3\n  NEG =~ neg1 + neg2 + neg3\n\"\n\nm1_short_fit &lt;- sem(m1_short, sample.cov = cov, sample.nobs = n, \n   sample.mean = mean, std.lv = TRUE,\n   group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m1_short_fit, standardized = TRUE, fit.measures = TRUE)\n\nCheck the output. It is the same as before except for one detail. It might be disconcerting for some that the latent means in the first group are not reported. Maybe it’s not important because they are zero (remember the constraint). To see them in the output, set remove.unused = FALSE in the summary() function.\n\nsummary(m1_short_fit, remove.unused = FALSE, standardized = TRUE,\n   fit.measures = TRUE)",
    "crumbs": [
      "SEMs with lavaan",
      "Scaling"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Little_2006/Little_2006.html#marker-variable-method",
    "href": "SEMs_with_lavaan/Little_2006/Little_2006.html#marker-variable-method",
    "title": "Scaling",
    "section": "Marker-Variable Method",
    "text": "Marker-Variable Method\n\nThe model\nThe model with the constraints is shown below.\n\n\n\n\n\nResults for three versions of Method 2 are presented in Table 2 - in each case, constraints are applied to different indicator variables. Here, only the third is considered - constraints apply to loadings and intercepts for the third indicator in the POS construct, and to the first indicator in the NEG construct.\nSome points to be considered.\nFirst, with strong metric invariance in place, the constraints applying to intercepts and loadings apply in both groups. In the model statement, pre-multiply the loadings by c(1,1), and the intercepts by c(0,0).\nSecond, again, the point concerning strong metric invariance - it will be set up in the next step.\nThird, again, there is no need to mention indicator variances - lavaan will add them automatically.\nFinally, lavaan’s default marker-variable method has to be explicitely disabled for the POS construct by pre-multiplying the first indicator be NA.\n\nm2c &lt;- \"\n  # Measurement Model\n  #   - Free the 1st loading in POS so it can be estimated\n  #   - Constrain 3rd loading in POS to 1 in both groups\n  #   - Constrain 1st loading in NEG to 1 in both groups\n  POS =~ NA*pos1 + pos2 + c(1,1)*pos3\n  NEG =~ c(1,1)*neg1 + neg2 + neg3\n\n  # Latent variances and covariance\n  POS ~~ POS\n  NEG ~~ NEG\n  POS ~~ NEG\n\n  # Indicator intercepts\n  #   - Constrain 3rd intercept in POS to 0 in both groups\n  #   - Constrain 1st intercept in NEG to 0 in both groups\n  pos1 ~ 1\n  pos2 ~ 1\n  pos3 ~ c(0,0)*1\n  neg1 ~ c(0,0)*1\n  neg2 ~ 1\n  neg3 ~ 1\n\n  # Latent means\n  POS ~ 1\n  NEG ~ 1\n\"\n\n\n\nFit the model and get the results\nAs before, the group.equal = c(\"loadings\", \"intercepts\") statement in the sem() function forces corresponding loadings and intercepts to be equal across the groups.\n\nm2c_fit &lt;- sem(m2c, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m2c_fit, standardized = TRUE, fit.measures = TRUE)\n\nCompare the output with “Method 2c” in Table 2 (pp. 64-65).\n\n\nLavaan default\nThis is not lavaan’s default method of scaling. The default method constrains the loadings for the first indicator to one for both constructs and, because of the strong metric invariance, in both groups. When there is a mean structure in the model, lavaan sets the latent means to zero (in the first group only). In the summary() function set remove.unused = FALSE to see the latent means.\n\nm2c_default &lt;- \"\n  # Measurement Model\n  POS =~ pos1 + pos2 + pos3\n  NEG =~ neg1 + neg2 + neg3\n\"\n\nm2c_default_fit &lt;- sem(m2c_default, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m2c_default_fit, remove.unused = FALSE,\n   standardized = TRUE, fit.measures = TRUE)",
    "crumbs": [
      "SEMs with lavaan",
      "Scaling"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Little_2006/Little_2006.html#effects-coding-method",
    "href": "SEMs_with_lavaan/Little_2006/Little_2006.html#effects-coding-method",
    "title": "Scaling",
    "section": "Effects-Coding Method",
    "text": "Effects-Coding Method\n\nThe model\nThe model with the equality constraints is shown below.\n\n\n\n\n\nIn the model statement, the loadings and the intercepts are labelled (see the “Measurement Model” and the “Indicator intercepts” sections in the model statement) so that the labels can be used to impose the constraints. Constraints are imposed on the loadings and the intercepts using the == operator - see the “Constraints” section in the model statement.\nSame points as before: lavaan will add indicator variances automatically; constraints concerning strong metric invariance will be attended to in the next step; and the default marker-variable method has to be explicitely disabled.\n\nm3 &lt;- \"\n  # Measurement Model\n  #   - Free the 1st loading so it can be estimated\n  #   - Label the loadings so they can be used in the constraints\n  POS =~ NA*p1*pos1 + p2*pos2 + p3*pos3\n  NEG =~ NA*n1*neg1 + n2*neg2 + n3*neg3\n\n  # Latent variances and covariance\n  POS ~~ POS\n  NEG ~~ NEG\n  POS ~~ NEG\n\n  # Indicator intercepts\n  #   - Label the intercepts so they can be used in the constraints\n  pos1 ~ ip1*1\n  pos2 ~ ip2*1\n  pos3 ~ ip3*1\n  neg1 ~ in1*1\n  neg2 ~ in2*1\n  neg3 ~ in3*1\n\n  # Latent means\n  POS ~ 1\n  NEG ~ 1\n\n  # Constraints\n  # For each construct:\n  #   The sum of the loadings equals the number of indicators\n  #   The sum of the intercepts equals zero\n  p1 + p2 + p3 == 3\n  n1 + n2 + n3 == 3\n\n  ip1 + ip2 + ip3 == 0\n  in1 + in2 + in3 == 0\n\"\n\n\n\nFit the model and get the summary\nAs before, the group.equal = c(\"loadings\", \"intercepts\") statement in the sem() function forces corresponding loadings and intercepts to be equal across the groups.\n\nm3_fit &lt;- sem(m3, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m3_fit, standardized = TRUE, fit.measures = TRUE)\n\nCompare the output with “Method 3” in Table 2 (pp. 64-65).\n\n\nA shortcut\nLavaan can do effects-scaling automatically - set effect.coding = TRUE in the sem() function.\n\nm3_short &lt;- \"\n  # Measurement Model\n  POS =~ pos1 + pos2 + pos3\n  NEG =~ neg1 + neg2 + neg3\n\"\n\nm3_short_fit &lt;- sem(m3_short, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, effect.coding = TRUE,\n   group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m3_short_fit, standardized = TRUE, fit.measures = TRUE)",
    "crumbs": [
      "SEMs with lavaan",
      "Scaling"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Little_2006/Little_2006.html#fit-measures",
    "href": "SEMs_with_lavaan/Little_2006/Little_2006.html#fit-measures",
    "title": "Scaling",
    "section": "Fit measures",
    "text": "Fit measures\nLS&C state that the models “produce overall model fit statistics that are identical” (p. 66). The following shows how to extract fit measures from all models presented here, and present them in a table.\n\n#  A function to extract fit measures\nGetFit &lt;- function(fit, ...) {\n   fitMeasures(fit, ...)\n}\n\n#  Add the fitted lavaan objects to a list\nmodels &lt;- list(\n   \"Method 1\"          = m1_fit,\n   \"Method 1 Shortcut\" = m1_short_fit,\n   \"Method 2c\"         = m2c_fit,\n   \"lavaan Default\"    = m2c_default_fit,\n   \"Method 3\"          = m3_fit,\n   \"Method 3 Shortcut\" = m3_short_fit)\n\n#  Select the fit measures\nmeasures &lt;- c(\"chisq\", \"df\", \"pvalue\", \"cfi\", \"tli\", \"rmsea\",\n   \"rmsea.ci.lower\", \"rmsea.ci.upper\")\n\n#  Get fit measures in a table\ntab &lt;- sapply(models, GetFit, measures)\ntab &lt;- t(round(tab, 4)); tab\n\nCompare the fit measures with those presented on page 66.\n\n\n\nR code with minimal commenting\n## Little, T., Slegers, D., & Card, N. (2006). A non-arbitrary method\n## of identifying and scaling latent variables in SEM and MACS models.\n## Structural Equation Modeling, 13(1), 59-72.\n\n## Load package\nlibrary(lavaan)\n\n## Get the data from Appendix A\n# 7th grade\ncor7 &lt;- c(\n   1.00000,\n   0.75854,  1.00000,\n   0.76214,  0.78705,  1.00000,\n   0.02766,  0.00973, -0.05762,  1.00000,\n  -0.06112, -0.06105, -0.14060,  0.78501,  1.00000,\n  -0.02222, -0.05180, -0.10250,  0.81616,  0.81076,  1.00000)\n\nmean7 &lt;- c(3.13552, 2.99061, 3.06945, 1.70069, 1.52705, 1.54483)\nsd7   &lt;- c(0.66770, 0.68506, 0.70672, 0.71418, 0.66320, 0.65276)\nn7    &lt;- 380\n\n# 8th grade\ncor8 &lt;- c(\n   1.00000,\n   0.81366,  1.00000,\n   0.84980,  0.83523,  1.00000,\n  -0.18804, -0.15524, -0.21520,  1.00000,\n  -0.28875, -0.24951, -0.33769,  0.78418,  1.00000,\n  -0.29342, -0.21022, -0.30553,  0.79952,  0.83156,  1.00000)\n\nmean8 &lt;- c(3.07338, 2.84716, 2.97882, 1.71700, 1.57955, 1.55001)\nsd8   &lt;- c(0.70299, 0.71780, 0.76208, 0.65011, 0.60168, 0.61420)\nn8    &lt;- 379\n\n## Get the variable names from Appendix A\nnames &lt;- c(\"pos1\", \"pos2\", \"pos3\", \"neg1\", \"neg2\", \"neg3\")\n\n## Combine into lists\ncor  &lt;- list(\"Grade 7\" = cor7, \"Grade 8\" = cor8)\nsd   &lt;- list(sd7, sd8)\nmean &lt;- list(mean7, mean8)\nn    &lt;- list(n7, n8)\n\n## Get the co/variance matrices\ncov &lt;- Map(getCov, x = cor, sds = sd, names = list(names, names))\n\n## The model - Reference-Group Method\nm1 &lt;- \"\n  # Measurement Model\n  #   - Free the 1st loading so it can be estimated\n  POS =~ NA*pos1 + pos2 + pos3\n  NEG =~ NA*neg1 + neg2 + neg3\n\n  # Latent variances and covariance\n  #   - Constrain latent variances to 1 in first group\n  POS ~~ c(1,NA)*POS\n  NEG ~~ c(1,NA)*NEG\n  POS ~~ NEG\n\n  # Indicator intercepts\n  pos1 ~ 1\n  pos2 ~ 1\n  pos3 ~ 1\n  neg1 ~ 1\n  neg2 ~ 1\n  neg3 ~ 1\n\n  # Latent means\n  #   - Constrain latent means to 0 in first group\n  POS ~ c(0,NA)*1\n  NEG ~ c(0,NA)*1\n\"\n\n## Fit the model and get the summary\n#  Compare with \"Method 1\" in Table 2\nm1_fit &lt;- sem(m1, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m1_fit, standardized = TRUE, fit.measures = TRUE)\n\n## Reference-Group Method - Shortcut\nm1_short &lt;- \"\n  # Measurement Model\n  POS =~ pos1 + pos2 + pos3\n  NEG =~ neg1 + neg2 + neg3\n\"\n\nm1_short_fit &lt;- sem(m1_short, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, std.lv = TRUE,\n   group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m1_short_fit, standardized = TRUE, fit.measures = TRUE)\n\n## To see all means including those set to zero\nsummary(m1_short_fit, remove.unused = FALSE, standardized = TRUE,\n   fit.measures = TRUE)\n\n## The model - Marker-Variable Method\nm2c &lt;- \"\n  # Measurement Model\n  #   - Free the 1st loading in POS so it can be estimated\n  #   - Constrain 3rd loading in POS to 1 in both groups\n  #   - Constrain 1st loading in NEG to 1 in both groups\n  POS =~ NA*pos1 + pos2 + c(1,1)*pos3\n  NEG =~ c(1,1)*neg1 + neg2 + neg3\n\n  # Latent variances and covariance\n  POS ~~ POS\n  NEG ~~ NEG\n  POS ~~ NEG\n\n  # Indicator intercepts\n  #   - Constrain 3rd intercept in POS to 0 in both groups\n  #   - Constrain 1st intercept in NEG to 0 in both groups\n  pos1 ~ 1\n  pos2 ~ 1\n  pos3 ~ c(0,0)*1\n  neg1 ~ c(0,0)*1\n  neg2 ~ 1\n  neg3 ~ 1\n\n  # Latent means\n  POS ~ 1\n  NEG ~ 1\n\"\n\n## Fit the model and get the summary\n#  Compare with \"Method 2c\" in Table 2\nm2c_fit &lt;- sem(m2c, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m2c_fit, standardized = TRUE, fit.measures = TRUE)\n\n## Lavaan default method of scaling\nm2c_default &lt;- \"\n  # Measurement Model\n  POS =~ pos1 + pos2 + pos3\n  NEG =~ neg1 + neg2 + neg3\n\"\n\nm2c_default_fit &lt;- sem(m2c_default, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m2c_default_fit, remove.unused = FALSE,\n   standardized = TRUE, fit.measures = TRUE)\n\n## The model - Effects-Scaling Method\nm3 &lt;- \"\n  # Measurement Model\n  #   - Free the 1st loading so it can be estimated\n  #   - Label the loadings so they can be used in the constraints\n  POS =~ NA*p1*pos1 + p2*pos2 + p3*pos3\n  NEG =~ NA*n1*neg1 + n2*neg2 + n3*neg3\n\n  # Latent variances and covariance\n  POS ~~ POS\n  NEG ~~ NEG\n  POS ~~ NEG\n\n  # Indicator intercepts\n  #   - Label the intercepts so they can be used in the constraints\n  pos1 ~ ip1*1\n  pos2 ~ ip2*1\n  pos3 ~ ip3*1\n  neg1 ~ in1*1\n  neg2 ~ in2*1\n  neg3 ~ in3*1\n\n  # Latent means\n  POS ~ 1\n  NEG ~ 1\n\n  # Constraints\n  # For each construct:\n  #   The sum of the loadings equals the number of indicators\n  #   The sum of the intercepts equals zero\n  p1 + p2 + p3 == 3\n  n1 + n2 + n3 == 3\n\n  ip1 + ip2 + ip3 == 0\n  in1 + in2 + in3 == 0\n\"\n\n## Fit the model and get the summary\n#  Compare with \"Method 3\" in Table 2\nm3_fit &lt;- sem(m3, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m3_fit, standardized = TRUE, fit.measures = TRUE)\n\n## Effects-Scaling Method - Shortcut\nm3_short &lt;- \"\n  # Measurement Model\n  POS =~ pos1 + pos2 + pos3\n  NEG =~ neg1 + neg2 + neg3\n\"\n\nm3_short_fit &lt;- sem(m3_short, sample.cov = cov, sample.nobs = n,\n   sample.mean = mean, effect.coding = TRUE,\n   group.equal = c(\"loadings\", \"intercepts\"))\nsummary(m3_short_fit, standardized = TRUE, fit.measures = TRUE)\n\n## Get fit measures\n#  A function to extract fit measures\nGetFit &lt;- function(fit, ...) {\n   fitMeasures(fit, ...)\n}\n\n#  Add the fitted lavaan objects to a list\nmodels &lt;- list(\n   \"Method 1\"          = m1_fit,\n   \"Method 1 Shortcut\" = m1_short_fit,\n   \"Method 2c\"         = m2c_fit,\n   \"lavaan Default\"    = m2c_default_fit,\n   \"Method 3\"          = m3_fit,\n   \"Method 3 Shortcut\" = m3_short_fit)\n\n#  Select the fit measures\nmeasures &lt;- c(\"chisq\", \"df\", \"pvalue\", \"cfi\", \"tli\", \"rmsea\",\n   \"rmsea.ci.lower\", \"rmsea.ci.upper\")\n\n#  Get fit measures in a table\ntab &lt;- sapply(models, GetFit, measures)\ntab &lt;- t(round(tab, 4)); tab",
    "crumbs": [
      "SEMs with lavaan",
      "Scaling"
    ]
  },
  {
    "objectID": "SEMs_with_OpenMx/EasierExamples.html",
    "href": "SEMs_with_OpenMx/EasierExamples.html",
    "title": "Methods of scaling applied to easier examples",
    "section": "",
    "text": "A one-factor model.\n\n\n\nModel for Reference-Group Method\n\n\n\n\n\nModel for Marker-Variable Method\n\n\n\n\n\nModel for Effects-Scaling Method\n\n\n\n\n\nOneFactor.r\n#### Methods of Scaling and Identification\n\n## Some easier examples.\n## Demonstrates three methods of scaling in a one-factor model:\n## 1. Reference-Group Method - Constrain latent variable's variance and mean;\n## 2. Marker-Variable Method - Constrain one loading and that indicator's intercept;\n## 3. Effects-Scaling Method - Constrain sums of loadings and intercepts.\n\n## Compare results with lavaan's results\n\n## One Factor:\n#  \"Positive Affect\" factor for 7th grade\n\n# Data in Appendix A of:\n# Little, T., Slegers, D., & Card, N. (2006). A non-arbitrary method of\n# identifying and scaling latent variables in SEM and MACS models.\n# Structural Equation Modeling, 13(1), 59-72.\n\n## Load package\nlibrary(OpenMx)\n\n## Get data\n# Vectors of correlations (row-by-row), standard deviations, and means, and sample size.\nvcor &lt;- c(\n   1.00000,\n   0.75854,  1.00000,\n   0.76214,  0.78705,  1.00000)\n\nvmean &lt;- c(3.13552, 2.99061, 3.06945)\nvsd &lt;- c(0.66770, 0.68506, 0.70672)\nn &lt;- 380\n\n# Variable names\nnames &lt;- c(\"pos1\", \"pos2\", \"pos3\")\n\n# Get full correlation matrix\nmcor &lt;- matrix( , 3, 3)                          # Empty matrix\nmcor[upper.tri(mcor, diag = TRUE)] &lt;- vcor       # Fill the upper triangle\nmcor &lt;- pmax(mcor, t(mcor), na.rm = TRUE)        # Fill the lower triangle\n\n# Get co/variance matrix\nmcov &lt;- outer(vsd, vsd) * mcor\n\n# Name the rows and columns\ndimnames(mcov) &lt;- list(names, names); mcov\n\nnames(vmean) &lt;- names   # OpenMx requires the means be named\n\n# Get data into OpenMx format\ndata &lt;- mxData(observed = mcov, type = \"cov\", means = vmean, numObs = n)\n\n\n### Method 1: Reference-Group Method\n## Constrain latent variance to 1\n## Constrain latent mean to 0\n\n## Collect the bits and pieces needed by OpenMx\n# Factor loadings\nloadings &lt;- mxPath(from = \"POS\", to = names, arrows = 1,\n   free = TRUE, values = 0.5,\n   labels = c(\"lambda1\", \"lambda2\", \"lambda3\"))\n\n# Factor variance - Constrain variance to 1\nvarFac &lt;- mxPath(from = \"POS\", arrows = 2,\n   free = FALSE, values = 1,\n   labels = \"phi\")\n\n# Factor mean - Constrain mean to 0\nmeans &lt;- mxPath(from = \"one\", to = \"POS\", arrows = 1,\n   free = FALSE, values = 0,\n   labels = \"kappa\")\n\n# Residual variances\nvarRes &lt;- mxPath(from = names, arrows = 2,\n   free = TRUE, values = 1,\n   labels = c(\"theta1\", \"theta2\", \"theta3\"))\n\n# Intercepts\nintercepts &lt;- mxPath(from = \"one\", to = names, arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"tau1\", \"tau2\", \"tau3\"))\n\n## Setup the model\nmodel1 &lt;- mxModel(\"One Factor Model\", type = \"RAM\",\n   manifestVars = names, latentVars = \"POS\",\n   data, loadings, varFac, means, varRes, intercepts)\n\n## Run the model and get summary\nfit1 &lt;- mxRun(model1)\nsummary(fit1)\n\n# These models are just-identified.\n# Number of variables is 3;\n# Therefore, number of pieces of information in co/variance matrix: (3 X 4) / 2 = 6\n# plus 3 means = 9 pieces of information.\n# Number of parameters:\n#   3 loadings\n#   3 redisual variances\n#   3 intercepts\n#   Total of 9 parameters\n\n# Therefore, degrees of freedom is zero,\n# chi square is 0,\n# and other fit indices are either 1 or 0.\n# There is a small discrepancy - chi sq is not quite 0.\n# Note: the log likelihoods for the model and the saturated model differ.\n# OpenMx needs to estimate reference (saturated and independence) models.\n\nsummary(fit1, refModels = mxRefModels(fit1, run = TRUE))\ncoef(fit1)\n\n########################\n## Check with lavaan\nlibrary(lavaan)\n\nm1 &lt;- \"\n  # Loadings\n  POS =~ NA*lambda1*pos1 + lambda2*pos2 + lambda3*pos3\n\n  # Latent variance - Constrained to 1\n  POS ~~ 1*phi*POS\n\n  # Latent mean - Constrained to 0\n  POS ~ 0*kappa*1\n\n  # Residual variances\n  pos1 ~~ theta1*pos1\n  pos2 ~~ theta2*pos2\n  pos3 ~~ theta3*pos3\n\n  # Intercepts \n  pos1 ~ tau1*1\n  pos2 ~ tau2*1\n  pos3 ~ tau3*1\n\"\n\nm1_fit &lt;- sem(m1, sample.cov = mcov, sample.nobs = n, sample.mean = vmean)\nOpenMx &lt;- coef(fit1)\nlavaan &lt;- coef(m1_fit)\n\n# Get coefs in same order\nlavaan &lt;- lavaan[match(names(OpenMx), names(lavaan))]\ncbind(OpenMx, lavaan)\n########################\n\n\n### Method 2: Marker-Variable Method\n## Constrain third loading to 1\n## Constrain third intercept to 0\n\n## Collect the bits and pieces needed by OpenMx\n# Factor loadings - Constrain 3rd loading to 1\nloadings &lt;- mxPath(from = \"POS\", to = names, arrows = 1,\n   free = c(TRUE, TRUE, FALSE), values = c(0.5, 0.5, 1),\n   labels = c(\"lambda1\", \"lambda2\", \"lambda3\"))\n\n# Factor variance\nvarFac &lt;- mxPath(from = \"POS\", arrows = 2,\n   free = TRUE, values = 1,\n   labels = \"phi\")\n\n# Factor mean\nmeans &lt;- mxPath(from = \"one\", to = \"POS\", arrows = 1,\n   free = TRUE, values = 1,\n   labels = \"kappa\")\n\n# Residual variances\nvarRes &lt;- mxPath(from = names, arrows = 2,\n   free = TRUE, values = 1,\n   labels = c(\"theta1\", \"theta2\", \"theta3\"))\n\n# Intercepts - Constrain 3rd intercept to 0\nintercepts &lt;- mxPath(from = \"one\", to = names, arrows = 1,\n   free = c(TRUE, TRUE, FALSE), values = c(1, 1, 0),\n   labels = c(\"tau1\", \"tau2\", \"tau3\"))\n\n## Setup the model\nmodel2 &lt;- mxModel(\"One Factor Model\", type = \"RAM\",\n   manifestVars = names, latentVars = \"POS\",\n   data, loadings, varFac, means, varRes, intercepts)\n\n## Run the model and get summary\nfit2 &lt;- mxRun(model2)\nsummary(fit2, refModels = mxRefModels(fit2, run = TRUE))\ncoef(fit2)\n\n########################\n## Check with lavaan\nlibrary(lavaan)\n\nm2 &lt;- \"\n  # Loadings - Constrain 3rd loading to 1\n  POS =~ NA*lambda1*pos1 + lambda2*pos2 + 1*lambda3*pos3\n\n  # Latent variance\n  POS ~~ phi*POS\n\n  # Latent mean\n  POS ~ kappa*1\n\n  # Residual variances\n  pos1 ~~ theta1*pos1\n  pos2 ~~ theta2*pos2\n  pos3 ~~ theta3*pos3\n\n  # Intercepts - Constrain 3rd intercept to 0\n  pos1 ~ tau1*1\n  pos2 ~ tau2*1\n  pos3 ~ 0*tau3*1\n\"\n\nm2_fit &lt;- sem(m2, sample.cov = mcov, sample.nobs = n, sample.mean = vmean)\nOpenMx &lt;- coef(fit2)\nlavaan &lt;- coef(m2_fit)\n\n# Get coefs in same order\nlavaan &lt;- lavaan[match(names(OpenMx), names(lavaan))]      \ncbind(OpenMx, lavaan)\n########################\n\n\n### Method 3: Effects-Scaling Method\n## Constrain sum of loadings to equal number of loadings\n## Constrain sum of intercepts to equal 0\n\n## Collect the bits and pieces needed by OpenMx\n# Factor loadings\nloadings &lt;- mxPath(from = \"POS\", to = names, arrows = 1,\n   free = TRUE, values = 0.5,\n   labels = c(\"lambda1\", \"lambda2\", \"lambda3\"))\n\n# Factor variance\nvarFac &lt;- mxPath(from = \"POS\", arrows = 2,\n   free = TRUE, values = 1,\n   labels = \"phi\")\n\n# Factor mean\nmeans &lt;- mxPath(from = \"one\", to = \"POS\", arrows = 1,\n   free = TRUE, values = 1,\n   labels = \"kappa\")\n\n# Residual variances\nvarRes &lt;- mxPath(from = names, arrows = 2,\n   free = TRUE, values = 1,\n   labels = c(\"theta1\", \"theta2\", \"theta3\"))\n\n# Intercepts\nintercepts &lt;- mxPath(from = \"one\", to = names, arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"tau1\", \"tau2\", \"tau3\"))\n\n# Constraints\nconLoad &lt;- mxConstraint(lambda1 + lambda2 + lambda3 == 3)\nconInter &lt;- mxConstraint(tau1 + tau2 + tau3 == 0)\n\n## Setup the model\nmodel3 &lt;- mxModel(\"One Factor Model\", type = \"RAM\",\n   manifestVars = names, latentVars = \"POS\",\n   data, loadings, means, varFac, varRes, intercepts,\n   conLoad, conInter)\n\n## Run the model and get summary\nfit3 &lt;- mxRun(model3)\nsummary(fit3, refModels = mxRefModels(fit3, run = TRUE))\ncoef(fit3)\n\n########################\n## Check with lavaan\nlibrary(lavaan)\n\nm3 &lt;- \"\n  # Loadings\n  POS =~ NA*lambda1*pos1 + lambda2*pos2 + lambda3*pos3\n\n  # Latent variance\n  POS ~~ phi*POS\n\n  # Latent mean\n  POS ~ kappa*1\n\n  # Residual variances\n  pos1 ~~ theta1*pos1\n  pos2 ~~ theta2*pos2\n  pos3 ~~ theta3*pos3\n\n  # Intercepts \n  pos1 ~ tau1*1\n  pos2 ~ tau2*1\n  pos3 ~ tau3*1\n\n  # Constraints\n  lambda1 + lambda2 + lambda3 == 3\n  tau1 + tau2 + tau3 == 0\n\"\n\nm3_fit &lt;- sem(m3, sample.cov = mcov, sample.nobs = n, sample.mean = vmean)\nOpenMx &lt;- coef(fit3)\nlavaan &lt;- coef(m3_fit)\n\n# Get coefs in same order\nlavaan &lt;- lavaan[match(names(OpenMx), names(lavaan))]\ncbind(OpenMx, lavaan)\n########################\n\n\n\nA two-factor model\n\n\n\nModel for Reference-Group Method\n\n\n\n\n\nModel for Marker-Variable Method\n\n\n\n\n\nModel for Effects-Scaling Method\n\n\n\n\n\nTwoFactor.r\n#### Methods of Scaling and Identification\n\n## Some easier examples.\n## Demonstrates three methods of scaling in two-factor model:\n## 1. Reference-Group Method - Constrain latent variables' variances and means;\n## 2. Marker-Variable Method - Constrain one loading and that indicator's\n##    intercept in both factors;\n## 3. Effects-Scaling Method - Constrain sums of loadings and intercepts\n##    for both factors.\n\n## Compare results with lavaan's results\n\n## Two Factors\n#  \"Positive Affect\" and \"Negative Affect\" factors for 7th grade\n\n# Data in Appendix A of:\n# Little, T., Slegers, D., & Card, N. (2006). A non-arbitrary method of\n# identifying and scaling latent variables in SEM and MACS models.\n# Structural Equation Modeling, 13(1), 59-72.\n\n## Load package\nlibrary(OpenMx)\n\n## Get data\n# Vectors of correlations (row-by-row), standard deviations, and means, and sample size.\nvcor &lt;- c(\n   1.00000,\n   0.75854,  1.00000,\n   0.76214,  0.78705,  1.00000,\n   0.02766,  0.00973, -0.05762,  1.00000,\n  -0.06112, -0.06105, -0.14060,  0.78501,  1.00000,\n  -0.02222, -0.05180, -0.10250,  0.81616,  0.81076,  1.00000)\n\nvmean &lt;- c(3.13552, 2.99061, 3.06945, 1.70069, 1.52705, 1.54483)\nvsd &lt;- c(0.66770, 0.68506, 0.70672, 0.71418, 0.66320, 0.65276)\nn &lt;- 380\n\n# Variable names\nnames &lt;- c(\"pos1\", \"pos2\", \"pos3\", \"neg1\", \"neg2\", \"neg3\")\n\n# Get full correlation matrix\nmcor &lt;- matrix( , 6, 6)                          # Empty matrix\nmcor[upper.tri(mcor, diag = TRUE)] &lt;- vcor       # Fill the upper triangle\nmcor &lt;- pmax(mcor, t(mcor), na.rm = TRUE)        # Fill the lower triangle\n\n# Get co/variance matrix\nmcov &lt;- outer(vsd, vsd) * mcor\n\n# Name the rows and columns\ndimnames(mcov) &lt;- list(names, names)\nmcov\n\nnames(vmean) &lt;- names   # OpenMx requires the means be named\n\n# Get data into OpenMx format\ndata &lt;- mxData(observed = mcov, type = \"cov\", means = vmean, numObs = n)\n\n\n### Method 1: Reference-Group Method\n## Constrain latent variances to 1\n## Constrain latent means to 0\n\n## Collect the bits and pieces needed by OpenMx\n# Factor loadings\nloadings1 &lt;- mxPath(from = \"POS\", to = c(\"pos1\", \"pos2\", \"pos3\"), arrows = 1,\n   free = TRUE, values = 0.5,\n   labels = c(\"lambda1\", \"lambda2\", \"lambda3\"))\n\nloadings2 &lt;- mxPath(from = \"NEG\", to = c(\"neg1\", \"neg2\", \"neg3\"), arrows = 1,\n   free = TRUE, values = 0.5,\n   labels = c(\"lambda4\", \"lambda5\", \"lambda6\"))\n\n# Factor variances and covariance - constrain variances to 1\nvarFac &lt;- mxPath(from = c(\"POS\", \"NEG\"), arrows = 2, connect = \"unique.pairs\",\n   free = c(FALSE, TRUE, FALSE), values = 1,\n   labels = c(\"phi11\", \"phi12\", \"phi22\"))\n\n# Factor means - constrain means to 0\nmeans &lt;- mxPath(from = \"one\", to = c(\"POS\", \"NEG\"), arrows = 1,\n   free = FALSE, values = 0,\n   labels = c(\"kappa1\", \"kappa2\"))\n\n# Residual variances\nvarRes &lt;- mxPath(from = names, arrows = 2,\n   free = TRUE, values = 1, \n   labels = c(\"theta1\", \"theta2\", \"theta3\", \"theta4\", \"theta5\", \"theta6\"))\n\n# Intercepts\nintercepts &lt;- mxPath(from = \"one\", to = names, arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"tau1\", \"tau2\", \"tau3\", \"tau4\", \"tau5\", \"tau6\"))\n\n## Setup the model\nmodel1 &lt;- mxModel(\"Two Factor Model\", type = \"RAM\",\n   manifestVars = names, latentVars = c(\"POS\", \"NEG\"),\n   data, loadings1, loadings2, varFac, means, varRes, intercepts)\n\n## Run the model and get summary\nfit1 &lt;- mxRun(model1)\nsummary(fit1)\n\n# Number of variables is 6;\n# Number of pieces of information in covariance matrix: (6 X 7) / 2 = 21\n# plus 6 means = 27 pieces of information\n# Number of parameters:\n#   6 loadings (3 per factor)\n#   1 covariance between factors\n#   6 residual variances (3 per factor)\n#   6 intercepts (3 per factor)\n#   Total of 19 parameters\n \n# Therefore, degrees of freedom = 8,\n# and chi sq and fit indices are calculated.\n# But make sure OpenMx estimates reference models (saturated and independence)\n# upon which to base calculations for chi sq and fit indices.\n\nsummary(fit1, refModels = mxRefModels(fit1, run = TRUE))\ncoef(fit1)\n\n########################\n## Check with lavaan\nlibrary(lavaan)\n\nm1 &lt;- \"\n  # Loadings\n  POS =~ NA*lambda1*pos1 + lambda2*pos2 + lambda3*pos3\n  NEG =~ NA*lambda4*neg1 + lambda5*neg2 + lambda6*neg3\n\n  # Latent variances and covariance - constrain variances to 1\n  POS ~~ 1*phi11*POS\n  NEG ~~ 1*phi22*NEG\n  POS ~~ phi12*NEG\n\n  # Latent means - constrain means to 0\n  POS ~ 0*kappa1*1\n  NEG ~ 0*kappa2*1\n\n  # Residual variances\n  pos1 ~~ theta1*pos1\n  pos2 ~~ theta2*pos2\n  pos3 ~~ theta3*pos3\n  neg1 ~~ theta4*neg1\n  neg2 ~~ theta5*neg2\n  neg3 ~~ theta6*neg3\n\n  # Intercepts \n  pos1 ~ tau1*1\n  pos2 ~ tau2*1\n  pos3 ~ tau3*1\n  neg1 ~ tau4*1\n  neg2 ~ tau5*1\n  neg3 ~ tau6*1\n\"\n\nm1_fit &lt;- sem(m1, sample.cov = mcov, sample.nobs = n, sample.mean = vmean)\nsummary(m1_fit)\nOpenMx &lt;- coef(fit1)\nlavaan &lt;- coef(m1_fit)\n\n# Get coefs in same order\nlavaan &lt;- lavaan[match(names(OpenMx), names(lavaan))]\ncbind(OpenMx, lavaan)\n########################\n\n\n\n### Method 2: Marker-Variable Method\n## Constrain 3rd loading for POS and 1st loading for NEG to 1\n## Constrain 3rd intercept for POS and 1st intercept for NEG to 0\n\n## Collect the bits and pieces needed by OpenMx\n# Factor loadings - Constrain 3rd loading for POS & 1st loading for NEG to 1\nloadings1 &lt;- mxPath(from = \"POS\", to = c(\"pos1\", \"pos2\", \"pos3\"), arrows = 1,\n   free = c(TRUE, TRUE, FALSE), values = c(0.5, 0.5, 1),\n   labels = c(\"lambda1\", \"lambda2\", \"lambda3\"))\n\nloadings2 &lt;- mxPath(from = \"NEG\", to = c(\"neg1\", \"neg2\", \"neg3\"), arrows = 1,\n   free = c(FALSE, TRUE, TRUE), values = c(1, 0.5, 0.5),\n   labels = c(\"lambda4\", \"lambda5\", \"lambda6\"))\n\n# Factor variances and covariance\nvarFac &lt;- mxPath(from = c(\"POS\", \"NEG\"), arrows = 2, connect = \"unique.pairs\",\n   free = TRUE, values = c(1, 0.5, 1),\n   labels = c(\"phi11\", \"phi12\", \"phi22\"))\n\n# Factor means\nmeans &lt;- mxPath(from = \"one\", to = c(\"POS\", \"NEG\"), arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"kappa1\", \"kappa2\"))\n\n# Residual variances\nvarRes &lt;- mxPath(from = names, arrows = 2,\n   free = TRUE, values = 1,\n   labels = c(\"theta1\", \"theta2\", \"theta3\", \"theta4\", \"theta5\", \"theta6\"))\n\n# Intercepts - constrain 3rd intercept for POS & 1st intercept for NEG to 0\nintercepts &lt;- mxPath(from = \"one\", to = names, arrows = 1,\n   free = c(TRUE, TRUE, FALSE, FALSE, TRUE, TRUE),\n   values = c(1, 1, 0, 0, 1, 1),\n   labels = c(\"tau1\", \"tau2\", \"tau3\", \"tau4\", \"tau5\", \"tau6\"))\n\n## Setup the model\nmodel2 &lt;- mxModel(\"Two Factor Model\", type = \"RAM\",\n   manifestVars = names, latentVars = c(\"POS\", \"NEG\"),\n   data, loadings1, loadings2, varFac, means, varRes, intercepts)\n\n## Run the model and get summary\nfit2 &lt;- mxRun(model2)\nsummary(fit2, refModels = mxRefModels(fit2, run = TRUE))\ncoef(fit2)\n\n########################\n## Check with lavaan\nlibrary(lavaan)\n\nm2 &lt;- \"\n  # Loadings - Constrain 3rd loading for POS & 1st loading for NEG to 1\n  POS =~ NA*lambda1*pos1 + lambda2*pos2 + 1*lambda3*pos3\n  NEG =~  1*lambda4*neg1 + lambda5*neg2 + lambda6*neg3\n\n  # Latent variances and covariance\n  POS ~~ phi11*POS\n  NEG ~~ phi22*NEG\n  POS ~~ phi12*NEG\n\n  # Latent means \n  POS ~ kappa1*1\n  NEG ~ kappa2*1\n\n  # Residual variances\n  pos1 ~~ theta1*pos1\n  pos2 ~~ theta2*pos2\n  pos3 ~~ theta3*pos3\n  neg1 ~~ theta4*neg1\n  neg2 ~~ theta5*neg2\n  neg3 ~~ theta6*neg3  \n\n  # Intercepts - Constrain 3rd intercept for POS & 1st intercept for NEG to 0\n  pos1 ~ tau1*1\n  pos2 ~ tau2*1\n  pos3 ~ 0*tau3*1\n  neg1 ~ 0*tau4*1\n  neg2 ~ tau5*1\n  neg3 ~ tau6*1\n\"\n\nm2_fit &lt;- sem(m2, sample.cov = mcov, sample.nobs = n, sample.mean = vmean)\nOpenMx &lt;- coef(fit2)\nlavaan &lt;- coef(m2_fit)\n\n# Get coefs in same order\nlavaan &lt;- lavaan[match(names(OpenMx), names(lavaan))]\ncbind(OpenMx, lavaan)\n########################\n\n\n### Method 3: Effects-Scaling Method\n## Constrain sum of loadings to equal number of loadings\n## Constrain sum of intercepts to equal 0\n\n## Collect the bits and pieces needed by OpenMx\n# Factor loadings\nloadings1 &lt;- mxPath(from = \"POS\", to = c(\"pos1\", \"pos2\", \"pos3\"), arrows = 1,\n   free = TRUE, values = 0.5,\n   labels = c(\"lambda1\", \"lambda2\", \"lambda3\"))\n\nloadings2 &lt;- mxPath(from = \"NEG\", to = c(\"neg1\", \"neg2\", \"neg3\"), arrows = 1,\n   free = TRUE, values = 0.5,\n   labels = c(\"lambda4\", \"lambda5\", \"lambda6\"))\n\n# Factor variances and covariance\nvarFac &lt;- mxPath(from = c(\"POS\", \"NEG\"), arrows = 2, connect = \"unique.pairs\",\n   free = TRUE, values = 1, labels = c(\"phi11\", \"phi12\", \"phi22\"))\n\n# Factor means\nmeans &lt;- mxPath(from = \"one\", to = c(\"POS\", \"NEG\"), arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"kappa1\", \"kappa2\"))\n\n# Residual variances\nvarRes &lt;- mxPath(from = names, arrows = 2,\n   free = TRUE, values = 1,\n   labels = c(\"theta1\", \"theta2\", \"theta3\", \"theta4\", \"theta5\", \"theta6\"))\n\n# Intercepts\nintercepts &lt;- mxPath(from = \"one\", to = names, arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"tau1\", \"tau2\", \"tau3\", \"tau4\", \"tau5\", \"tau6\"))\n\n# Constraints\nconLoadPOS &lt;- mxConstraint(lambda1 + lambda2 + lambda3 == 3)\nconLoadNEG &lt;- mxConstraint(lambda4 + lambda5 + lambda6 == 3)\nconInterPOS &lt;- mxConstraint(tau1 + tau2 + tau3 == 0)\nconInterNEG &lt;- mxConstraint(tau4 + tau5 + tau6 == 0)\n\n## Setup the model\nmodel3 &lt;- mxModel(\"Two Factor Model\", type = \"RAM\",\n   manifestVars = names, latentVars = c(\"POS\", \"NEG\"),\n   data, loadings1, loadings2, varFac, means, varRes, intercepts,\n   conLoadPOS, conLoadNEG, conInterPOS, conInterNEG)\n\n## Run the model and get summary\nfit3 &lt;- mxRun(model3)\nsummary(fit3, refModels = mxRefModels(fit3, run = TRUE))\ncoef(fit3)\n\n########################\n## Check with lavaan\nlibrary(lavaan)\n\nm3 &lt;- \"\n  # Loadings\n  POS =~ NA*lambda1*pos1 + lambda2*pos2 + lambda3*pos3\n  NEG =~ NA*lambda4*neg1 + lambda5*neg2 + lambda6*neg3\n\n  # Latent variances and covariance\n  POS ~~ phi11*POS\n  NEG ~~ phi22*NEG\n  POS ~~ phi12*NEG\n\n  # Latent means\n  POS ~ kappa1*1\n  NEG ~ kappa2*1\n\n  # Residual variances\n  pos1 ~~ theta1*pos1\n  pos2 ~~ theta2*pos2\n  pos3 ~~ theta3*pos3\n  neg1 ~~ theta4*neg1\n  neg2 ~~ theta5*neg2\n  neg3 ~~ theta6*neg3\n\n  # Intercepts \n  pos1 ~ tau1*1\n  pos2 ~ tau2*1\n  pos3 ~ tau3*1\n  neg1 ~ tau4*1\n  neg2 ~ tau5*1\n  neg3 ~ tau6*1\n\n  # Constraints\n  lambda1 + lambda2 + lambda3 == 3\n  lambda4 + lambda5 + lambda6 == 3\n\n  tau1 + tau2 + tau3 == 0\n  tau4 + tau5 + tau6 == 0\n\"\n\nm3_fit &lt;- sem(m3, sample.cov = mcov, sample.nobs = n, sample.mean = vmean)\nsummary(m3_fit)\nOpenMx &lt;- coef(fit3)\nlavaan &lt;- coef(m3_fit)\n\n# Get coefs in same order\nlavaan &lt;- lavaan[match(names(OpenMx), names(lavaan))]\ncbind(OpenMx, lavaan)\n########################\n\n\n\nA one-factor two-group model\n\n\n\nModel for Reference-Group Method\n\n\n\n\n\nModel for Marker-Variable Method\n\n\n\n\n\nModel for Effects-Scaling Method\n\n\n\n\n\nOneFactorTwoGroup.r\n#### Methods of Scaling and Identification\n\n## Some easier examples.\n## Demonstrates three methods of scaling in one-factor, two-group model:\n## 1. Reference-Group Method - Constrain latent variable's variance and mean;\n## 2. Marker-Variable Method - Constrain one loading and that indicator's intercept;\n## 3. Effects-Scaling Method - Constrain sums of loadings and intercepts.\n\n## Following Little et al's lead, assume strong metric invariance:\n## corresponding loadings and intercepts constrained to equality across groups\n\n## Compare results from OpenMx with lavaan's results\n\n## One Factor, Two Groups\n#  \"Positive Affect\" factor for 7th and 8th grades\n\n# Data in Appendix A of:\n# Little, T., Slegers, D., & Card, N. (2006). A non-arbitrary method of\n# identifying and scaling latent variables in SEM and MACS models.\n# Structural Equation Modeling, 13(1), 59-72.\n\n## Load package\nlibrary(OpenMx)\n\n## Get data\n# Vectors of correlations (row-by-row), standard deviations, and means, and sample size.\n# 7th grade\nvcor7 &lt;- c(\n   1.00000,\n   0.75854,  1.00000,\n   0.76214,  0.78705,  1.00000)\n\nvmean7 &lt;- c(3.13552, 2.99061, 3.06945)\nvsd7 &lt;- c(0.66770, 0.68506, 0.70672)\nn7 &lt;- 380\n\n# 8th grade\nvcor8 &lt;- c(\n   1.00000,\n   0.81366,  1.00000,\n   0.84980,  0.83523,  1.00000)\n\nvmean8 &lt;- c(3.07338, 2.84716, 2.97882)\nvsd8 &lt;- c(0.70299, 0.71780, 0.76208)\nn8 &lt;- 379\n\n# Variable names\nnames &lt;- c(\"pos1\", \"pos2\", \"pos3\")\n\n# Get full correlation matrix for each Grade\nmcor7 &lt;- matrix( , 3, 3)                           # Empty matrix\nmcor7[upper.tri(mcor7, diag = TRUE)] &lt;- vcor7      # Fill the upper triangle\nmcor7 &lt;- pmax(mcor7, t(mcor7), na.rm = TRUE)       # Fill the lower triangle\n\nmcor8 &lt;- matrix( , 3, 3)                           # Empty matrix\nmcor8[upper.tri(mcor8, diag = TRUE)] &lt;- vcor8      # Fill the upper triangle\nmcor8 &lt;- pmax(mcor8, t(mcor8), na.rm = TRUE)       # Fill the lower triangle\n\n# Get co/variance matrices\nmcov7 &lt;- outer(vsd7, vsd7) * mcor7\nmcov8 &lt;- outer(vsd8, vsd8) * mcor8\n\n# Name the rows and columns\ndimnames(mcov7) &lt;- list(names, names)\ndimnames(mcov8) &lt;- list(names, names)\nmcov7; mcov8\n\nnames(vmean7) &lt;- names   # OpenMx requires the means be named\nnames(vmean8) &lt;- names\n\n# Put data into lists - used in lavaan analysis\nmcov &lt;- list(\"Grade 7\" = mcov7, \"Grade 8\" = mcov8)\nvmean &lt;- list(vmean7, vmean8)\nn &lt;- list(n7, n8)\n\n# Get data into OpenMx format\ndata7 &lt;- mxData(observed = mcov7, type = \"cov\", means = vmean7, numObs = n7)\ndata8 &lt;- mxData(observed = mcov8, type = \"cov\", means = vmean8, numObs = n8)\n\n\n### Method 1: Reference-Group Method\n## Constrain latent variance to 1\n## Constrain latent mean to 0\n## These constraints apply to Grade 7 only.\n\n## Collect the bits and pieces needed by OpenMx\n# Factor loadings\nloadings &lt;- mxPath(from = \"POS\", to = names, arrows = 1,\n   free = TRUE, values = 0.5,\n   labels = c(\"lambda1\", \"lambda2\", \"lambda3\"))\n\n# Factor variances - Constrain Grade 7 variance to 1\nvarFac7 &lt;- mxPath(from = \"POS\", arrows = 2,\n   free = FALSE, values = 1, labels = \"phi7\")\n\nvarFac8 &lt;- mxPath(from = \"POS\", arrows = 2,\n   free = TRUE, values = 1, labels = \"phi8\")\n\n# Factor means - Constrain Grade 7 mean to 0\nmeans7 &lt;- mxPath(from = \"one\", to = \"POS\", arrows = 1,\n   free = FALSE, values = 0, labels = \"kappa7\")\n\nmeans8 &lt;- mxPath(from = \"one\", to = \"POS\", arrows = 1,\n   free = TRUE, values = 1, labels = \"kappa8\") \n\n# Residual variances\nvarRes7 &lt;- mxPath(from = names, arrows = 2,\n   free = TRUE, values = 1,\n   labels = c(\"theta71\", \"theta72\", \"theta73\"))\n\nvarRes8 &lt;- mxPath(from = names, arrows = 2,\n   free = TRUE, values = 1, \n   labels = c(\"theta81\", \"theta82\", \"theta83\"))\n\n# Intercepts\nintercepts &lt;- mxPath(from = \"one\", to = names, arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"tau1\", \"tau2\", \"tau3\"))\n\n## Setup models for each Grade\nmodGr7 &lt;- mxModel(\"Grade7\", type = \"RAM\",\n   manifestVars = names, latentVars = \"POS\",\n   data7, loadings, varFac7, means7, varRes7, intercepts)\n\nmodGr8 &lt;- mxModel(\"Grade8\", type = \"RAM\",\n   manifestVars = names, latentVars = \"POS\",\n   data8, loadings, varFac8, means8, varRes8, intercepts)\n\n## Combine the two models\nfun &lt;- mxFitFunctionMultigroup(c(\"Grade7.fitfunction\", \"Grade8.fitfunction\"))\nmodel1 &lt;- mxModel(\"One Factor Two Group Model\", modGr7, modGr8, fun)\n\n## Run the model and get summary\nfit1 &lt;- mxRun(model1)\nsummary(fit1)\n\n# Number of variables: 3\n# Number of pices of information in co/variance matrix: (3 X 4) / 2 = 6\n# plus 3 means = 9 pieces of information for each group;\n# that is, 18 for the model\n\n# Number of parameters:\n#   3 loadings (constrained to equality across groups)\n#   1 latent mean\n#   1 latent variance\n#   6 residual variances (3 per group)\n#   3 intercepts (constrained to equality across groups)\n#   Total of 14 parameters\n\n# Therefore, degrees of freedom = 4,\n# and chi sq and fit indices are calculated.\n# But make sure OpenMx estimates the reference models\n# upon which to base calculations for chi sq and fit indices.\n\nsummary(fit1, refModels = mxRefModels(fit1, run = TRUE))\ncoef(fit1)\n\n########################\n## Check with lavaan\nlibrary(lavaan)\n\nm1 &lt;- \"\n  # Loadings\n  POS =~ c(NA,NA)*c(lambda1, lambda1)*pos1 + c(lambda2, lambda2)*pos2 + c(lambda3, lambda3)*pos3\n\n  # Latent variances - Constrain Grade 7 variance to 1\n  POS ~~ c(1, NA)*c(phi7, phi8)*POS\n\n  # Latent means - Constrain Grade 7 mean to 0\n  POS ~ c(0, NA)*c(kappa7, kappa8)*1\n\n  # Residual variances\n  pos1 ~~ c(theta71, theta81)*pos1\n  pos2 ~~ c(theta72, theta82)*pos2\n  pos3 ~~ c(theta73, theta83)*pos3\n\n  # Intercepts\n  pos1 ~ c(tau1, tau1)*1\n  pos2 ~ c(tau2, tau2)*1\n  pos3 ~ c(tau3, tau3)*1\n\"\n\nm1_fit &lt;- sem(m1, sample.cov = mcov, sample.nobs = n, sample.mean = vmean)\nsummary(m1_fit)\nOpenMx &lt;- coef(fit1)\nlavaan &lt;- coef(m1_fit)\n\n# Get coefs in same order\nlavaan &lt;- lavaan[match(names(OpenMx), names(lavaan))]\ncbind(OpenMx, lavaan)\n########################\n\n\n### Method: Marker-Variable Method\n## Constrain third loading in POS to 1\n## Constrain third intercept to 0\n## With strong measurement invariance,\n## these constraints apply to both Grades.\n\n## Collect the bits and pieces needed by OpenMx\n# Factor loadings - Constrain 3rd loading to 1\nloadings &lt;- mxPath(from = \"POS\", to = names, arrows = 1,\n   free = c(TRUE, TRUE, FALSE), values = c(0.5, 0.5, 1),\n   labels = c(\"lambda1\", \"lambda2\", \"lambda3\"))\n\n# Factor variances\nvarFac7 &lt;- mxPath(from = \"POS\", arrows = 2,\n   free = TRUE, values = 1, labels = \"phi7\")\n\nvarFac8 &lt;- mxPath(from = \"POS\", arrows = 2,\n   free = TRUE, values = 1, labels = \"phi8\")\n\n# Factor means\nmeans7 &lt;- mxPath(from = \"one\", to = \"POS\", arrows = 1,\n   free = TRUE, values = 1, labels = \"kappa7\")\n\nmeans8 &lt;- mxPath(from = \"one\", to = \"POS\", arrows = 1,\n   free = TRUE, values = 1, labels = \"kappa8\")\n\n# Residual variances\nvarRes7 &lt;- mxPath(from = names, arrows = 2,\n   free = TRUE, values = 1,\n   labels = c(\"theta71\", \"theta72\", \"theta73\"))\n\nvarRes8 &lt;- mxPath(from = names, arrows = 2,\n   free = TRUE, values = 1,\n   labels = c(\"theta81\", \"theta82\", \"theta83\"))\n\n# Intercepts - Constrain 3rd intercept to 0\nintercepts &lt;- mxPath(from = \"one\", to = names, arrows = 1,\n   free = c(TRUE, TRUE, FALSE), values = c(1, 1, 0),\n   labels = c(\"tau1\", \"tau2\", \"tau3\"))\n\n## Setup models for each Grade\nmodGr7 &lt;- mxModel(\"Grade7\", type = \"RAM\",\n   manifestVars = names, latentVars = \"POS\",\n   data7, loadings, varFac7, means7, varRes7, intercepts)\n\nmodGr8 &lt;- mxModel(\"Grade8\", type = \"RAM\",\n   manifestVars = names, latentVars = \"POS\",\n   data8, loadings, varFac8, means8, varRes8, intercepts)\n\n## Combine the two models using \"mxFitFunctionMultigroup()\"\nfun &lt;- mxFitFunctionMultigroup(c(\"Grade7.fitfunction\", \"Grade8.fitfunction\"))\nmodel2 &lt;- mxModel(\"One Factor Two Group Model\", modGr7, modGr8, fun)\n\n## Run the model and get summary\nfit2 &lt;- mxRun(model2)\nsummary(fit2, refModels = mxRefModels(fit2, run = TRUE))\ncoef(fit2)\n\n########################\n## Check with lavaan\nlibrary(lavaan)\n\nm2 &lt;- \"\n  # Loadings - Constrain 3rd loading to 1 in both Grades\n  POS =~ c(NA,NA)*c(lambda1, lambda1)*pos1 + c(lambda2, lambda2)*pos2 + c(1,1)*c(lambda3, lambda3)*pos3\n\n  # Latent variances\n  POS ~~ c(phi7, phi8)*POS\n\n  # Latent means\n  POS ~ c(kappa7, kappa8)*1\n\n  # Residual variances\n  pos1 ~~ c(theta71, theta81)*pos1\n  pos2 ~~ c(theta72, theta82)*pos2\n  pos3 ~~ c(theta73, theta83)*pos3\n\n  # Intercepts - Constrain 3rd intercept to 0 in both Grades\n  pos1 ~ c(tau1, tau1)*1\n  pos2 ~ c(tau2, tau2)*1\n  pos3 ~ c(0,0)*c(tau3, tau3)*1\n\"\n\nm2_fit &lt;- sem(m2, sample.cov = mcov, sample.nobs = n, sample.mean = vmean)\nsummary(m2_fit)\nOpenMx &lt;- coef(fit2)\nlavaan &lt;- coef(m2_fit)\n\n# Get coefs in same order\nlavaan &lt;- lavaan[match(names(OpenMx), names(lavaan))]\ncbind(OpenMx, lavaan)\n########################\n\n\n### Method 3\n## Constrain sum of loadings to equal number of loadings\n## Constrain sum of intercepts to equal 0\n## With strong measurement invariance,\n## these constraints apply to both Grades.\n\n## Collect the bits and pieces needed by OpenMx\n# Factor loadings\nloadings &lt;- mxPath(from = \"POS\", to = names, arrows = 1,\n   free = TRUE, values = 0.5,\n   labels = c(\"lambda1\", \"lambda2\", \"lambda3\"))\n\n# Factor variances\nvarFac7 &lt;- mxPath(from = \"POS\", arrows = 2,\n   free = TRUE, values = 1, labels = \"phi7\")\n\nvarFac8 &lt;- mxPath(from = \"POS\", arrows = 2,\n   free = TRUE, values = 1, labels = \"phi8\")\n\n# Factor means\nmeans7 &lt;- mxPath(from = \"one\", to = \"POS\", arrows = 1,\n   free = TRUE, values = 0, labels = \"kappa7\")\n\nmeans8 &lt;- mxPath(from = \"one\", to = \"POS\", arrows = 1,\n   free = TRUE, values = 1, labels = \"kappa8\")\n\n# Residual variances\nvarRes7 &lt;- mxPath(from = names, arrows = 2,\n   free = TRUE, values = 1,\n   labels = c(\"theta71\", \"theta72\", \"theta73\"))\n\nvarRes8 &lt;- mxPath(from = names, arrows = 2,\n   free = TRUE, values = 1,\n   labels = c(\"theta81\", \"theta82\", \"theta83\"))\n\n# Intercepts\nintercepts &lt;- mxPath(from = \"one\", to = names, arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"tau1\", \"tau2\", \"tau3\"))\n\n## Setup models for each Grade\nmodGr7 &lt;- mxModel(\"Grade7\", type = \"RAM\",\n   manifestVars = names, latentVars = \"POS\",\n   data7, loadings, varFac7, means7, varRes7, intercepts)\n\nmodGr8 &lt;- mxModel(\"Grade8\", type = \"RAM\",\n   manifestVars = names, latentVars = \"POS\",\n   data8, loadings, varFac8, means8, varRes8, intercepts)\n\n## Constraints\nconLoad &lt;- mxConstraint(lambda1 + lambda2 + lambda3 == 3)\nconInter &lt;- mxConstraint(tau1 + tau2 + tau3 == 0)\n\n## Combine the two models\nfun &lt;- mxFitFunctionMultigroup(c(\"Grade7.fitfunction\", \"Grade8.fitfunction\"))\nmodel3 &lt;- mxModel(\"One Factor Two Group Model\", modGr7, modGr8,\n   conLoad, conInter, fun)\n\n# Note: Constraints are added to final model, not to each of the Grade7 and Grade 8 models;\n# otherwise, OpenMx will count them as 4 constraints, accounting for 4 degrees of freedom,\n# instead of 2.\n\n## Run the model and get summary\nfit3 &lt;- mxRun(model3)\nsummary(fit3, refModels = mxRefModels(fit3, run = TRUE))\n\n# Counting degrees of freedom.\n# Number of variables: 3\n# Number of pieces of information in the covariance matrix: 6\n# plus 3 means = 9 per group;\n# that is, 18 for the model\n\n# Number of parameters:\n# 3 loadings (constrained to equality across the groups)\n# 3 intercepts (constrained to equality across the groups)\n# 6 residual variances (3 per group)\n# 2 latent means (1 per group)\n# 2 latent variances (1 per group)\n# Total of 16\n# but take away 2 for the 2 constraints = 14,\n# resulting in 18 - 14 = 4 degrees of freedom.\n#\n# If the constraints were added to each Grade's model,\n# OpenMx would have counted them as 4 constraints (even thought they are identical),\n# resulting in 6 degrees of freedom for the model.\n\n########################\n## Check with lavaan\nlibrary(lavaan)\n\nm3 &lt;- \"\n  # Loadings\n  POS =~ c(NA,NA)*c(lambda1, lambda1)*pos1 + c(lambda2, lambda2)*pos2 + c(lambda3, lambda3)*pos3\n\n  # Latent variances\n  POS ~~ c(phi7, phi8)*POS\n\n  # Latent means\n  POS ~ c(kappa7, kappa8)*1\n\n  # Residual variances\n  pos1 ~~ c(theta71, theta81)*pos1\n  pos2 ~~ c(theta72, theta82)*pos2\n  pos3 ~~ c(theta73, theta83)*pos3\n\n  # Intercepts\n  pos1 ~ c(tau1, tau1)*1\n  pos2 ~ c(tau2, tau2)*1\n  pos3 ~ c(tau3, tau3)*1\n\n  # Constraints\n  lambda1 + lambda2 + lambda3 == 3\n  tau1 + tau2 + tau3 == 0\n\"\n\nm3_fit &lt;- sem(m3, sample.cov = mcov, sample.nobs = n, sample.mean = vmean)\nsummary(m3_fit)\nOpenMx &lt;- coef(fit3)\nlavaan &lt;- coef(m3_fit)\n\n# Get coefs in same order\nlavaan &lt;- lavaan[match(names(OpenMx), names(lavaan))]\ncbind(OpenMx, lavaan)\n########################"
  },
  {
    "objectID": "SEMs_with_OpenMx/index.html",
    "href": "SEMs_with_OpenMx/index.html",
    "title": "",
    "section": "",
    "text": "Reproducing published Structural Equation Models with OpenMx\n\n\n\n\n\n\n\nThis post presents R scripts to reproduce published Structural Equation Modeling analyses using OpenMx.\nClick on the R file to see the R script. Click on the model to see a diagram of the model.\n\nThe publications\n\nJose, P. (2013). Doing statistical mediation and moderation. New York, NY: Guilford Press.  A basic three-variable mediation analysis (See Chapter 3).\n\n\n\nMediation model\n\n\n\n\n\nJose_2013.r\n## Jose, P. (2013). Doing statistical mediation and moderation. \n## New York, NY: Guilford Press.\n\n## Chapter 3 describes a basic three-variable mediation analysis.\n\n## Load packages\nlibrary(OpenMx)\nlibrary(haven)   # To read SPSS data files\n\n# OpenMx is very verbose;\n# it requires everything to be coded;\n# means and intercepts must be included.\n\n## Get the data from Guilford Press web site\nurl &lt;- \"http://www.guilford.com/add/jose/mediation_example.sav\"\ndf &lt;- data.frame(haven::read_spss(url))\n\nstr(df)\nhead(df)\nsummary(df)\n\n## The model is shown in Fig 3.3 (p. 46);\n## or see the model diagram above.\n\n#### Collect the bits and pieces needed by OpenMx\n## Get the names of the variables\nmanifest &lt;- names(df)\n\n## Get data into OpenMx format\ndataRaw &lt;- mxData(observed = df, type = \"raw\")\n\n## Regressions\n#  - Arrows from \"ple\" and \"grat\" to \"shs\".\n#  - Arrows are single headed - arrow head at \"shs\".\n#  - Starting values are 0.5.  When they are the same,\n#    they need to be listed once only.\n#  - Labels are \"cprime\" for arrow \"ple\" to \"shs\";\n#    and \"b\" for arrow \"grat\" to \"shs\".\nregPaths1 &lt;- mxPath(from = c(\"ple\", \"grat\"), to = \"shs\",\n   arrows = 1, values = 0.5,\n   labels = c(\"cprime\", \"b\"))\n\n#  - Arrow from \"ple\" to \"grat\".\n#  - Arrow is single headed - arrow head at \"grat\".\n#  - Starting value is 0.5.\n#  - Label is \"a\".\nregPaths2 &lt;- mxPath(from = \"ple\", to = \"grat\",\n   arrows = 1, values = 0.5,\n   labels = \"a\")\n\n## Variances\n## Exogenous variables (\"ple\") have variances;\n## Endogenous variables (\"grat\" and \"shs\") have residual or error variances.\n## Variance for exogenous variable is not shown in the model diagram.\n## The distinction does not matter to OpenMx, but I distinguish in the labels.\n\n#  - Arrows are from manifest variables to manifest variables\n#    (when \"arrows = 2\", the \"to\" argument can be omitted); \n#    ie, from \"ple\" to \"ple\"; from \"grat\" to \"grat\"; and from \"shs\" to \"shs\".\n#  - Arrows are two headed.\n#  - Starting values are 1.\n#  - Labels are \"vPLE\" \"eGRAT\", and \"eSHS\".\nvarPaths &lt;- mxPath(from = manifest,\n   arrows = 2, values = 1,\n   labels = c(\"vPLE\", \"eGRAT\", \"eSHS\"))\n\n## Means and intercepts\n## Exogenous variables (\"ple\") have means;\n## Endogenous variables (\"grat\" and \"shs\") have intercepts.\n## Regress variables on a constant - in OpenMx, \"one\".\n## Means and intercepts are not shown in the model diagram.\n## The distinction does not matter to OpenMx, but I distinguish in the labels.\n\n#  - Arrows from \"one\" to the manifest variables;\n#    ie, from \"one\" to \"ple\"; from \"one\" to \"grat\"; from \"one\" to \"shs\".\n#  - Arrows are single headed.\n#  - Starting values are 1.\n#  - labels are \"mPLE\", \"iGRAT\", \"iSHS\".\nmeans &lt;- mxPath(from = \"one\", to = manifest,\n   arrows = 1, values = 1,\n   labels = c(\"mPLE\", \"iGRAT\", \"iSHS\"))\n\n## Indirect and total effects\nindirect &lt;- mxAlgebra(a * b, name = \"indirect\")\ntotal &lt;- mxAlgebra(a * b + cprime, name = \"total\")\n\n## Setup the model with all the bits\nmedModel &lt;- mxModel(model = \"Mediation\",\n   type = \"RAM\",\n   data = dataRaw,\n   manifestVars = manifest,\n   varPaths,\n   regPaths1, regPaths2,\n   means, \n   indirect, total)\n\n## Run the model and get summary\n# Compare with regression outputs in Tables 3.4 and 3.5 (p. 52)\nfit &lt;- mxRun(medModel)\nsummary(fit)   # Note: summary() does not return indirect and total effects\ncoef(fit)      # Just the estimates\n\n## Extract indirect and total effects (and their standard errors) from \"fit\" object\n# Compare with unstandardised indirect and total effect in Fig 3.6 (p. 59).\nestimates &lt;- mxEval(c(indirect, total), fit); estimates\nSE &lt;- sapply(c(\"indirect\", \"total\"), function(x) mxSE(x, fit, silent = TRUE)); SE\n\n## To get the standardised effects, mxStandardizeRAMpaths(fit) will give standardised\n## effects for free parameters, but not derived effects.\n\n# Could use mxStandardizeRAMpaths(fit) to extract standardised \"a\", \"b\", and \"cprime\",\n# then calculate standardised indirect effect (a * b),\n# and standardised total effect (a * b + cprime) by hand.\n\n# Compare with standardised indirect and total effect in Fig 3.6.\n# Compare standardised regression coefficients given in Fig 3.6, or\n# in Tables 3.4 and 3.5.\nmxStandardizeRAMpaths(fit)\nestZ &lt;- mxStandardizeRAMpaths(fit)[1:3, 8]\nnames(estZ) &lt;- mxStandardizeRAMpaths(fit)[1:3, \"label\"]; estZ\n\nestZ[\"indirect\"] &lt;- estZ[\"a\"] * estZ[\"b\"]\nestZ[\"total\"] &lt;- estZ[\"indirect\"] + estZ[\"cprime\"]\nestZ\n\n## To get bootstrap CIs\nfitBoot &lt;- mxBootstrap(fit, 2000)\n# statistics &lt;- summary(fitBoot, boot.quantile = c(0.025, 0.975),\n#    boot.SummaryType = \"bcbci\"); statistics\n# Note: No defined effects\nci &lt;- mxBootstrapEval(c(a, b, cprime, indirect, total), fitBoot,\n   bq = c(0.025, 0.975), method = \"bcbci\"); ci\n\n## To get likelihood-based CIs\nci &lt;- mxCI(c(\"a\", \"b\", \"cprime\", \"indirect\", \"total\"))\n\n# Add to the model\nmedModel &lt;- mxModel(medModel, ci)\n\n# Run the model\nfit &lt;- mxRun(medModel, intervals = TRUE)\nsummary(fit)$CI\n\n\n\n\nKurbanoglu, N. & Takunyaci, M. (2021). A structural equation modeling on relationship between self-efficacy, physics laboratory anxiety and attitudes. Journal of Family, Counseling and Education, 6(1), 47-56.  A basic three-variable mediation analysis using summary data.\n\n\n\nMediation model\n\n\n\n\n\nKurbanoglu_2021.r\n## Kurbanoglu, N. & Takunyaci, M. (2021). A structural equation modeling\n## on relationship between self-efficacy, physics laboratory anxiety\n## and attitudes. Journal of Family, Counseling and Education, 6(1), 47-56.\n\n## This example shows a basic three-variable mediation\n## analysis, and how to use summary data (correlations, \n## standard deviations, and means) when the raw sample\n## are not available.\n\n## Load package\nlibrary(OpenMx)\n\n## Get the data from Table 1 (p. 50)\n# Vectors of correlations, standard deviations, and means.\n# Correlations entered row-by-row.\n# (If entered column-by-column, use 'lower.tri' in place of 'upper.tri' below.)\nvcor &lt;- c(\n   1,\n   0.30,  1,\n  -0.42, -0.32,  1)\nvsd &lt;- c(8.81, 7.95, 18.30)             # Standard deviations\nvmean &lt;- c(56.57, 40.39, 68.22)         # Means\nn &lt;- 513                                # Sample size\n\n## Get the variable names (make sure order is the same as in Table 1)\nnames &lt;- c(\"Att\", \"SE\", \"Anx\")\n\n## Get the co/variance matrix\n# First, get full correlation matrix\nmcor = matrix( , 3, 3)                           # Empty matrix\nmcor[upper.tri(mcor, diag = TRUE)] &lt;- vcor       # Fill the upper triangle\nmcor = pmax(mcor, t(mcor), na.rm = TRUE)         # Fill the lower triangle\n\n# Get co/variances\nmcov &lt;- outer(vsd, vsd) * mcor\n\n# Name the rows and columns\ndimnames(mcov) &lt;- list(names, names); mcov\nnames(vmean) = names   # OpenMx requires the means be named\n\n## The model is shown in Fig 1 (p. 51); or see the model diagram above.\n\n#### Collect the bits and pieces needed by OpenMx\n## Get data into OpenMx format\ndataCov &lt;- mxData(observed = mcov, type = \"cov\", means = vmean, numObs = n)\n\n## Regressions\nregPaths1 &lt;- mxPath(from = c(\"SE\", \"Att\"), to = \"Anx\",\n   arrows = 1, values = 0.5, labels = c(\"cprime\", \"b\"))\n\nregPaths2 &lt;- mxPath(from = \"SE\", to = \"Att\",\n   arrows = 1, values = 0.5, labels = \"a\")\n\n## Variances\nvarPaths &lt;- mxPath(from = names, \n   arrows = 2, values = 1, labels = c(\"eAtt\", \"vSE\", \"eAnx\"))\n\n## Means and intercepts\nmeans &lt;- mxPath(from = \"one\", to = names,\n   arrows = 1, values = 1, labels = c(\"iAtt\", \"mSE\", \"iAnx\"))\n\n## Indirect and total effects\nindirect &lt;- mxAlgebra(a * b, name = \"indirect\")\ntotal &lt;- mxAlgebra(a * b + cprime, name = \"total\")\n\n## Setup the model with all the bits\nmedModel &lt;- mxModel(model = \"Mediation\",\n   type = \"RAM\",\n   data = dataCov,\n   manifestVars = names,\n   varPaths,\n   regPaths1, regPaths2,\n   means, \n   indirect, total) \n\n## Run the model and get summary\nfit &lt;- mxRun(medModel)\nsummary(fit)\n\n## Extract indirect and total effects (and their standard errors) from \"fit\" object\nestimates &lt;- mxEval(c(indirect, total), fit); estimates\nSE &lt;- sapply(c(\"indirect\", \"total\"), function(x) mxSE(x, fit, silent = TRUE)); SE\n\n## Get the standardised effects\n# Compare with standardised estimates in Fig 1\nmxStandardizeRAMpaths(fit)\nestZ &lt;- mxStandardizeRAMpaths(fit)[1:3, 8]\nnames(estZ) &lt;- mxStandardizeRAMpaths(fit)[1:3, \"label\"]; estZ\n\n# Calculate standardised effects for \"indirect\" and \"total\" by hand\nestZ[\"indirect\"] &lt;- estZ[\"a\"] * estZ[\"b\"]\nestZ[\"total\"] &lt;- estZ[\"indirect\"] + estZ[\"cprime\"]\nestZ\n\n## R squares - have to calculate by hand\n# For variables implicated in regressions,\n# R square is given by matrix product of:\n#   row matrix of correlations and\n#   column matrix of standardised regression coefficients\n\n# Compare with R squares given in Fig 1.\n\n# Get correlations (with names) and standardised regression coefficients\ndimnames(mcor) = list(names, names); mcor\nestZ\n\n# R Squared for SE predicting Att:\n# Correlation between Att and SE, and\n# \"a\" standardised regression coefficient\nRsqAtt = mcor[\"Att\", \"SE\"] * estZ[\"a\"]\n\n# R Squared for SE and Att predicting Anx\n# Correlations between Anx and SE, and Anx and Att\n# \"b\" and \"cprime\" standardised regression coefficients\nRsqAnx =  matrix(mcor[\"Anx\", c(\"Att\", \"SE\")], 1)  %*%\n   matrix(estZ[c(\"b\", \"cprime\")], 2)\n\n# Combine them\nRsq = matrix(c(RsqAtt, RsqAnx), \n  dimnames = list(c(\"Att\", \"Anx\"), \"R Square\"),\n  2)\nRsq\n\n## To get likelihood-based CIs\nci &lt;- mxCI(c(\"a\", \"b\", \"cprime\", \"indirect\", \"total\"))\n\n# Add to the model\nmedModel &lt;- mxModel(medModel, ci)\n\n# Run the model\nfit &lt;- mxRun(medModel, intervals = TRUE)\nsummary(fit)$CI\n\n\n\n\nLittle, T., Slegers, D., & Card, N. (2006). A non-arbitrary method of identifying and scaling latent variables in SEM and MACS models. Structural Equation Modeling, 13(1), 59-72.  Three methods of scaling (reference group, marker variable, and effects scaling) in a two-factor, two-group model. Some easier examples (one-factor model, two-factor model, one-factor two-group model) are shown here.\n\n\n\nModel for Reference-Group Method\n\n\n\n\n\nModel for Marker-Variable Method\n\n\n\n\n\nModel for Effects-Scaling Method\n\n\n\n\n\nLittle_Scaling.r\n## Little, T., Slegers, D., & Card, N. (2006). A non-arbitrary method of\n## identifying and scaling latent variables in SEM and MACS models.\n## Structural Equation Modeling, 13(1), 59-72.\n\n## Methods of Scaling and Identification\n\n## Demonstrates three methods of scaling in two-factor, two-group model:\n## 1. Reference-group method - Constrain both latent variables' variances and means;\n## 2. Marker-variable method - Constrain one loading and that indicator's intercept in both factors;\n## 3. Effect-scaling method - Constrain sums of loadings and intercepts for both factors.\n\n## Little et al assume strong metric invariance:\n## Corresponding loadings and intercepts constrained to equality across groups\n\n## Compare with results given in Table 2 (pp. 64-65)\n## Little et al show results for three versions of Method 2.\n## Only the third is demonstrated here.\n\n## Load package\nlibrary(OpenMx)\n\n## Get the data from Appendix A\n# 7th grade\ncor7 &lt;- c(\n   1.00000,\n   0.75854,  1.00000,\n   0.76214,  0.78705,  1.00000,\n   0.02766,  0.00973, -0.05762,  1.00000,\n  -0.06112, -0.06105, -0.14060,  0.78501,  1.00000,\n  -0.02222, -0.05180, -0.10250,  0.81616,  0.81076,  1.00000)\n\nmean7 &lt;- c(3.13552, 2.99061, 3.06945, 1.70069, 1.52705, 1.54483)\nsd7 &lt;- c(0.66770, 0.68506, 0.70672, 0.71418, 0.66320, 0.65276)\nn7 &lt;- 380\n\n# 8th grade\ncor8 &lt;- c(\n   1.00000,\n   0.81366,  1.00000,\n   0.84980,  0.83523,  1.00000,\n  -0.18804, -0.15524, -0.21520,  1.00000,\n  -0.28875, -0.24951, -0.33769,  0.78418,  1.00000,\n  -0.29342, -0.21022, -0.30553,  0.79952,  0.83156,  1.00000)\n\nmean8 &lt;- c(3.07338, 2.84716, 2.97882, 1.71700, 1.57955, 1.55001)\nsd8 &lt;- c(0.70299, 0.71780, 0.76208, 0.65011, 0.60168, 0.61420)\nn8 &lt;- 379\n\n## Get the variable names from Appendix A\nnames = c(\"pos1\", \"pos2\", \"pos3\", \"neg1\", \"neg2\", \"neg3\")\n\n# Get full correlation matrix for each Grade\nmcor7 &lt;- matrix( , 6, 6)                         # Empty matrix\nmcor7[upper.tri(mcor7, diag = TRUE)] &lt;- cor7     # Fill the upper triangle\nmcor7 &lt;- pmax(mcor7, t(mcor7), na.rm = TRUE)     # Fill the lower triangle\n\nmcor8 &lt;- matrix( , 6, 6)                          # Empty matrix\nmcor8[upper.tri(mcor8, diag = TRUE)] &lt;- cor8      # Fill the upper triangle\nmcor8 &lt;- pmax(mcor8, t(mcor8), na.rm = TRUE)      # Fill the lower triangle\n\n# Get co/variance matrix for each grade\nmcov7 &lt;- outer(sd7, sd7) * mcor7\nmcov8 &lt;- outer(sd8, sd8) * mcor8\n\n# Name the rows and columns\ndimnames(mcov7) &lt;- list(names, names)\ndimnames(mcov8) &lt;- list(names, names)\nmcov7; mcov8\n\nnames(mean7) &lt;- names   # OpenMx requires the means be named\nnames(mean8) &lt;- names\n\n# Get data into OpenMx format\ndata7 &lt;- mxData(observed = mcov7, type = \"cov\", means = mean7, numObs = n7)\ndata8 &lt;- mxData(observed = mcov8, type = \"cov\", means = mean8, numObs = n8)\n\n\n### Meethod 1: Reference-Group Method\n## Constrain latent variances to 1\n## Constrain latent means to 0\n## These constraints apply to Grade 7 only.\n\n## Collect the bits and pieces needed by OpenMx\n# Factor loadings\nloadings1 &lt;- mxPath(from = \"POS\", to = c(\"pos1\", \"pos2\", \"pos3\"), arrows = 1,\n   free = TRUE, values = 0.5,\n   labels = c(\"lambda1\", \"lambda2\", \"lambda3\"))\n\nloadings2 &lt;- mxPath(from = \"NEG\", to = c(\"neg1\", \"neg2\", \"neg3\"), arrows = 1,\n   free = TRUE, values = 0.5,\n   labels = c(\"lambda4\", \"lambda5\", \"lambda6\"))\n\n# Factor variances and covariance - constrain variances to 1 for Grade 7 only\nvarFac7 &lt;- mxPath(from = c(\"POS\", \"NEG\"), arrows = 2, connect = \"unique.pairs\",\n   free = c(FALSE, TRUE, FALSE), values = 1,\n   labels = c(\"phi7_11\", \"phi7_12\", \"phi7_22\"))\n \nvarFac8 &lt;- mxPath(from = c(\"POS\", \"NEG\"), arrows = 2, connect = \"unique.pairs\",\n   free = TRUE, values = 1,\n   labels = c(\"phi8_11\", \"phi8_12\", \"phi8_22\"))\n\n# Factor means - constrain means to 0 for Grade 7 only\nmeans7 &lt;- mxPath(from = \"one\", to = c(\"POS\", \"NEG\"), arrows = 1,\n   free = FALSE, values = 0,\n   labels = c(\"kappa7_1\", \"kappa7_2\"))\n\nmeans8 &lt;- mxPath(from = \"one\", to = c(\"POS\", \"NEG\"), arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"kappa8_1\", \"kappa8_2\"))\n\n# Residual variances\nvarRes7 &lt;- mxPath(from = names, arrows = 2,\n   free = TRUE, values = 1,\n   labels = c(\"theta7_1\", \"theta7_2\", \"theta7_3\", \"theta7_4\", \"theta7_5\", \"theta7_6\"))\n\nvarRes8 &lt;- mxPath(from = names, arrows = 2,\n   free = TRUE, values = 1,\n   labels = c(\"theta8_1\", \"theta8_2\", \"theta8_3\", \"theta8_4\", \"theta8_5\", \"theta8_6\"))\n\n# Intercepts\nintercepts &lt;- mxPath(from = \"one\", to = names, arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"tau1\", \"tau2\", \"tau3\", \"tau4\", \"tau5\", \"tau6\"))\n\n## Setup models for each Grade\nmodGr7 &lt;- mxModel(\"Grade7\", type = \"RAM\",\n   manifestVars = names, latentVars = c(\"POS\", \"NEG\"),\n   data7, loadings1, loadings2, varFac7, means7, varRes7, intercepts)\n\nmodGr8 &lt;- mxModel(\"Grade8\", type = \"RAM\",\n   manifestVars = names, latentVars = c(\"POS\", \"NEG\"),\n   data8, loadings1, loadings2, varFac8, means8, varRes8, intercepts)\n\n## Combine the two models\nfun &lt;- mxFitFunctionMultigroup(c(\"Grade7.fitfunction\", \"Grade8.fitfunction\"))\nmodel1 &lt;- mxModel(\"Referemce Group Method\", modGr7, modGr8, fun)\n\n## Run the model and get summary\n# Compare with results for Method 1 in Table 2.\nfit1 &lt;- mxRun(model1)\nsummary1 &lt;- summary(fit1, refModels = mxRefModels(fit1, run = TRUE))\nsummary1\n\n\n### Method 2: Marker-Variable Method\n## Constrain 3rd loading in POS to 1 in both groups\n## Constrain 1st loading in NEG to 1 in both groups\n## Constrain 3rd intercept in POS to 0 in both groups\n## Constrain 1st intercept in NEG to 0 in both groups\n\n## Collect the bits and pieces needed by OpenMx\n# Factor loadings - 3rd loading for POS constrained to 1\n#                 - 1st loading for NEG constrained to 1\nloadings1 &lt;- mxPath(from = \"POS\", to = c(\"pos1\", \"pos2\", \"pos3\"), arrows = 1,\n   free = c(TRUE, TRUE, FALSE), values = c(0.5, 0.5, 1),\n   labels = c(\"lambda1\", \"lambda2\", \"lambda3\"))\n\nloadings2 &lt;- mxPath(from = \"NEG\", to = c(\"neg1\", \"neg2\", \"neg3\"), arrows = 1,\n   free = c(FALSE, TRUE, TRUE), values = c(1, 0.5, 0.5),\n   labels = c(\"lambda4\", \"lambda5\", \"lambda6\"))\n\n# Factor variances and covariance\nvarFac7 &lt;- mxPath(from = c(\"POS\", \"NEG\"), arrows = 2, connect = \"unique.pairs\",\n   free = TRUE, values = 1, \n   labels = c(\"phi7_11\", \"phi7_12\", \"phi7_22\"))\n\nvarFac8 &lt;- mxPath(from = c(\"POS\", \"NEG\"), arrows = 2, connect = \"unique.pairs\",\n   free = TRUE, values = 1,\n   labels = c(\"phi8_11\", \"phi8_12\", \"phi8_22\"))\n\n# Factor means\nmeans7 &lt;- mxPath(from = \"one\", to = c(\"POS\", \"NEG\"), arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"kappa7_1\", \"kappa7_2\"))\n\nmeans8 &lt;- mxPath(from = \"one\", to = c(\"POS\", \"NEG\"), arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"kappa8_1\", \"kappa8_2\"))\n\n# Residual variances\nvarRes7 &lt;- mxPath(from = names, arrows = 2,\n   free = TRUE, values = 1,\n   labels = c(\"theta7_1\", \"theta7_2\", \"theta7_3\", \"theta7_4\", \"theta7_5\", \"theta7_6\"))\n\nvarRes8 &lt;- mxPath(from = names, arrows = 2,\n   free = TRUE, values = 1, \n   labels = c(\"theta8_1\", \"theta8_2\", \"theta8_3\", \"theta8_4\", \"theta8_5\", \"theta8_6\"))\n\n# Intercepts - 3rd intercept for POS & 1st intercept for NEG constrained to 0\nintercepts &lt;- mxPath(from = \"one\", to = names, arrows = 1,\n   free = c(TRUE, TRUE, FALSE, FALSE, TRUE, TRUE), values = c(1, 1, 0, 0, 1, 1),\n   labels = c(\"tau1\", \"tau2\", \"tau3\", \"tau4\", \"tau5\", \"tau6\"))\n\n## Setup models for each Grade\nmodGr7 &lt;- mxModel(\"Grade7\", type = \"RAM\",\n   manifestVars = names, latentVars = c(\"POS\", \"NEG\"),\n   data7, loadings1, loadings2, varFac7, means7, varRes7, intercepts)\n\nmodGr8 &lt;- mxModel(\"Grade8\", type = \"RAM\",\n   manifestVars = names, latentVars = c(\"POS\", \"NEG\"),\n   data8, loadings1, loadings2, varFac8, means8, varRes8, intercepts)\n\n## Combine the two models\nfun &lt;- mxFitFunctionMultigroup(c(\"Grade7.fitfunction\", \"Grade8.fitfunction\"))\nmodel2 &lt;- mxModel(\"Referemce Group Method\", modGr7, modGr8, fun)\n\n## Run the model and get summary\n# Compare with results for third Method 2 in Table 2.\nfit2 &lt;- mxRun(model2)\nsummary2 &lt;- summary(fit2, refModels = mxRefModels(fit2, run = TRUE))\nsummary2\n\n\n### Method 3: Effects-Scaling Method\n## Constrain loadings to add to 3 in both factors for both Grades\n## Constrain intercepts to add to 0 in both factors for both Grades\n\n## Collect the bits and pieces needed by OpenMx\n# Factor loadings\nloadings1 &lt;- mxPath(from = \"POS\", to = c(\"pos1\", \"pos2\", \"pos3\"), arrows = 1,\n   free = TRUE, values = 0.5,\n   labels = c(\"lambda1\", \"lambda2\", \"lambda3\"))\n\nloadings2 &lt;- mxPath(from = \"NEG\", to = c(\"neg1\", \"neg2\", \"neg3\"), arrows = 1,\n   free = TRUE, values = 0.5,\n   labels = c(\"lambda4\", \"lambda5\", \"lambda6\"))\n\n# Factor variances and covariance\nvarFac7 &lt;- mxPath(from = c(\"POS\", \"NEG\"), arrows = 2, connect = \"unique.pairs\",\n   free = TRUE, values = 1, \n   labels = c(\"phi7_11\", \"phi7_12\", \"phi7_22\"))\n\nvarFac8 &lt;- mxPath(from = c(\"POS\", \"NEG\"), arrows = 2, connect = \"unique.pairs\",\n   free = TRUE, values = 1,\n   labels = c(\"phi8_11\", \"phi8_12\", \"phi8_22\"))\n\n# Factor means\nmeans7 &lt;- mxPath(from = \"one\", to = c(\"POS\", \"NEG\"), arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"kappa7_1\", \"kappa7_2\"))\n\nmeans8 &lt;- mxPath(from = \"one\", to = c(\"POS\", \"NEG\"), arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"kappa8_1\", \"kappa8_2\"))\n\n# Residual variances\nvarRes7 &lt;- mxPath(from = names, arrows = 2,\n   free = TRUE, values = 1,\n   labels = c(\"theta7_1\", \"theta7_2\", \"theta7_3\", \"theta7_4\", \"theta7_5\", \"theta7_6\"))\n\nvarRes8 &lt;- mxPath(from = names, arrows = 2,\n   free = TRUE, values = 1,\n   labels = c(\"theta8_1\", \"theta8_2\", \"theta8_3\", \"theta8_4\", \"theta8_5\", \"theta8_6\"))\n\n# Intercepts\nintercepts &lt;- mxPath(from = \"one\", to = names, arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"tau1\", \"tau2\", \"tau3\", \"tau4\", \"tau5\", \"tau6\"))\n\n## Setup models for each Grade\nmodGr7 &lt;- mxModel(\"Grade7\", type = \"RAM\",\n   manifestVars = names, latentVars = c(\"POS\", \"NEG\"),\n   data7, loadings1, loadings2, varFac7, means7, varRes7, intercepts)\n\nmodGr8 &lt;- mxModel(\"Grade8\", type = \"RAM\",\n   manifestVars = names, latentVars = c(\"POS\", \"NEG\"),\n   data8, loadings1, loadings2, varFac8, means8, varRes8, intercepts)\n\n## Constraints\nconLoad1  &lt;- mxConstraint(lambda1 + lambda2 + lambda3 == 3)\nconLoad2  &lt;- mxConstraint(lambda4 + lambda5 + lambda6 == 3)\nconInter1 &lt;- mxConstraint(tau1 + tau2 + tau3 == 0)\nconInter2 &lt;- mxConstraint(tau4 + tau5 + tau6 == 0)\n\n## Combine the two models\nfun &lt;- mxFitFunctionMultigroup(c(\"Grade7.fitfunction\", \"Grade8.fitfunction\"))\nmodel3 &lt;- mxModel(\"Referemce Group Method\", modGr7, modGr8,\n          conLoad1, conLoad2, conInter1, conInter2, fun)\n\n## Run the model and get summary\n# Compare with results for Method 3 in Table 2.\nfit3 &lt;- mxRun(model3)\nsummary3 &lt;- summary(fit3, refModels = mxRefModels(fit3, run = TRUE))\nsummary3\n\n## Get fit measures\n#  Compare with fit measures given on page 66\nmodels &lt;- list(\n   \"Method 1\" = summary1,\n   \"Method 2\" = summary2,\n   \"Method 3\" = summary3)\n\nmeasures = c(\"Chi\", \"ChiDoF\", \"p\", \"CFI\", \"TLI\", \"RMSEA\")\n\nfit1 &lt;- do.call(rbind, lapply(models, `[`, measures))\nfit2 &lt;- do.call(rbind, lapply(models, `[[`, \"RMSEACI\"))\n\ncbind(fit1, fit2)\n\n## Note: RMSEA given by OpenMx does not agree with the value given by Little et al. \n#  OpenMx does not adjust RMSEA in multiple group models -\n#  see the RMSEA section in ?mxSummary for brief explanation, and\n# https://openmx.ssri.psu.edu/index.php/forums/opensem-forums/fit-functions/rmsea-multiple-group-analysis\n#  for another discussion.\n#  LISREL, lavaan, Mplus (and possibly other packages) do make the adjustment.\n\n# Equation for RMSEA, as given by Steiger (1998, Eq. 25, p. 417):\n#  RMSEA = sqrt((ChiSq/df - 1) / n)\n\n#  Substitute values from above;\n#  gives 'unadjusted RMSEA' as obtained by OpneMx.\nsqrt((58.60023/24 - 1) / 759)\n\n#  Steiger (1998, p. 417) states that 'adjusted RMSEA' can be obtained\n#  by multiplying 'unadjusted RMSEA' by sqrt(g) (where g is the number\n#  of groups).\nsqrt(2) * sqrt((58.60023/24 - 1) / 759)\n\n#  Gives 'adjusted RMSEA' as given by Little et al (ie, LISREL)\n#  and by lavaan (see 'SEMs_with_lavaan').\n\n\n# Steiger, J. (1998). A note on multiple sample extensions of the RMSEA \n# fit index. Structural Equation Modeling, 5(4), 411-419.\n\n\n\n\nThompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.  SEMs approaches for ANOVA and MANOVA type models.\n\n\nThe Models\n\n\n\none-way ANOVA model\n\n\n\n\n\none-way ANCOVA model\n\n\n\n\n\ntwo-way ANOVA model\n\n\n\n\n\none-way MANOVA model\n\n\n\n\n\none-way LATENT model\n\n\n\n\nThe Data\n\n\n\nsatisfactionI.r\n### Data for Tables 21.1, 21.2, 21.3, 21.4 ###\n\ndf &lt;- structure(list(x = c(\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\"), g = c(\"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \n\"m\", \"m\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \n\"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \n\"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\"), \n    c = c(\"before\", \"before\", \"before\", \"before\", \"before\", \"before\", \n    \"before\", \"before\", \"before\", \"after\", \"after\", \"after\", \n    \"after\", \"after\", \"after\", \"after\", \"after\", \"after\", \"before\", \n    \"before\", \"before\", \"before\", \"before\", \"before\", \"after\", \n    \"after\", \"after\", \"after\", \"after\", \"after\", \"before\", \"before\", \n    \"before\", \"before\", \"before\", \"before\", \"before\", \"before\", \n    \"before\", \"after\", \"after\", \"after\", \"after\", \"after\", \"after\", \n    \"after\", \"after\", \"after\"), y = c(21, 19, 22, 21, 24, 23, \n    21, 24, 23, 22, 22, 24, 25, 27, 30, 22, 23, 24, 23, 23, 21, \n    19, 22, 21, 30, 26, 22, 25, 26, 27, 27, 25, 24, 25, 23, 22, \n    23, 28, 26, 34, 30, 26, 26, 27, 28, 29, 40, 42)), class = \"data.frame\", row.names = c(NA, \n-48L))\n\n\nhead(df)\n\n## x - Coping Strategy (a - No strategy; b - Discussion; c - Exercise)\n## g - Gender\n## c - before/after \n## y - dependent variable (Life Satisfaction)\n\n\n\n\nANOVA_data.r\n### Data for Tables 21.1, 21.2, 21.3, 21.4 ###\n\n## Reshape data - long to wide\ntab &lt;- 0.5 * table(df$x)  # in each condition\ndf$id &lt;- c(rep(1:tab[1], 2), rep(1:tab[2], 2), rep(1:tab[3], 2))  # id variable \n\ndf &lt;- reshape(df, timevar = \"c\", idvar = c(\"id\", \"x\", \"g\"), varying = c(\"pre\", \"y\"), \n   direction = \"wide\")\n\ndf &lt;- within(df, {\n## Grand mean centered \"pre\" - the before scores\n   preC &lt;- scale(pre, scale = FALSE)\n\n## Drop the id variable\n   id &lt;- NULL\n\n## Gender X Coping Strategy interaction\n  sg &lt;- interaction(x, g, sep = \"\")\n})\n\n\n\n\nsatisfactionII.r\n### Data for Tables 21.5 and 21.6 ###\n\ndf &lt;- structure(list(x = c(\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\"), x1 = c(1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L), x2 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L), x3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), y1 = c(18L, 24L, \n21L, 24L, 19L, 22L, 23L, 32L, 24L, 22L, 24L, 23L, 28L, 22L, 22L, \n23L, 19L, 28L, 25L, 25L, 27L, 21L, 33L, 24L, 23L, 28L, 29L, 24L, \n28L, 24L, 26L, 28L, 21L, 26L, 20L, 24L, 22L, 32L, 31L, 22L, 22L, \n27L, 22L, 26L, 24L, 24L, 25L, 27L, 26L, 24L, 22L, 18L, 25L, 27L, \n29L, 24L, 22L, 32L, 23L, 27L, 28L, 24L, 18L, 32L, 27L, 25L, 24L, \n25L, 29L, 21L, 29L, 25L, 25L, 25L, 19L, 32L, 29L, 22L, 18L, 26L, \n23L, 26L, 21L, 18L, 24L, 24L, 17L, 24L, 33L, 21L, 23L, 27L, 26L, \n28L, 20L, 27L, 25L, 25L, 25L, 18L, 27L, 25L, 22L, 23L, 26L, 23L, \n29L, 26L, 24L, 27L, 22L, 24L, 26L, 31L, 27L, 22L, 22L, 26L, 25L, \n21L, 26L, 25L, 24L, 26L, 28L, 27L, 26L, 26L, 19L, 22L, 25L, 26L, \n30L, 22L, 26L, 25L, 27L, 32L, 22L, 27L, 26L, 30L, 32L, 28L, 25L, \n23L, 21L, 14L, 26L, 28L, 29L, 25L, 27L, 25L, 26L, 21L, 23L, 25L, \n26L, 30L, 30L, 26L, 22L, 31L, 28L, 26L, 29L, 25L, 26L, 24L, 28L, \n22L, 35L, 26L, 34L, 29L, 26L, 27L, 32L, 16L, 26L, 22L, 25L, 30L, \n28L, 25L, 22L, 23L, 28L, 23L, 36L, 27L, 24L, 23L, 34L, 31L, 33L, \n26L, 27L, 22L), y2 = c(49L, 50L, 51L, 53L, 44L, 50L, 52L, 55L, \n53L, 48L, 48L, 51L, 57L, 51L, 48L, 51L, 48L, 53L, 59L, 55L, 51L, \n54L, 63L, 49L, 54L, 54L, 52L, 47L, 50L, 49L, 54L, 57L, 51L, 53L, \n49L, 53L, 53L, 57L, 58L, 49L, 53L, 55L, 59L, 57L, 55L, 53L, 55L, \n54L, 47L, 54L, 48L, 47L, 50L, 59L, 52L, 52L, 52L, 60L, 59L, 50L, \n55L, 59L, 55L, 59L, 61L, 48L, 55L, 55L, 60L, 50L, 62L, 54L, 56L, \n61L, 52L, 55L, 51L, 56L, 52L, 56L, 53L, 49L, 59L, 51L, 57L, 55L, \n48L, 54L, 56L, 53L, 47L, 54L, 52L, 54L, 50L, 54L, 52L, 54L, 59L, \n54L, 61L, 54L, 54L, 50L, 56L, 51L, 59L, 50L, 52L, 55L, 57L, 57L, \n62L, 55L, 53L, 51L, 50L, 60L, 51L, 52L, 52L, 56L, 52L, 55L, 56L, \n51L, 64L, 54L, 47L, 51L, 54L, 55L, 55L, 55L, 54L, 55L, 58L, 57L, \n56L, 60L, 55L, 54L, 61L, 55L, 50L, 53L, 60L, 49L, 58L, 61L, 55L, \n51L, 58L, 53L, 55L, 49L, 55L, 53L, 56L, 53L, 55L, 53L, 48L, 59L, \n56L, 52L, 55L, 58L, 54L, 54L, 59L, 49L, 60L, 62L, 57L, 59L, 57L, \n61L, 58L, 53L, 56L, 52L, 53L, 55L, 54L, 53L, 49L, 48L, 59L, 55L, \n61L, 59L, 50L, 55L, 58L, 63L, 53L, 56L, 55L, 54L), y3 = c(42L, \n42L, 46L, 39L, 39L, 37L, 38L, 43L, 36L, 37L, 40L, 45L, 46L, 39L, \n39L, 36L, 38L, 43L, 44L, 42L, 37L, 38L, 41L, 40L, 40L, 48L, 41L, \n37L, 42L, 32L, 38L, 43L, 38L, 41L, 45L, 39L, 40L, 41L, 49L, 40L, \n39L, 40L, 41L, 39L, 41L, 43L, 43L, 37L, 38L, 42L, 44L, 36L, 39L, \n44L, 41L, 38L, 40L, 49L, 41L, 39L, 46L, 45L, 40L, 50L, 45L, 43L, \n40L, 42L, 44L, 34L, 42L, 39L, 46L, 39L, 39L, 42L, 41L, 36L, 42L, \n46L, 39L, 39L, 37L, 36L, 42L, 32L, 37L, 43L, 42L, 42L, 46L, 47L, \n42L, 47L, 39L, 36L, 38L, 43L, 38L, 40L, 47L, 42L, 43L, 42L, 44L, \n42L, 45L, 41L, 39L, 45L, 42L, 41L, 46L, 44L, 43L, 38L, 42L, 44L, \n36L, 37L, 45L, 45L, 37L, 41L, 38L, 42L, 42L, 40L, 35L, 46L, 40L, \n42L, 48L, 42L, 42L, 44L, 44L, 48L, 38L, 43L, 42L, 40L, 48L, 39L, \n40L, 32L, 46L, 34L, 45L, 43L, 42L, 38L, 42L, 35L, 46L, 38L, 42L, \n39L, 43L, 43L, 50L, 41L, 42L, 43L, 44L, 35L, 44L, 42L, 41L, 47L, \n48L, 40L, 46L, 44L, 51L, 43L, 39L, 47L, 51L, 37L, 42L, 38L, 37L, \n38L, 43L, 40L, 36L, 40L, 46L, 43L, 50L, 42L, 42L, 40L, 43L, 46L, \n43L, 40L, 42L, 41L), y4 = c(29L, 31L, 34L, 36L, 26L, 30L, 34L, \n38L, 37L, 31L, 37L, 30L, 38L, 26L, 36L, 27L, 30L, 39L, 37L, 35L, \n39L, 33L, 35L, 32L, 34L, 40L, 32L, 31L, 38L, 38L, 34L, 42L, 30L, \n32L, 27L, 33L, 32L, 35L, 40L, 27L, 31L, 35L, 32L, 37L, 38L, 31L, \n29L, 28L, 33L, 35L, 31L, 22L, 34L, 37L, 27L, 33L, 35L, 47L, 30L, \n39L, 38L, 40L, 29L, 43L, 34L, 34L, 32L, 41L, 34L, 33L, 34L, 34L, \n32L, 32L, 30L, 34L, 32L, 38L, 25L, 35L, 34L, 24L, 34L, 33L, 26L, \n31L, 30L, 35L, 37L, 35L, 35L, 40L, 34L, 33L, 28L, 35L, 36L, 35L, \n40L, 34L, 39L, 33L, 28L, 34L, 31L, 29L, 39L, 40L, 35L, 37L, 36L, \n34L, 38L, 33L, 32L, 26L, 33L, 36L, 30L, 25L, 33L, 35L, 35L, 38L, \n36L, 39L, 32L, 34L, 35L, 34L, 36L, 28L, 35L, 30L, 31L, 38L, 35L, \n40L, 31L, 40L, 37L, 32L, 42L, 35L, 34L, 34L, 35L, 23L, 35L, 41L, \n39L, 37L, 34L, 26L, 35L, 34L, 35L, 33L, 31L, 40L, 38L, 32L, 29L, \n37L, 39L, 34L, 35L, 35L, 28L, 40L, 37L, 35L, 40L, 35L, 42L, 40L, \n42L, 37L, 39L, 32L, 38L, 31L, 34L, 39L, 38L, 35L, 32L, 33L, 39L, \n36L, 43L, 36L, 30L, 36L, 42L, 35L, 32L, 32L, 33L, 35L)), class = \"data.frame\", row.names = c(NA, \n-200L))\n\n\n\nhead(df)\n\n## x - Coping Strategy (a - No strategy; b - Discussion; c - Exercise)\n## y1, y2, y3, y4 - Multiple dependent variables (life-satisfaction scores)\n\n\n\nR Scripts\n\n\n\none_way_ANOVA.r\n## One-Way ANOVA\n##\n## Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling\n## approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural\n## equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\n\n# This example shows the SEM approach to a one-way ANOVA. \n# Results are presented in Table 21.1 (p. 389).\n\n# The data are discussed on page 388.\n# Data are available in \"satisfactionI.r\"\n# \"ANOVA_data.r\" rearranges the data - from \"long\" to \"wide\".\n\n# The variables used here are:\n#   x - Coping Strategy (a - No strategy; b - Discussion; c - Exercise)\n#   y - dependent variable (Life-Satisfaction) \n\n## Load packages\nlibrary(OpenMx)\n\n## Get the data\nsource(\"satisfactionI.r\")\nhead(df)\n\n## Rearrange the data file\nsource(\"ANOVA_data.r\")\nhead(df)\n\n## Two models:\n# \"Less Constrained\" model - means allowed to differ across the groups;\n# \"More Constrained\" model - means constrained to equality across the groups.\n# To be consistent with ANOVA's assumption of homogeneity of variances, \n# the residual variances are constrained to equality across the groups.\n\n## Get data into OpenMx format for each group\ndataA &lt;- mxData(observed = df[df$x == \"a\", c(\"x\",\"y\")], type = \"raw\")\ndataB &lt;- mxData(observed = df[df$x == \"b\", c(\"x\",\"y\")], type = \"raw\")\ndataC &lt;- mxData(observed = df[df$x == \"c\", c(\"x\",\"y\")], type = \"raw\")\n\n### \"Less Constrained\" model\n## Means for each group - Means differ across the groups\nmeanA &lt;- mxPath(from = \"one\", to = \"y\", values = 0.5, arrows = 1, label = \"a1\")\nmeanB &lt;- mxPath(from = \"one\", to = \"y\", values = 0.5, arrows = 1, label = \"a2\")\nmeanC &lt;- mxPath(from = \"one\", to = \"y\", values = 0.5, arrows = 1, label = \"a3\")\n   \n## Residual variances - Constrained to equality across the groups\nvar &lt;- mxPath(from = \"y\", values = 1, arrows = 2, label = \"e\") \n\n## Setup the group models\nmodA &lt;- mxModel(\"GrA\", type = \"RAM\",\n   manifestVars = \"y\", dataA, meanA, var)\n\nmodB &lt;- mxModel(\"GrB\", type = \"RAM\",\n   manifestVars = \"y\", dataB, meanB, var)\n\nmodC &lt;- mxModel(\"GrC\", type = \"RAM\",\n   manifestVars = \"y\", dataC, meanC, var)\n\n## Combine the three models\nfun &lt;- mxFitFunctionMultigroup(c(\"GrA\", \"GrB\", \"GrC\"))\nmodelLC &lt;- mxModel(\"LC\", modA, modB, modC, fun)\n\n## Run the LC model and get the summary\nfitLC &lt;- mxRun(modelLC)\nsummary(fitLC, refModels = mxRefModels(fitLC, run = TRUE))\n\n## Get the means and error variance\n## Compare with SEM results in Table 21.1\nmeansLC &lt;- coef(fitLC)[c(\"a1\", \"a2\", \"a3\")]; meansLC\nthetaLC &lt;- coef(fitLC)[\"e\"]; thetaLC\n\n### \"More Constrained\" model\n## Constraints\nC1 &lt;- mxConstraint(a1 == a2)\nC2 &lt;- mxConstraint(a2 == a3)\n\n## Add them to \"Less Constrained\" model\nmodelMC &lt;- mxModel(modelLC, C1, C2)\nmodelMC &lt;- mxModel(modelMC, name = \"MC\")       # Change its name \n\n## Run the MC model and get the summary\nfitMC &lt;- mxRun(modelMC)\nsummary(fitMC, refModels = mxRefModels(fitMC, run = TRUE))\ncoef(fitMC)\n\n## Get the means and error variance\n## Compare with SEM results in Table 21.1\nmeansMC &lt;- coef(fitMC)[c(\"a1\", \"a2\", \"a3\")]; meansMC\nthetaMC &lt;- coef(fitMC)[\"e\"]; thetaMC\n\n## Contrast the two models, and campare with chi sq test in Table 21.1\nanova(fitMC, fitLC)\n\n## Get R square and compare with result given on page 390.\n## R square formula given in Equation 21.4 (p. 390).\nRsquare &lt;- (thetaMC - thetaLC)/thetaMC; Rsquare\n\n## The warning message at the bottom of the summary might be disconcerting for some. \n# One way to avoid the message is not to run the reference models.\n# Without the reference models, there will be no chi sq tests, \n# but that's okay; I'm not interested in the chi squares for each separate model.\n# The model comparison is what I want, and it is still available.\n\nsummary(fitLC)\nsummary(fitMC)\nanova(fitMC, fitLC)\n\n## But where does the warning come from.\n# First, some counting of degrees of freedom.\n\n# There is 1 variable per group;\n# thus, the co/variance matrix contains (1 X 2) / 2 = 1 piece of information,\n# plus the mean; that's 2 pieces of information per group.\n# There are 3 groups, thus 6 pieces of information submitted to the model.\n\n# For the LC model, \n# 1 mean per group is estimated = 3 means, and\n# 1 variance in total (it is constrainted to equality across the groups)\n# giving 4 quantities estimated.\n\n# Resulting is 2 degrees of freedom for the LC model.\n\n# When chi squares are required, and thus when reference models are included,\n# two additional models are estimated:\n# saturated model and independence model.\n\n# The saturated model estimates means and variances, \n# but does not constrain variances to equality across the groups.\n# There are 6 quantities estimated (3 means and 3 variances),\n# leaving 0 degrees of freedom (hence the name, \"saturated\").\n# The saturated model's log likelihood is used in the chi square calculation.\n# The chi square value and df are correct (check with the values given in Table 21.1).\n\n# The independence model sets all correlations to 0, \n# and estimates just the variances.\n# But with just 1 variable, there is only 1 variance to be estimated\n# (plus the means), and as a consequence, the independence model is\n# the same as the saturated model, and indeed it generates the same\n# log likelihood as the saturated model.\n# This means that the independence model too is a perfect fit to the data.\n# This, I think, is the basis of OpenMx's complaint, and the origin of the\n# warning message. The independence model is supposed to be the\n# worst fitting model, but in this situation it ends up fitting the data\n# perfectly; that is, better, not worse, than the preferred model;\n\n# Therefore, the warning message can be safely ignored - everything is\n# correctly estimated (and an overly cautious OpenMx alerts you to the fact that\n# the preferred model fits the data worse than the independence model).\n\n\n### Relax homogeneity of variances assumption\n### The \"Less Constrained\" model\n\n## Residual variances - differ across the groups\nvarA &lt;- mxPath(from = \"y\", arrows = 2,\n   free = TRUE, values = 1, label = \"e1\")\n\nvarB &lt;- mxPath(from = \"y\", arrows = 2,\n   free = TRUE, values = 1, label = \"e2\")\n\nvarC &lt;- mxPath(from = \"y\", arrows = 2,\n   free = TRUE, values = 1, label = \"e3\")\n\n## Everythiing else stays the same\n\n## Setup the group models\nmodA &lt;- mxModel(\"GrA\", type = \"RAM\",\n   manifestVars = \"y\", dataA, meanA, varA)\n\nmodB &lt;- mxModel(\"GrB\", type = \"RAM\",\n   manifestVars = \"y\", dataB, meanB, varB)\n\nmodC &lt;- mxModel(\"GrC\", type = \"RAM\",\n   manifestVars = \"y\", dataC, meanC, varC)\n\n## Combine the three models\nfun &lt;- mxFitFunctionMultigroup(c(\"GrA\", \"GrB\", \"GrC\"))\nmodelLC &lt;- mxModel(\"LC\", modA, modB, modC, fun) \n\n## Run the LC model and get the summary\nfitLC &lt;- mxRun(modelLC)\nsummary(fitLC, refModels = mxRefModels(fitLC, run = TRUE))\ncoef(fitLC)\n\n# Note: the LC model is the same as the saturated and, in turn, the independence model.\n# All three generate the same log likelihood.\n\n## Get the means and error variances\nmeansLC &lt;- coef(fitLC)[c(\"a1\", \"a2\", \"a3\")]; meansLC\nthetaLC &lt;- coef(fitLC)[c(\"e1\", \"e2\", \"e3\")]; thetaLC\n\n### The \"More Constrained\" model\n## Constraints - same as before\nC1; C2\n\n## Add them to \"Less Constrained\" model\nmodelMC &lt;- mxModel(modelLC, C1, C2)\nmodelMC &lt;- mxModel(modelMC, name = \"MC\")       # Change its name \n\n## Run the MC model and get the summary\nfitMC &lt;- mxRun(modelMC)\nsummary(fitMC, refModels = mxRefModels(fitMC, run = TRUE))\ncoef(fitMC)\n\n## Get the means and error variances\nmeansMC &lt;- coef(fitMC)[c(\"a1\", \"a2\", \"a3\")]; meansMC\nthetaMC &lt;- coef(fitMC)[c(\"e1\", \"e2\", \"e3\")]; thetaMC\n\n## Contrast the two models\nanova(fitMC, fitLC)\n\n\n\n\none_way_ANCOVA.r\n## One-Way ANCOVA\n##\n## Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling\n## approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural\n## equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\n\n# This example show the SEM approach to a one-way ANCOVA.\n# Results presented in Table 21.2 (p. 393).\n\n# Means and variances for exogenous variables - the covariate (preC) - are not\n# normally included in SEM diagrams, and they are not shown in these SEM diagrams.\n# However, OpenMX requires them in its model statements.\n\n# Data are available in \"satisfactionI.r\"\n# \"ANOVA_data.r\" rearranges the data \n#   - from \"long\" to \"wide\",\n#   - centering the Pre-Life_Satisfaction scores.\n\n# The variables used here are:\n#   x - Coping Strategy (a - No strategy; b - Discussion; c - Exercise)\n#   y - dependent variable (Life-Satisfaction) \n#   preC - Pre-Life-Satisfaction scores centred on the grand mean\n\n## Load packages\nlibrary(OpenMx)\n\n## Get the data\nsource(\"satisfactionI.r\")\nhead(df)\n\n## Rearrange the data file\nsource(\"ANOVA_data.r\")\nhead(df)\n\n## Two models:\n# \"Less Constrained\" model - means allowed to differ across the groups;\n# \"More Constrained\" model - means constrained to equality across the groups.\n# To be consistent with ANCOVA's assumptions of homogeneity of variances,\n# and homogeneity of regression slopes,\n# the residual variances and regression slopes are constrained to equality\n# across the groups.\n\n## Get data into OpenMx format for each group\ndataA &lt;- mxData(observed = df[df$x == \"a\", c(\"x\",\"y\", \"preC\")], type = \"raw\")\ndataB &lt;- mxData(observed = df[df$x == \"b\", c(\"x\",\"y\", \"preC\")], type = \"raw\")\ndataC &lt;- mxData(observed = df[df$x == \"c\", c(\"x\",\"y\", \"preC\")], type = \"raw\")\n\n### \"Less Constrained\" model\n## Means for each group - \n## \"y\" means differ across the groups.\n## The means for the covariate (\"preC\") need to be included in the model.\nmanifest &lt;- c(\"y\", \"preC\")\nmeanA &lt;- mxPath(from = \"one\", to = manifest, arrows = 1,\n   values = 0.5, label = c(\"a1\", \"cov1\"))\nmeanB &lt;- mxPath(from = \"one\", to = manifest, arrows = 1,\n   values = 0.5, label = c(\"a2\", \"cov2\"))\nmeanC &lt;- mxPath(from = \"one\", to = manifest, arrows = 1,\n  values = 0.5 , label = c(\"a3\", \"cov3\"))\n\n## Regression slopes - Constrained to equality across the groups\nreg &lt;- mxPath(from = \"preC\", to = \"y\", arrows = 1,\n   values = 0.5, label = \"b\")\n\n## Variances - \n## Residual variances - Constrained to equality across the groups\n## The variances for the covariate (\"preC\") need to be included in the model\nvarA &lt;- mxPath(from = manifest, arrows = 2,\n   values = 1, label = c(\"e\", \"cov1var\")) \n   \nvarB &lt;- mxPath(from = manifest, arrows = 2,\n   values = 1, label = c(\"e\", \"cov2var\"))\n   \nvarC &lt;- mxPath(from = manifest, arrows = 2,\n   values = 1, label = c(\"e\", \"cov3var\"))\n\n## Setup the group models\nmodA &lt;- mxModel(\"GrA\", type = \"RAM\",\n   manifestVars = manifest, dataA, meanA, reg, varA)\n\nmodB &lt;- mxModel(\"GrB\", type = \"RAM\",\n   manifestVars = manifest, dataB, meanB, reg, varB)\n\nmodC &lt;- mxModel(\"GrC\", type = \"RAM\",\n   manifestVars = manifest, dataC, meanC, reg, varC)\n\n## Combine the three models\nfun &lt;- mxFitFunctionMultigroup(c(\"GrA.fitfunction\", \"GrB.fitfunction\", \"GrC.fitfunction\"))\nmodelLC &lt;- mxModel(\"LC\", modA, modB, modC, fun)\n\n## Run the LC model and get the summary\nfitLC &lt;- mxRun(modelLC)\nsummary(fitLC, refModels = mxRefModels(fitLC, run = TRUE))\n\n## Get the means and error variance\n## Compare with SEM results in Table 21.2\nmeansLC &lt;- coef(fitLC)[c(\"a1\", \"a2\", \"a3\")]; meansLC\nthetaLC &lt;- coef(fitLC)[\"e\"]; thetaLC\n\n## Get regression slopes and compare with Table 21.2 footnote\nslopeLC &lt;- coef(fitLC)[\"b\"]; slopeLC\n\n### \"More Constrained\" model\n## Constraints\nC1 &lt;- mxConstraint(a1 == a2)\nC2 &lt;- mxConstraint(a2 == a3)\n\n## Add them to \"Less Constrained\" model\nmodelMC &lt;- mxModel(modelLC, C1, C2)\nmodelMC &lt;- mxModel(modelMC, name = \"MC\")       # Change its name \n\n## Run the MC model and get the summary\nfitMC &lt;- mxRun(modelMC)\nsummary(fitMC, refModels = mxRefModels(fitMC, run = TRUE))\ncoef(fitMC)\n\n## Get the means and error variance\n## Compare with SEM results in Table 21.2\nmeansMC &lt;- coef(fitMC)[c(\"a1\", \"a2\", \"a3\")]; meansMC\nthetaMC &lt;- coef(fitMC)[\"e\"]; thetaMC\n\n## Get regression slopes and compare with Table 21.2 footnote\nslopeMC &lt;- coef(fitMC)[\"b\"]; slopeMC\n\n## Contrast the two models, and campare with chi sq test in Table 21.2\nanova(fitMC, fitLC)\n\n## Get R square and compare with result given on page 394.\n## R square formula given in Equation 21.9 (p. 394).\nRsquare &lt;- (thetaMC - thetaLC)/thetaMC; Rsquare\n\n\n\n\ntwo_way_ANOVA.r\n## Two-Way ANOVA\n##\n## Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling\n## approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural\n## equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\n\n# This example shows the SEM approach to a two-way ANOVA.\n# Results presented in Table 21.4 (p. 396).\n\n# Data are available in \"satisfactionI.r\"\n# \"ANOVA_data.r\" rearranges the data \n#   - from \"long\" to \"wide\",\n#   - sets up the Gender X Coping Strategy interaction\n\n# The variables used here are:\n#   x - Coping Strategy (a - No strategy; b - Discussion; c - Exercise)\n#   y - dependent variable (Life-Satisfaction) \n#   g - Gender\n#   sg - Gender X Coping Strategy interaction\n\n## Load packages\nlibrary(OpenMx)\n\n## Get the data\nsource(\"satisfactionI.r\")\nhead(df)\n\n## Rearrange the data file\nsource(\"ANOVA_data.r\")\nhead(df)\n\n## Code to get the  prelimnary results presented Table 21.3 (p. 395) \n## is not shown here\n\n## Two-way ANOVA\n# There are six groups in the model, and thus there are six means.\n# They are represented by the labels am, af, ..., cf in the model diagram.\n# The \"Less Constrained\" model allows the six means to differ. \n#\n# There are three \"More Constrained\" models to test for:\n#   Gender main effect,\n#   Coping Strategy main effect, and\n#   Gender X Coping Strategy interaction.\n# These effects can be tested for unweighted means and weighted means.\n# One page 394, TLG discuss when to use weighted and unweighted means.\n\n# To be consistent with ANOVA's assumption of homogeneity of variances,\n# the variances are constrained to equality aross the groups.\n\n# Table 21.4 (p. 396) shows the results for the test of the\n# \"Coping Strategy\" main effect for weighted means.\n# Here, tests for both main effects and the interaction\n# for weighted and unweighted means are shown.\n\n## Get data into OpenMx format for each group\ndataAM &lt;- mxData(observed = df[df$sg == \"am\", c(\"sg\",\"y\")], type = \"raw\")\ndataAF &lt;- mxData(observed = df[df$sg == \"af\", c(\"sg\",\"y\")], type = \"raw\")\ndataBM &lt;- mxData(observed = df[df$sg == \"bm\", c(\"sg\",\"y\")], type = \"raw\")\ndataBF &lt;- mxData(observed = df[df$sg == \"bf\", c(\"sg\",\"y\")], type = \"raw\")\ndataCM &lt;- mxData(observed = df[df$sg == \"cm\", c(\"sg\",\"y\")], type = \"raw\")\ndataCF &lt;- mxData(observed = df[df$sg == \"cf\", c(\"sg\",\"y\")], type = \"raw\")\n\n### \"Less Constrained\" model\n## Means for each group - Means differ across the groups\nmeanAM &lt;- mxPath(from = \"one\", to = \"y\", arrows = 1, values = 0.5, label = \"am\")\nmeanAF &lt;- mxPath(from = \"one\", to = \"y\", arrows = 1, values = 0.5, label = \"af\")\nmeanBM &lt;- mxPath(from = \"one\", to = \"y\", arrows = 1, values = 0.5, label = \"bm\")\nmeanBF &lt;- mxPath(from = \"one\", to = \"y\", arrows = 1, values = 0.5, label = \"bf\")\nmeanCM &lt;- mxPath(from = \"one\", to = \"y\", arrows = 1, values = 0.5, label = \"cm\")\nmeanCF &lt;- mxPath(from = \"one\", to = \"y\", arrows = 1, values = 0.5, label = \"cf\")\n\n## Residual variance - Constrained to equality across the groups\nvar &lt;- mxPath(from = \"y\", arrows = 2, values = 1, label = \"e\")\n\n## Setup the group models\nmodAM &lt;- mxModel(\"GrAM\", type = \"RAM\",\n   manifestVars = \"y\", dataAM, meanAM, var)\n\nmodAF &lt;- mxModel(\"GrAF\", type = \"RAM\",\n   manifestVars = \"y\", dataAF, meanAF, var)\n\nmodBM &lt;- mxModel(\"GrBM\", type = \"RAM\",\n   manifestVars = \"y\", dataBM, meanBM, var)\n\nmodBF &lt;- mxModel(\"GrBF\", type = \"RAM\",\n   manifestVars = \"y\", dataBF, meanBF, var)\n\nmodCM &lt;- mxModel(\"GrCM\", type = \"RAM\",\n   manifestVars = \"y\", dataCM, meanCM, var)\n\nmodCF &lt;- mxModel(\"GrCF\", type = \"RAM\",\n   manifestVars = \"y\", dataCF, meanCF, var)\n\n## Combine the six models\nfun &lt;- mxFitFunctionMultigroup(c(\n   \"GrAM\", \"GrAF\", \"GrBM\", \"GrBF\", \"GrCM\", \"GrCF\"))\nmodelLC &lt;- mxModel(\"LC\", modAM, modAF, modBM, modBF, modCM, modCF, fun)\n\n## Run the LC model and get the summary\nfitLC &lt;- mxRun(modelLC)\nsummary(fitLC, refModels = mxRefModels(fitLC, run = TRUE))\n\n## Get the means and error variance\n## Compare with SEM results in Table 21.4\nmeansLC &lt;- coef(fitLC)[c(\"am\", \"bm\", \"cm\", \"af\", \"bf\", \"cf\")]; meansLC\nthetaLC &lt;- coef(fitLC)[\"e\"]; thetaLC\n\n### Gender main effect - unweighted means\n## To test the Gender main effect (applied to unweighted means), \n## constrain the mean for males to equal the mean for females. \n## But there are three means for males and three means for females. \n## Simply constrain the sum of the three means for males to equal \n## the sum of the three means for females.\n\n## Constraint\nconGU &lt;- mxConstraint(af + bf + cf == am + bm + cm)\n\n## Add it to \"Less Constrained\" model\nmodelGU &lt;- mxModel(modelLC, conGU)\nmodelGU &lt;- mxModel(modelGU, name = \"Gender Unweighted\")       # Change its name \n\n## Run the MC model and get the summary\nfitGU &lt;- mxRun(modelGU)\nsummary(fitGU, refModels = mxRefModels(fitGU, run = TRUE))\n\n## Get the means and error variance\nmeansGU &lt;- coef(fitGU)[c(\"am\", \"bm\", \"cm\", \"af\", \"bf\", \"cf\")]; meansGU\nthetaGU &lt;- coef(fitGU)[\"e\"]; thetaGU\n\n## Contrast the two models\nanova(fitGU, fitLC)\n\n### Coping Strategy main effect - unweighted means\n## To test for the \"Coping Strategy\" main effect, \n## restrict the mean for \"a\" strategy to equal the mean for \"b\" strategy\n## to equal the mean for \"c\" strategy. That is, constrain \n## the sum of the two \"a\" means to equal \n## the sum of the two \"b\" means; and \n## the sum of the two \"b\" means to equal \n## the sum of the two \"c\" means.\n\n## Constraints\nconCU1 &lt;- mxConstraint(af + am == bf + bm)\nconCU2 &lt;- mxConstraint(af + am == cf + cm)\n\n## Add them to \"Less Constrained\" model\nmodelCU &lt;- mxModel(modelLC, conCU1, conCU2)\nmodelCU &lt;- mxModel(modelCU, name = \"Coping Unweighted\")       # Change its name \n\n## Run the MC model and get the summary\nfitCU &lt;- mxRun(modelCU)\nsummary(fitCU, refModels = mxRefModels(fitCU, run = TRUE))\n\n## Get the means and error variance\nmeansCU &lt;- coef(fitCU)[c(\"am\", \"bm\", \"cm\", \"af\", \"bf\", \"cf\")]; meansCU\nthetaCU &lt;- coef(fitCU)[\"e\"]; thetaCU\n\n## Contrast the two models\nanova(fitCU, fitLC)\n\n### Gender main effect - weighted means\n## To test for the main effects applied to weighted means,\n## the constraints are set the same way as before except this time\n## the means are weighted in proportion to the cell frequencies.\n\n# Constraint\nfreq &lt;- table(df$g, df$x); freq      # cell frequencies\nconGW &lt;- mxConstraint((3*af + 3*bf + 6*cf)/12 == (6*am + 3*bm + 3*cm)/12)\n\n## Add it to \"Less Constrained\" model\nmodelGW &lt;- mxModel(modelLC, conGW)\nmodelGW &lt;- mxModel(modelGW, name = \"Gender Weighted\")       # Change its name\n\n## Run the MC model and get the summary\nfitGW &lt;- mxRun(modelGW)\nsummary(fitGW, refModels = mxRefModels(fitGW, run = TRUE))\n\n## Get the means and error variance\nmeansGW &lt;- coef(fitGW)[c(\"am\", \"bm\", \"cm\", \"af\", \"bf\", \"cf\")]; meansGW\nthetaGW &lt;- coef(fitGW)[\"e\"]; thetaGW\n\n## Contrast the two models\nanova(fitGW, fitLC)\n\n### Coping Strategy main effect - weighted means\n# Compare with SEM section in Table 21.4\n\n## Constraints\nfreq &lt;- table(df$g, df$x); freq      # cell frequencies\nconCW1 &lt;- mxConstraint((3*af + 6*am)/9 == (3*bf + 3*bm)/6 )\nconCW2 &lt;- mxConstraint((3*bf + 3*bm)/6 == (6*cf + 3*cm)/9)\n\n## Add them to \"Less Constrained\" model\nmodelCW &lt;- mxModel(modelLC, conCW1, conCW2)\nmodelCW &lt;- mxModel(modelCW, name = \"Coping Weighted\")       # Change its name\n\n## Run the MC model and get the summary\nfitCW &lt;- mxRun(modelCW)\nsummary(fitCW, refModels = mxRefModels(fitCW, run = TRUE))\n\n## Get the means and error variance\n## Compare with SEM results in Table 21.4\nmeansCW &lt;- coef(fitCW)[c(\"am\", \"bm\", \"cm\", \"af\", \"bf\", \"cf\")]; meansCW\nthetaCW &lt;- coef(fitCW)[\"e\"]; thetaCW\n\n## Contrast the two models\nanova(fitCW, fitLC)\n\n### Gender X Coping Strategy interaction\n## To test for the Gender X Coping Strategy interaction,\n## the \"More Constrained\" model needs the means to be constrained so that\n## the difference between the mean for \"female\" and the mean for \"male\" \n## remains constant across levels of \"Coping Strategy\". That is:\n\n## the difference between \"female\" mean and \"male\" mean for the \"a\" strategy equals\n## the difference between \"female\" mean and \"male\" mean for the \"b\" strategy; and\n## the difference between \"female\" mean and \"male\" mean for the \"b\" strategy equals\n## the difference between \"female\" mean and \"male\" mean for the \"c\" strategy.\n\n## Constraints\nconI1 &lt;- mxConstraint((af - am) == (bf - bm))\nconI2 &lt;- mxConstraint((bf - bm) == (cf - cm))\n\n## Add them to \"Less Constrained\" model\nmodelI &lt;- mxModel(modelLC, conI1, conI2)\nmodelI &lt;- mxModel(modelI, name = \"Interaction\")       # Change its name\n\n## Run the MC model and get the summary\nfitI &lt;- mxRun(modelI)\nsummary(fitI, refModels = mxRefModels(fitI, run = TRUE))\n\n## Get the means and error variance\nmeansI &lt;- coef(fitI)[c(\"am\", \"bm\", \"cm\", \"af\", \"bf\", \"cf\")]; meansI\nthetaI &lt;- coef(fitI)[\"e\"]; thetaI\n\n## Contrast the two models\nanova(fitI, fitLC)\n\n\n\n\none_way_MANOVA.r\n## One-way MANOVA\n##\n## Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling\n## approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural\n## equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\n\n# This example shows the SEM approach to a one-way MANOVA.\n# Results presented in Table 21.5 (p. 399).\n\n# The data are discussed on page 397.\n# Data are available in \"satisfactionII.r\".\n\n# The variables used here are:\n#   x - Coping Strategy (a - No strategy; b - Discussion; c - Exercise)\n#   y1, y2, y3, y4 - multiple dependent variables (Life-Satisfaction)\n\n## Load packages\nlibrary(OpenMx)\n\n## Get the data\nsource(\"satisfactionII.r\")\nhead(df)\n\n## Two models:\n# \"Less Constrained\" model - means allowed to differ across the groups;\n# \"More Constrained\" model - means constrained to equality across the groups.\n# Variances and covariances are constrained to equality across the groups.\n\n## Get data into OpenMx format for each group\ndataA &lt;- mxData(observed = df[df$x == \"a\", c(\"x\", \"y1\", \"y2\", \"y3\", \"y4\")], type = \"raw\")\ndataB &lt;- mxData(observed = df[df$x == \"b\", c(\"x\", \"y1\", \"y2\", \"y3\", \"y4\")], type = \"raw\")\ndataC &lt;- mxData(observed = df[df$x == \"c\", c(\"x\", \"y1\", \"y2\", \"y3\", \"y4\")], type = \"raw\")\n\n### \"Less Constrained\" model\n## Means for each group - Means differ across the groups\nmanifest &lt;- c(\"y1\", \"y2\", \"y3\", \"y4\")\nmeanA &lt;- mxPath(from = \"one\", to = manifest , arrows = 1,\n   values = 0.5, label = c(\"a1y1\", \"a1y2\", \"a1y3\", \"a1y4\"))\n\nmeanB &lt;- mxPath(from = \"one\", to = manifest , arrows = 1,\n   values = 0.5, label = c(\"a2y1\", \"a2y2\", \"a2y3\", \"a2y4\"))\n\nmeanC &lt;- mxPath(from = \"one\", to = manifest , arrows = 1,\n   values = 0.5, label = c(\"a3y1\", \"a3y2\", \"a3y3\", \"a3y4\"))\n\n## Residual variances/covariances - Constrained to equality across the groups\nvar &lt;- mxPath(from = manifest, to = manifest, connect = \"unique.pairs\", arrows = 2,\n   values = c(\n   1, 0.5, 0.5, 0.5,\n   1, 0.5, 0.5,\n   1, 0.5,\n   1),\n   labels = \n   c(\"e1\", \"e12\", \"e13\", \"e14\",\n     \"e2\", \"e23\", \"e24\",\n    \"e3\", \"e34\",\n    \"e4\"))\n\n## Setup the group models\nmodA &lt;- mxModel(\"GrA\", type = \"RAM\",\n   manifestVars = manifest, dataA, meanA, var)\n\nmodB &lt;- mxModel(\"GrB\", type = \"RAM\",\n   manifestVars = manifest, dataB, meanB, var)\n\nmodC &lt;- mxModel(\"GrC\", type = \"RAM\",\n   manifestVars = manifest, dataC, meanC, var)\n\n## Combine the three models\nfun &lt;- mxFitFunctionMultigroup(c(\"GrA\", \"GrB\", \"GrC\"))\nmodelLC &lt;- mxModel(\"LC\", modA, modB, modC, fun)\n\n## Run the LC model and get the summary\nfitLC &lt;- mxRun(modelLC)\nsummary(fitLC, refModels = mxRefModels(fitLC, run = TRUE))\n\n## Get the means, and compare with SEM results in Table 21.5\nmeansLC &lt;- coef(fitLC)[grepl(\"^a\", names(coef(fitLC)))]\nmatrix(meansLC, byrow = TRUE, nrow = 3, dimnames = list(c(\"a\", \"b\", \"c\"), manifest))\n\n## Get the error SSCP matrix - compare with Table 21.5\n## error SSCP = variance/covariance matrix X sample size  \nthetaLC &lt;- coef(fitLC)[grepl(\"^e\", names(coef(fitLC)))]; thetaLC\n\neLC &lt;- matrix( , 4, 4)                            # Empty matrix\neLC[upper.tri(eLC, diag = TRUE)] &lt;- thetaLC       # Fill the upper triangle\neLC &lt;- pmax(eLC, t(eLC), na.rm = TRUE)            # Fill the lower triangle\neLC &lt;- eLC * 200\nmatrix(eLC, 4, 4, dimnames = list(manifest, manifest))\n\n### \"More Constrained\" model\n# Constraints\nC1 &lt;- mxConstraint(a1y1 == a2y1)\nC2 &lt;- mxConstraint(a2y1 == a3y1)\n\nC3 &lt;- mxConstraint(a1y2 == a2y2)\nC4 &lt;- mxConstraint(a2y2 == a3y2)\n\nC5 &lt;- mxConstraint(a1y3 == a2y3)\nC6 &lt;- mxConstraint(a2y3 == a3y3)\n\nC7 &lt;- mxConstraint(a1y4 == a2y4)\nC8 &lt;- mxConstraint(a2y4 == a3y4)\n\n## Add them to \"Less Constrained\" model\nmodelMC &lt;- mxModel(modelLC, C1, C2, C3, C4, C5, C6, C7, C8)\nmodelMC &lt;- mxModel(modelMC, name = \"MC\")       # Change its name \n\n## Run the MC model and get the summary\nfitMC &lt;- mxRun(modelMC)\nsummary(fitMC, refModels = mxRefModels(fitMC, run = TRUE))\n\n## Get the means, and compare with SEM results in Table 21.5\nmeansMC &lt;- coef(fitMC)[grepl(\"^a\", names(coef(fitLC)))]\nmatrix(meansMC, byrow = TRUE, nrow = 3, dimnames = list(c(\"a\", \"b\", \"c\"), manifest))\n\n## Get the error SSCP matrix - Table 21.5\n## error SSCP = variance/covariance matrix X sample size\nthetaMC &lt;- coef(fitMC)[grepl(\"^e\", names(coef(fitLC)))]; thetaMC\n\neMC &lt;- matrix( , 4, 4)                              # Empty matrix\neMC[upper.tri(eMC, diag = TRUE)] &lt;- thetaMC         # Fill the upper triangle\neMC &lt;- pmax(eMC, t(eMC), na.rm = TRUE)              # Fill the lower triangle\neMC &lt;- eMC*200\nmatrix(eMC, 4, 4, dimnames = list(manifest, manifest))\n\n## Contrast the two models, and campare with chi sq test in Table 21.5\nanova(fitLC, fitMC)\n\n\n### Relax homogeneity of variances and covariances assumption. \n### See discussion in section headed \"Avoiding OLS Assumptions for \n### ANOVA/MANOVA Designs Using SEM\" (pp. 389-401)\n### \"Less Constrained\" model\n# Variance and covariances - differ across the groups\nvarA &lt;- mxPath(from = manifest, to = manifest, connect = \"unique.pairs\", arrows = 2,\n   values = c(\n   1, 0.5, 0.5, 0.5,\n        1, 0.5, 0.5,\n             1, 0.5,\n                  1),\n   labels = \n   c(\"e11a1\", \"e12a1\", \"e13a1\", \"e14a1\",\n              \"e22a1\", \"e23a1\", \"e24a1\",\n                      \"e33a1\", \"e34a1\",\n                               \"e44a1\"))\n\nvarB &lt;- mxPath(from = manifest, to = manifest, connect = \"unique.pairs\", arrows = 2,\n   values = c(\n   1, 0.5, 0.5, 0.5,\n   1, 0.5, 0.5,\n   1, 0.5,\n   1),\n   labels = \n   c(\"e11a2\", \"e12a2\", \"e13a2\", \"e14a2\",\n     \"e22a2\", \"e23a2\", \"e24a2\",\n    \"e33a2\", \"e34a2\",\n    \"e44a2\"))\n\nvarC &lt;- mxPath(from = manifest, to = manifest, connect = \"unique.pairs\", arrows = 2,\n   values = c(\n   1, 0.5, 0.5, 0.5,\n   1, 0.5, 0.5,\n   1, 0.5,\n   1),\n   labels = \n   c(\"e11a3\", \"e12a3\", \"e13a3\", \"e14a3\",\n     \"e22a3\", \"e23a3\", \"e24a3\",\n    \"e33a3\", \"e34a3\",\n    \"e44a3\"))\n\n## Everything else stays the same\n\n## Setup the group models\nmodA &lt;- mxModel(\"GrA\", type = \"RAM\",\n   manifestVars = manifest, dataA, meanA, varA)\n\nmodB &lt;- mxModel(\"GrB\", type = \"RAM\",\n   manifestVars = manifest, dataB, meanB, varB)\n\nmodC &lt;- mxModel(\"GrC\", type = \"RAM\",\n   manifestVars = manifest, dataC, meanC, varC)\n\n## Combine the three models\nfun &lt;- mxFitFunctionMultigroup(c(\"GrA\", \"GrB\", \"GrC\"))\nmodelLC &lt;- mxModel(\"LC\", modA, modB, modC, fun)\n\n## Run the LC model and get the summary\nfitLC &lt;- mxRun(modelLC)\nsummary(fitLC, refModels = mxRefModels(fitLC, run = TRUE))\n\n## Get the means\nmeansLC = coef(fitLC)[grepl(\"^a\", names(coef(fitLC)))]\nmatrix(meansLC, byrow = TRUE, nrow = 3, dimnames = list(c(\"a\", \"b\", \"c\"), manifest))\n\n## Get variance/covariance matrix\nthetaLC = coef(fitLC)[grepl(\"^e\", names(coef(fitLC)))]; thetaLC\n\n### \"More Constrained\" model\n## Constraints - same as before\nC1; C2; C3; C4; C5; C6; C7; C8\n\n## Add them to less constrained model\nmodelMC &lt;- mxModel(modelLC, C1, C2, C3, C4, C5, C6, C7, C8)\nmodelMC &lt;- mxModel(modelMC, name = \"MC\")       # Change its name \n\n## Run the MC model and get the summary\nfitMC &lt;- mxRun(modelMC)\nsummary(fitMC, refModels = mxRefModels(fitMC, run = TRUE))\n\n## Get the means\nmeansMC &lt;- coef(fitMC)[grepl(\"^a\", names(coef(fitLC)))]\nmatrix(meansMC, byrow = TRUE, nrow = 3, dimnames = list(c(\"a\", \"b\", \"c\"), manifest))\n\n## Get the variance/covariance matrix\nthetaMC &lt;- coef(fitMC)[grepl(\"^e\", names(coef(fitLC)))]; thetaMC\n\n## Contrast the two models, and campare with chi sq test on page 401\nanova(fitLC, fitMC)\n\n\n\n#### lavaan\nlibrary(lavaan)\n\n# Variances and covariances (for both models)\nvcov &lt;- \"\n   y1 ~~ y1 + y2 + y3 + y4\n   y2 ~~ y2 + y3 + y4\n   y3 ~~ y3 + y4\n   y4 ~~ y4\"\n\nmodels &lt;- list(\n\n\"Less Constrained\" =  c(\n# Means\n   \"y1 ~ c(a1, b1, c1)*1\n    y2 ~ c(a2, b2, c2)*1\n    y3 ~ c(a3, b3, c3)*1\n    y4 ~ c(a4, b4, c4)*1\",\n    \n    vcov),\n\n\"More Constrained\" = c(\n# Means\n   \"y1 ~ c(a1, a1, a1)*1\n    y2 ~ c(a2, a2, a2)*1\n    y3 ~ c(a3, a3, a3)*1\n    y4 ~ c(a4, a4, a4)*1\",\n    \n    vcov)\n)\n\n# Fit the models \nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n# Get model summaries\nlapply(fit, summary)[[1]]\n\n# Contrast model fits\nReduce(anova, fit)\n\n\n\n\none_way_LATENT.r\n## One-way ANOVA of latent variable\n##\n## Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling\n## approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural\n## equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\n\n# This example shows the SEM approach to a one-way ANOVA of latent means.\n# Results presented in Table 21.6 (p. 404).\n\n# Data are available in \"satisfactionII.r\".\n\n# The variables used here are:\n#   x - Coping Strategy (a - No strategy; b - Discussion; c - Exercise)\n#   y1, y2, y3, y4 - multiple dependent variables (Life-Satisfaction) \n\n## Load packages\nlibrary(OpenMx)\n\n## Get the data\nsource(\"satisfactionII.r\")\nhead(df)\n\n## Comparisons of latent means assume some level of measurement invariance.\n# Thompson, Lie, and Green (TLG) assume strict measurement invariance:\n# loadings, intercepts, and residual variances and covariances are constrainted\n# to equality across the groups (covariances are zero, and thus they are equal).\n# TLG also constrain the latent error variance to equality across the groups.\n\n# Latent variables require constraints for the purposes of identification and scaling.\n# TLG claim the loading for the 4th indicator is constrained to 1,\n# but I think that is a typo. TLG constrain the loading of the 1st indicator to 1,\n# and because of measurement invariance, this constraint applies to all groups.\n# Also, TLG constrain the latent mean to 0 in the first group only.\n\n## Two models:\n# \"Less Constrained\" model - latent means are freely estimated in the other two groups;\n# \"More Constrained\" model - latent means constrained to equality across the groups;\n# that is, they are all constrained to 0.\n\n## Get data into OpenMx format for each group\ndataA &lt;- mxData(observed = df[df$x == \"a\", c(\"x\", \"y1\", \"y2\", \"y3\", \"y4\")], type = \"raw\")\ndataB &lt;- mxData(observed = df[df$x == \"b\", c(\"x\", \"y1\", \"y2\", \"y3\", \"y4\")], type = \"raw\")\ndataC &lt;- mxData(observed = df[df$x == \"c\", c(\"x\", \"y1\", \"y2\", \"y3\", \"y4\")], type = \"raw\")\n\n### \"Less Constrained\" model\n# Factor loadings - equal across groups\nmanifest &lt;- c(\"y1\", \"y2\", \"y3\", \"y4\")\nloadings &lt;- mxPath(from = \"LS\", to = manifest, arrows = 1,\n   free = c(FALSE, TRUE, TRUE, TRUE), values = 1,   # First loading constrained to 1\n   labels = c(\"l1\", \"l2\", \"l3\", \"l4\"))\n\n## Factor variances - equal across groups\nvarFac &lt;- mxPath(from = \"LS\", arrows = 2,\n   free = TRUE, values = 1, labels = \"d\")\n\n## Residual variances - equal across groups\nvarRes &lt;- mxPath(from = manifest, arrows = 2,\n   free = TRUE, values = 1, \n   labels = c(\"e1\", \"e2\", \"e3\", \"e4\"))\n\n## Intercepts - equal across groups\nintercepts &lt;- mxPath(from = \"one\", to = manifest, arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"t1\", \"t2\", \"t3\", \"t4\"))\n\n## Factor means - differs across the groups\nmeanA &lt;- mxPath(from = \"one\", to = \"LS\", arrows = 1,\n   free = FALSE, values = 0, labels = \"a1\")\nmeanB &lt;- mxPath(from = \"one\", to = \"LS\", arrows = 1,\n   free = TRUE, values = 1, labels = \"a2\")\nmeanC &lt;- mxPath(from = \"one\", to = \"LS\", arrows = 1,\n   free = TRUE, values = 1, labels = \"a3\")\n\n## Setup the group models\nmodA &lt;- mxModel(\"GrA\", type = \"RAM\",\n   manifestVars = manifest, latentVars = \"LS\",\n   dataA, loadings, varFac, varRes, intercepts, meanA)\n\nmodB &lt;- mxModel(\"GrB\", type = \"RAM\",\n   manifestVars = manifest, latentVars = \"LS\",\n   dataB, loadings, varFac, varRes, intercepts, meanB)\n\nmodC &lt;- mxModel(\"GrC\", type = \"RAM\",\n   manifestVars = manifest, latentVars = \"LS\",\n   dataC, loadings, varFac, varRes, intercepts, meanC)\n\n## Combine the three models\nfun &lt;- mxFitFunctionMultigroup(c(\"GrA\", \"GrB\", \"GrC\"))\nmodelLC &lt;- mxModel(\"LC\", modA, modB, modC, fun)\n\n## Run the LC model and get the summary\nfitLC &lt;- mxRun(modelLC)\nsummary(fitLC, refModels = mxRefModels(fitLC, run = TRUE))\n\n## Trouble!! \n## Try letting OpenMx select starting values\nmodelLC = mxAutoStart(modelLC)\n\n## Try again\nfitLC &lt;- mxRun(modelLC)\nsummary(fitLC, refModels = mxRefModels(fitLC, run = TRUE))\n## All good\n\n## Get latent means and variance, and compare with \"All measures\" row in Table 21.6\nestimates &lt;- coef(fitLC)\n\nlatentMeans = coef(fitLC)[c(\"a2\", \"a3\")]; latentMeans\nlatentVar = coef(fitLC)[\"d\"]; latentVar\n\n### \"More Constrained\" model\n## Constraints\nC1 &lt;- mxConstraint(a2 == 0)\nC2 &lt;- mxConstraint(a3 == 0)\n\n## Add them to \"Less Constrained\" model\nmodelMC &lt;- mxModel(modelLC, C1, C2)\nmodelMC &lt;- mxModel(modelMC, name = \"MC\")       # Change its name \n\n## Run the MC model and get the summary\nfitMC &lt;- mxRun(modelMC)\nsummary(fitMC, refModels = mxRefModels(fitMC, run = TRUE))\n\n## Contrast the two models, and campare with chi sq test in Table 21.6\nanova(fitLC, fitMC)\n\n## Effect sizes, and compare with values on p. 405\n# Cut-and-paste means and variances to get effect sizes\nd1 &lt;- (0.6638 - 0) / sqrt(8.1346); d1    # \"no strategy\" vs \"discussion\"\nd2 &lt;- (1.9446 - 0) / sqrt(8.1346); d2    # \"no strategy\" vs \"exercise\"\n\n## Better - extract latent means and error variances from \"Less Constrained\" model\n## Already extracted above\nd1 &lt;- (latentMeans[1] - 0) / sqrt(latentVar); d1   # \"no strategy\" vs \"discussion\"\nd2 &lt;- (latentMeans[2] - 0) / sqrt(latentVar); d2   # \"no strategy\" vs \"exercise\"\n\n\n#### Minimal constraints\n# This section applies to the 2nd and 3rd rows in Table 21.6.\n# And see the discussion at the end of page 406, and top of page 407.\n\n## Get data into OpenMx format for each group\ndataA &lt;- mxData(observed = df[df$x == \"a\", c(\"x\", \"y1\", \"y2\", \"y3\", \"y4\")], type = \"raw\")\ndataB &lt;- mxData(observed = df[df$x == \"b\", c(\"x\", \"y1\", \"y2\", \"y3\", \"y4\")], type = \"raw\")\ndataC &lt;- mxData(observed = df[df$x == \"c\", c(\"x\", \"y1\", \"y2\", \"y3\", \"y4\")], type = \"raw\")\n\n\n### ANOVA model for 2nd row in Table 21.6\n# Constrain 1st loading only to equality across groups\n# and constrain 1st intercept only to equality across groups.\n\n## \"Less Constrained\" model\n\nmanifest &lt;- c(\"y1\", \"y2\", \"y3\", \"y4\")\n\n# Factor loadings - 1st loading constrained to 1\n#                 - other loadings freely estimated across groups\nloadsA &lt;- mxPath(from = \"LS\", to = manifest, arrows = 1,\n   free = c(FALSE, TRUE, TRUE, TRUE), values = 1,\n   labels = c(\"l1\", \"l2A\", \"l3A\", \"l4A\"))\n\nloadsB &lt;- mxPath(from = \"LS\", to = manifest, arrows = 1,\n   free = c(FALSE, TRUE, TRUE, TRUE), values = 1,\n   labels = c(\"l1\", \"l2B\", \"l3B\", \"l4B\"))\n\nloadsC &lt;- mxPath(from = \"LS\", to = manifest, arrows = 1,\n   free = c(FALSE, TRUE, TRUE, TRUE), values = 1,\n   labels = c(\"l1\", \"l2C\", \"l3C\", \"l4C\"))\n\n# Factor variances - freely estimated across groups \nvarFacA &lt;- mxPath(from = \"LS\", arrows = 2,\n   free = TRUE, values = 1, labels = \"dA\")\n\nvarFacB &lt;- mxPath(from = \"LS\", arrows = 2,\n   free = TRUE, values = 1, labels = \"dB\")\n\nvarFacC &lt;- mxPath(from = \"LS\", arrows = 2,\n   free = TRUE, values = 1, labels = \"dC\")\n\n# Residual variances - freely estimated across groups\nvarResA &lt;- mxPath(from = manifest, arrows = 2,\n   free = TRUE, values = 1, \n   labels = c(\"e1A\", \"e2A\", \"e3A\", \"e4A\"))\n\nvarResB &lt;- mxPath(from = manifest, arrows = 2,\n   free = TRUE, values = 1, \n   labels = c(\"e1B\", \"e2B\", \"e3B\", \"e4B\"))\n\nvarResC &lt;- mxPath(from = manifest, arrows = 2,\n   free = TRUE, values = 1,\n   labels = c(\"e1C\", \"e2C\", \"e3C\", \"e4C\"))\n\n# Intercepts - 1st intercept constrained to equality across groups\n#            - other intercepts freely estimated across groups\ninterceptsA &lt;- mxPath(from = \"one\", to = manifest, arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"t1\", \"t2A\", \"t3A\", \"t4A\"))\n\ninterceptsB &lt;- mxPath(from = \"one\", to = manifest, arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"t1\", \"t2B\", \"t3B\", \"t4B\"))\n\ninterceptsC &lt;- mxPath(from = \"one\", to = manifest, arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"t1\", \"t2C\", \"t3C\", \"t4C\"))\n\n# Factor means - differ across the groups\nmeanA &lt;- mxPath(from = \"one\", to = \"LS\", arrows = 1,\n   free = FALSE, values = 0, labels = \"aA\")\nmeanB &lt;- mxPath(from = \"one\", to = \"LS\", arrows = 1,\n   free = TRUE, values = 1, labels = \"aB\")\nmeanC &lt;- mxPath(from = \"one\", to = \"LS\", arrows = 1,\n   free = TRUE, values = 1, labels = \"aC\")\n\n# Setup the group models\nmodA &lt;- mxModel(\"GrA\", type = \"RAM\",\n   manifestVars = manifest, latentVars = \"LS\",\n   dataA, loadsA, varFacA, varResA, interceptsA, meanA)\n\nmodB &lt;- mxModel(\"GrB\", type = \"RAM\",\n   manifestVars = manifest, latentVars = \"LS\",\n   dataB, loadsB, varFacB, varResB, interceptsB, meanB)\n\nmodC &lt;- mxModel(\"GrC\", type = \"RAM\",\n   manifestVars = manifest, latentVars = \"LS\",\n   dataC, loadsC, varFacC, varResC, interceptsC, meanC)\n\n# Combine the three models\nfun &lt;- mxFitFunctionMultigroup(c(\"GrA\", \"GrB\", \"GrC\"))\nmodelLC &lt;- mxModel(\"LC\", modA, modB, modC, fun)\n\n# Run the LC model and get the summary\nfitLC &lt;- mxRun(modelLC)\n\n# Again trouble, but let OpenMx choose starting values\nmodelLC = mxAutoStart(modelLC)\n\nfitLC &lt;- mxRun(modelLC)\nsummary(fitLC, refModels = mxRefModels(fitLC, run = TRUE))\n# All good\n\n## More Consttained model\n# Constraints\nC1 = mxConstraint(aB == 0)\nC2 = mxConstraint(aC == 0)\n\n# Add them to less constrained model\nmodelMC = mxModel(modelLC, C1, C2)\nmodelMC = mxModel(modelMC, name = \"MC\")       # Change its name\n\n# Run the MC model and get the summary\nfitMC &lt;- mxRun(modelMC)\nsummary(fitMC, refModels = mxRefModels(fitMC, run = TRUE))\n\n## Contrast the two models, and campare with chi sq test in 2dn row in Table 21.6\nanova(fitLC, fitMC)\n\n## Get latent means and variances, and compare with \"All measures\" row in Table 21.6\nestimates &lt;- coef(fitLC)\n\nlatentMeans &lt;- coef(fitLC)[c(\"aB\", \"aC\")]; latentMeans\nlatentVar &lt;- coef(fitLC)[c(\"dA\", \"dB\", \"dC\")]; latentVar\n\n\n## Section of Table 21.6 headed \"Results for measures with invariant parameters\"\n# Sample statistics - get means and variances of 1st indicator for the 3 groups\ndfY1 &lt;- split(df$y1, df$x)\nmeansY1 &lt;- do.call(cbind, lapply(dfY1, mean)); meansY1\nvarY1 &lt;- do.call(cbind, lapply(dfY1, var)); varY1\n\n# Note: means agree with means in Table 21.6, but variances don't.\n# To get TLG variances, the denominator in the variance formula needs to be n, not (n-1)\n\n# Get the n's\nn &lt;- do.call(cbind, lapply(dfY1, length)); n\n\n# Adjust variance calculation\nvarY1 &lt;- varY1 * (n - 1) / n; varY1   # All good\n\n\n# Differences between y1 means\nmeansY1[2] - meansY1[1]\nmeansY1[3] - meansY1[1]\n\n# These equal the latent means; compare with latent means\nlatentMeans\n\n# Alternatively, the y1 intercepts (which are constrained to equality)\n# added to the latent means give the y1 Means\nintercepts &lt;- coef(fitLC)[\"t1\"]; intercepts\nintercepts + latentMeans; meansY1\n\n\n# Extract residual variances for y1 from estimates\nresidVarY1 &lt;- coef(fitLC)[c(\"e1A\", \"e1B\", \"e1C\")]   # Compare with 2nd row in Table 21.6\n\n# Differences between y1 variances and y1 residual variances\nvarY1 - residVarY1\n\n# These are latent variances - Compare with the latent variances\nlatentVar\n\n\n\n\n## ANOVA model for 3rd row in Table 21.6\n# Constrain 2nd loading to equality across groups\n# and constrain 2nd intercept to equality across groups\n\n## \"Less Constrained\" model\n\nmanifest &lt;- c(\"y1\", \"y2\", \"y3\", \"y4\")\n\n# Factor loadings\nloadsA &lt;- mxPath(from = \"LS\", to = manifest, arrows = 1,\n   free = c(TRUE, FALSE, TRUE, TRUE), values = 1,\n   labels = c(\"l1A\", \"l2\", \"l3A\", \"l4A\"))\n\nloadsB &lt;- mxPath(from = \"LS\", to = manifest, arrows = 1,\n   free = c(TRUE, FALSE, TRUE, TRUE), values = 1,\n   labels = c(\"l1B\", \"l2\", \"l3B\", \"l4B\"))\n\nloadsC &lt;- mxPath(from = \"LS\", to = manifest, arrows = 1,\n   free = c(TRUE, FALSE, TRUE, TRUE), values = 1,\n   labels = c(\"l1C\", \"l2\", \"l3C\", \"l4C\"))\n\n# Factor variances - equal across groups\nvarFacA &lt;- mxPath(from = \"LS\", arrows = 2,\n   free = TRUE, values = 1, labels = \"dA\")\n\nvarFacB &lt;- mxPath(from = \"LS\", arrows = 2,\n   free = TRUE, values = 1, labels = \"dB\")\n\nvarFacC &lt;- mxPath(from = \"LS\", arrows = 2,\n   free = TRUE, values = 1, labels = \"dC\")\n\n# Residual variances - equal across groups\nvarResA &lt;- mxPath(from = manifest, arrows = 2,\n   free = TRUE, values = 1, \n   labels = c(\"e1A\", \"e2A\", \"e3A\", \"e4A\"))\n\nvarResB &lt;- mxPath(from = manifest, arrows = 2,\n   free = TRUE, values = 1, \n   labels = c(\"e1B\", \"e2B\", \"e3B\", \"e4B\"))\n\nvarResC &lt;- mxPath(from = manifest, arrows = 2,\n   free = TRUE, values = 1, \n   labels = c(\"e1C\", \"e2C\", \"e3C\", \"e4C\"))\n\n# Intercepts - equal across groups\ninterceptsA &lt;- mxPath(from = \"one\", to = manifest, arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"t1A\", \"t2\", \"t3A\", \"t4A\"))\n\ninterceptsB &lt;- mxPath(from = \"one\", to = manifest, arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"t1B\", \"t2\", \"t3B\", \"t4B\"))\n\ninterceptsC &lt;- mxPath(from = \"one\", to = manifest, arrows = 1,\n   free = TRUE, values = 1,\n   labels = c(\"t1C\", \"t2\", \"t3C\", \"t4C\"))\n\n# Factor mean - differ across the groups\nmeanA &lt;- mxPath(from = \"one\", to = \"LS\", arrows = 1,\n   free = FALSE, values = 0, labels = \"aA\")\nmeanB &lt;- mxPath(from = \"one\", to = \"LS\", arrows = 1,\n   free = TRUE, values = 1, labels = \"aB\")\nmeanC &lt;- mxPath(from = \"one\", to = \"LS\", arrows = 1,\n   free = TRUE, values = 1, labels = \"aC\")\n\n# Setup the group models\nmodA &lt;- mxModel(\"GrA\", type = \"RAM\",\n   manifestVars = manifest, latentVars = \"LS\",\n   dataA, loadsA, varFacA, varResA, interceptsA, meanA)\n\nmodB &lt;- mxModel(\"GrB\", type = \"RAM\",\n   manifestVars = manifest, latentVars = \"LS\",\n   dataB, loadsB, varFacB, varResB, interceptsB, meanB)\n\nmodC &lt;- mxModel(\"GrC\", type = \"RAM\",\n   manifestVars = manifest, latentVars = \"LS\",\n   dataC, loadsC, varFacC, varResC, interceptsC, meanC)\n\n# Combine the three models\nfun &lt;- mxFitFunctionMultigroup(c(\"GrA\", \"GrB\", \"GrC\"))\nmodelLC &lt;- mxModel(\"LC\", modA, modB, modC, fun)\n\n# Run the LC model and get the summary\nfitLC &lt;- mxRun(modelLC)\n\n# Again, let OpenMx choose starting values\nmodelLC = mxAutoStart(modelLC)\n\nfitLC &lt;- mxRun(modelLC)\nsummary(fitLC, refModels = mxRefModels(fitLC, run = TRUE))\n# All good\n\n## More Consttained model\n# Constraints\nC1 &lt;- mxConstraint(aB == 0)\nC2 &lt;- mxConstraint(aC == 0)\n\n# Add them to less constrained model\nmodelMC &lt;- mxModel(modelLC, C1, C2)\nmodelMC &lt;- mxModel(modelMC, name = \"MC\")       # Change its name \n\n# Run the MC model and get the summary\nfitMC &lt;- mxRun(modelMC)\nsummary(fitMC, refModels = mxRefModels(fitMC, run = TRUE))\n\n## Contrast the two models, and campare with chi sq test in 2nd row in Table 21.6\nanova(fitLC, fitMC)\n\n## Get latent means and variance, and compare with \"All measures\" row in Table 21.6\nestimates &lt;- coef(fitLC)\n\nlatentMeans &lt;- coef(fitLC)[c(\"aB\", \"aC\")]; latentMeans\nlatentVar &lt;- coef(fitLC)[c(\"dA\", \"dB\", \"dC\")]; latentVar\n\n\n## Section of Table 21.6 headed \"Results for measures with invariant parameters\"\n# Sample statistics - get means and variances of 1st indicator for the 3 groups\ndfY2 &lt;- split(df$y2, df$x)\nmeansY2 &lt;- do.call(cbind, lapply(dfY2, mean)); meansY2\nvarY2 &lt;- do.call(cbind, lapply(dfY2, var)); varY2\n\nn &lt;- do.call(cbind, lapply(dfY2, length)); n\n\n# Adjust variance calculation\nvarY2 &lt;- varY2 * (n - 1) / n; varY2   # All good\n\n# Differences between y1 means\nmeansY2[2] - meansY2[1]\nmeansY2[3] - meansY2[1]\n\n# These equal the latent means; compare with latent means\nlatentMeans\n\n# Alternatively, the y1 intercepts (which are constrained to equality)\n# added to the latent means give the y2 Means\nintercepts &lt;- coef(fitLC)[\"t2\"]; intercepts\nintercepts + latentMeans; meansY2\n\n# Extract residual variances for y1 from estimates\nresidVarY2 &lt;- coef(fitLC)[c(\"e2A\", \"e2B\", \"e2C\")]   # Compare with 2nd row in Table 21.6\n\n# Differences between y2 variances and y2 residual variances\nvarY2 - residVarY2\n\n# These are the latent variances - Compare with the latent variances\nlatentVar",
    "crumbs": [
      "SEMs with OpenMx"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Kurbanoglu_2021/Kurbanoglu_2021.html",
    "href": "SEMs_with_lavaan/Kurbanoglu_2021/Kurbanoglu_2021.html",
    "title": "Mediation",
    "section": "",
    "text": "Kurbanoglu, N. & Takunyaci, M. (2021). A structural equation modeling on relationship between self-efficacy, physics laboratory anxiety and attitudes. Journal of Family, Counseling and Education, 6(1), 47-56.\nThis example shows how to obtain a basic three-variable mediation analysis using lavaan, and how to obtain indirect and total effects. The three variables are: Self-Efficacy; Physics Laboratory Attitudes; and Physics Laboratory Anxiety. Self-Efficacy has a direct effect on Anxiety, but also Self-Efficacy has an indirect effect on Anxiety via Attitudes. This example also shows how to use summary data when the raw sample data are not available; in particular, how to obtain a matrix of variances and covariances from the summary data (correlations and standard deviations), and then how to use the co/variance matrix to replicate the analysis.\nExcept in this case, the analysis cannot be replicated (see below). There are problems with the paper. Rather than being an examplar, this example is included to show how to run SEM using summary data in order to check published results.\n\nLoad relevant packages\nLoad the lavaan and semmcci packages.\n\nlibrary(lavaan)\nlibrary(semmcci)  # For Monte Carlo CIs\n\n\n\nGet the data\nSample data are not available, but Table 1 (p. 50) gives correlations, means, and standard deviations, and the sample size is given on page 49. From these, the co/variance matrix can be obtained. The correlations do not need to be in the form of a matrix. All that is required is a vector of the lower triangle of correlations with ones along the diagonal.\n\ncor &lt;- c(\n   1,\n   0.30,  1,\n  -0.42, -0.32,  1)\n\nsds &lt;- c(8.81, 7.95, 18.30)\nmeans &lt;- c(56.57, 40.39, 68.22)\nn &lt;- 513\n\nThe three variables need names, making sure the order is the same as in Table 1. The names used here are:\n\nSE - Self-Efficacy\nAtt - Physics Laboratory Attitudes\nAnx - Physics Laboratory Anxiety\n\n\nnames &lt;- c(\"Att\", \"SE\", \"Anx\")\n\nThe getCov() function from the lavaan package is used to get the co/variance matrix.\n\ncov &lt;- lavaan::getCov(cor, sds = sds, names = names)\n\n\n\nThe model\nThe model is given in Figure 1 (p. 51), reproduced below.\n\n\n\n\n\nKurbanoglu & Takunyaci (K&T) do not estimate the indirect effect; only the “a” and “b” paths. In lavaan, indirect effects can be estimated using the := operator. In the diagram, the effects are labelled a, b, and c\\('\\); in the model statement, they are labelled a, b, and cpr. The labels can then be used to obtain the indirect and total effects.\n\nmodel &lt;- \"\n  # direct effect\n  Anx ~ cpr * SE\n\n  # effects via the mediator\n  Att ~ a * SE\n  Anx ~ b * Att\n\n  # indirect effect (a * b)\n  ab := a * b\n\n  # total effect\n  total := cpr + (a * b)\n\"\n\n\n\nFit the model and get the results\nIn Figure 1, K&T present standardised estimates and R2 values; so they are requested here (for standardised estimates, see “std.all” column in the output).\n\nfit &lt;- sem(model, sample.cov = cov, sample.nobs = n)\nsummary(fit, rsquare = TRUE, standardized = TRUE, fit.measures = TRUE)\n\nI’ve requested a selection of fit measures. Why fit measures? Afterall, the model is saturated, and all fit measures should indicate a perfect fit. Something has gone awry for K&T. At the bottom of page 50, they state that the model is saturated. As a consequence, \\(\\upchi\\)2 and RMSEA should be zero, and GFI, AGF, CFI, NFI, RFI, and IFI should all be one; yet values are given (p. 50) to indicate a less than perfect fit. I’m not sure how this could have come about, or why the error was not picked up during review.\nIf the intercepts are required, include sample.mean = means in the sem() function.\n\nfit_intercepts &lt;- sem(model, sample.cov = cov, sample.nobs = n,\n   sample.mean = means)\nsummary(fit_intercepts, rsquare = TRUE, standardized = TRUE)\n\nDo not rely on the t-tests, especially for indirect effects. Often bootstrap confidence intervals are calculated, but bootstrapping requires the raw sample data. Instead of bootstrap CIs, Monte Carlo CIs can be calculated using the MC() function from the semmcci package.\n\nsemmcci::MC(fit, R = 50000, alpha = 0.05)\n\n\n\n\nR code with minimal commenting\n## Kurbanoglu, N. & Takunyaci, M. (2021). A structural equation modeling\n## on relationship between self-efficacy, physics laboratory anxiety\n## and attitudes. Journal of Family, Counseling and Education, 6(1), 47-56.\n\n## Load packages\nlibrary(lavaan)\nlibrary(semmcci)  # For Monte Carlo CIs\n\n## Get the data from Table 1\ncor &lt;- c(\n   1,\n   0.30,  1,\n  -0.42, -0.32,  1)\n\nsds &lt;- c(8.81, 7.95, 18.30)\nmeans &lt;- c(56.57, 40.39, 68.22)\nn &lt;- 513\n\n## Get the variable names\nnames &lt;- c(\"Att\", \"SE\", \"Anx\")\n\n## Get the co/variance matrix\ncov &lt;- lavaan::getCov(cor, sds = sds, names = names)\n\n## The model\nmodel &lt;- \"\n  # direct effect\n  Anx ~ cpr * SE\n\n  # effects via the mediator\n  Att ~ a * SE\n  Anx ~ b * Att\n\n  # indirect effect (a * b)\n  ab := a * b\n\n  # total effect\n  total := cpr + (a * b)\n\"\n\n## Fit the model and get the summary\n#  Compare with Figure 1\nfit &lt;- sem(model, sample.cov = cov, sample.nobs = n)\nsummary(fit, rsquare = TRUE, standardized = TRUE, fit.measures = TRUE)\n\n## To get intercepts\nfit_intercepts &lt;- sem(model, sample.cov = cov, sample.nobs = n,\n   sample.mean = means)\nsummary(fit_intercepts, rsquare = TRUE, standardized = TRUE)\n\n## To get Monte Carlo CIs\nsemmcci::MC(fit, R = 50000, alpha = 0.05)",
    "crumbs": [
      "SEMs with lavaan",
      "Mediation II"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Green_2023/one_way_LATENT.html",
    "href": "SEMs_with_lavaan/Green_2023/one_way_LATENT.html",
    "title": "One-Way ANOVA of Latent Variable",
    "section": "",
    "text": "Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\nThis example shows the SEM approach to a one-way ANOVA of a latent variable. Results are reported in Table 21.6 (p. 404).\nAny comparison of latent means assumes some level of measurement invariance. The first part of this example demonstrates SEM assuming strict measurement invariance. The second part demonstrates SEM under partial invariance of loadings and intercepts.\n\nLoad package and get the data\nLoad the lavaan package, and run satisfactionII.r to get the data.\n\nlibrary(lavaan)\n\nsource(\"satisfactionII.r\")\nhead(df)\n\nThe variables used in this example are:\n\nx - Coping Strategy (“a” - no strategy; “b” - discussion; “c” - exercise)\ny1, y2, y3, y4 - Multiple dependent variables (Life-Satisfaction scores)\n\n\n\nThe models\nThe SEM model for the one-way ANOVA of a latent variable is shown in Fig 21.3 (p. 403), and is reproduced below. The diagram shows the “Less Constrained” model.\n\n\n\n\n\nFor purposes of identification and scaling, the loading for the first indicator is constrained to one. (TLG claim that the loading for the 4th indicator is constrained to one. However, when the 4th loading is constrained to one, I do not get the same results as given in Table 21.6 (in particular the latent variance), nor do I get the means (given in the discussion on page 405); whereas I get agreement with the Table and the text when I constrain the 1st loading to one.)\nAlso for the purposes of identification and scaling, the latent mean for the first group is constrained to zero. For the “Less Constrained” model, the latent means for the other groups (a2 and a3) are freely estimated.\nTLG assume strict measurement invariance:\n\nthe loadings (\\(\\uplambda\\)) are constrained to equality across the groups;\nthe intercepts (\\(\\uptau\\)) are constrained to equality across the groups;\nthe indicator residual variances (e) and covariances are constrained to equality (covariances are set to zero by default, and thus they are equal);\nTLG impose one last constraint - latent error variances are constrained to equality across the groups (they do this to obtain a pooled variance to calculate an effect size for the differences between latent means).\n\nThe model statements are shown below. The only difference between the “More Constrained” model and the “Less Constrained” model is in the latent means. For purposess of identification and scaling, the latent mean for the first group is constrained to zero; in the “More Constrained” model, in which the means are constrained to equality, all three are constrained to zero. In the “Less Constrained” model, the means in the second and third groups are freely estimated.\nThe common parts of the two models are set up according to the bullet points above.\n\ncommon &lt;- \"\n   #  Measurement model\n   F =~ y1 + c(l2,l2,l2)*y2 + c(l3,l3,l3)*y3 + c(l4,l4,l4)*y4 \n\n   # Indicator intercepts\n   y1 ~ c(a1,a1,a1)*1\n   y2 ~ c(a2,a2,a2)*1\n   y3 ~ c(a3,a3,a3)*1\n   y4 ~ c(a4,a4,a4)*1\n\n   # Indicator residual variances\n   y1 ~~ c(e1,e1,e1)*y1\n   y2 ~~ c(e2,e2,e2)*y2\n   y3 ~~ c(e3,e3,e3)*y3\n   y4 ~~ c(e4,e4,e4)*y4\n\n   # Latent error variances\n   F ~~ c(d,d,d)*F\"\n\nmodels &lt;- list(\n  \"More Constrained\" = c(\n    \"# Latent means\n     F ~ c(m,m,m)*1\n\n     # Constraint\n     m == 0\",\n\n     common),\n\n  \"Less Constrained\" =  c(\n    \"# Latent means\n     F ~ c(m1,m2,m3)*1\n\n     # Constraint\n     m1 == 0\",\n\n     common)\n)\n\n\n\nFit the models and get the results\n\n## Fit the models \nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n## Get model summaries\nlapply(fit, summary)\n\n## Contrast model fits\nReduce(anova, fit)\n\nCompare with \\(\\upchi\\)2 test in the “All measures” row in Table 21.6.\nOne could scroll through the model summaries to find the latent means and error variances for the “Less Constrained” model, and compare them with Table 21.6. They are also needed to calculate effect sizes (given in the first column on page 405).\n\nd1 &lt;- (0.664 - 0) / sqrt(8.135); d1    # \"no strategy\" vs \"discussion\"\nd2 &lt;- (1.945 - 0) / sqrt(8.135); d2    # \"no strategy\" vs \"exercise\"\n\nBut it is probably safer to extract latent means and error variances from a list of parameter estimates, then substitute into the formula for effect size.\n\nestimates &lt;- lavInspect(fit[[\"Less Constrained\"]], \"est\"); estimates\n   # Note: latent means are in element \"alpha\"\n   #       latent error variances are in element \"psi\"\n\nLatentMeans &lt;- sapply(estimates, \"[[\", \"alpha\"); LatentMeans\nLatentVar   &lt;- sapply(estimates, \"[[\", \"psi\"); LatentVar\n\n   # \"no strategy\" vs \"discussion\"\nd1 &lt;- (LatentMeans[2] - LatentMeans[1]) / sqrt(LatentVar[1]); d1\n\n   # \"no strategy\" vs \"exercise\"\nd2 &lt;- (LatentMeans[3] - LatentMeans[1]) / sqrt(LatentVar[1]); d2\n\nCompare the effect sizes with those given on page 405, and the means and error variances with those in Table 21.6.\n\n\nMore Flexible Tests of Differences in Means on Latent Variables\nThe second and third rows of Table 21.6 follow after a discussion in the section headed “More Flexible Tests of Differences in Means on Latent Variables” (pp. 406-407).\nIn this section, TLG assume partial strong invariance:\n\nConstrain the loading for one indicator to equality across groups\nConstrain that indicator’s intercept to equality across groups\nThe other loadings and intercepts are freely estimated\n\nFor purposes of identification:\n\nFirst loading in each group is constrained to one\nLatent mean in the first group is constrained to zero\n\nNote that the residual variances are freely estimated across groups, as are the latent error variances. The indicator covariances are by default set to zero (unless there is good reason to have one or more estimated).\nFor the “More Constrained” model, the latent means are constrained to equality across the groups; for the “Less Constrained” model, the latent means differ.\nThe purpose of these examples is to demonstrate that “if a latent variable has only a single referent variable, the means and variances of the latent variable are a function of only the means and variances of this variable” (p. 406).\n\nModel that applies to the 2nd row in Table 21.6: “One measure - Y\\(_1\\)”\nThe selected indicator is the first - “y1”.\n\n# Model statements\ncommon &lt;- \n  \"# Measurement model\n   F =~ y1 + c(l12,l22,l32)*y2 + c(l13,l23,l33)*y3 + c(l14,l24,l34)*y4\n\n   # Indicator intercepts\n   y1 ~ c(a1,a1,a1)*1\n   y2 ~ c(a12,a22,a32)*1\n   y3 ~ c(a13,a23,a33)*1\n   y4 ~ c(a14,a24,a34)*1\n\n   # Indicator residual variances\n   y1 ~~ c(e11,e21,e31)*y1\n   y2 ~~ c(e12,e22,e32)*y2\n   y3 ~~ c(e13,e23,e33)*y3\n   y4 ~~ c(e14,e24,e34)*y4\n\n   # Latent error variances\n   F ~~ c(d1,d2,d3)*F\"\n\nmodels &lt;- list(\n  \"More Constrained\" = c(\n    \"# Latent means\n     F ~ c(m,m,m)*1\n\n     # Constraint\n     m == 0\",\n   \n     common),\n\n  \"Less Constrained\" =  c(\n    \"# Latent means\n     F ~ c(m1,m2,m3)*1\n\n     # Constraint\n     m1 == 0\",\n\n     common)\n)\n\nFit the models and get the latent means, latent error variances, and the \\(\\upchi\\)2 test.\n\n# Fit the models \nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n# Model summaries\nlapply(fit, summary)\n\n# Get the latent means and latent error variances for \"Less Constrained\" model\nestimates &lt;- lavInspect(fit[[\"Less Constrained\"]], \"est\"); estimates\nLatentMeans &lt;- sapply(estimates, \"[[\", \"alpha\"); LatentMeans\nLatentVar   &lt;- sapply(estimates, \"[[\", \"psi\"); LatentVar\n\n# Contrast model fits\nReduce(anova, fit)\n\nCompare with the latent means and error variances, and the \\(\\upchi\\)2 test in the 2nd row in Table 21.6.\nConsider the three columns of Table 21.6 dealing with means, variances and residual variances of one measure - in this case, “y1”.\nI need sample means and covariances - they can be extract from a list of sample statistics. I need estimated indicator intercepts and residual variances - they can be extracted from estimates. Also I need estimated latent means and error variances - they have already been extracted.\n\n# Get sample statistics\nsampstat &lt;- lavInspect(fit[[\"Less Constrained\"]], \"sampstat\"); sampstat\n   # Means are in element \"mean\"\n   # Variances are the diagonal elements in element \"cov\"\n\n# Get estimated model parameters\nestimates\n   # Residual variances for the measures are the diagonal elements in element \"theta\"\n   # Intercepts for the measures are in element \"nu\"\n\n\nMeans of the measures for each group (ie, the “y1” means).\n\nExtract the “y1” means from sampstats\nLatent means already extracted in LatentMeans\nThe differences between the “y1” means are the differences between the latent means\n\nAlternatively, the “y1” intercepts (which are constrained to equality) when added to the latent means give the “y1” means\n\n\n# Extract y1 means from sampstats\nMeansY1 &lt;- sapply(sampstat, \"[[\", \"mean\")\nMeansY1 &lt;- MeansY1[1,]; MeansY1   # Compare with 2nd row in Table 21.6\n\n# Differences between y1 means are differencs between latent means\nMeansY1[2] - MeansY1[1]\nMeansY1[3] - MeansY1[1]\n\n# Compare with latent means\nLatentMeans\n\n# Alternatively, the y1 intercepts (which are constrained to equality)\n# added to the latent means give the y1 means\nintercepts &lt;- sapply(estimates, \"[[\", \"nu\")[1,1]; intercepts\nintercepts + LatentMeans; MeansY1\n\n\n\nVariances of the measure for each group (ie, “y1” variances)\n\nExtract the “y1” variances from sampstats\nExtract residual variances for “y1” from estimates\nLatent error variances already extracted in LatentVar\nDifferences between “y1” variances and “y1” residual variances are the latent error variances\n\n\n# Extract y1 variances from sampstats\nVarY1 &lt;- sapply(lapply(sampstat, \"[[\", \"cov\"), diag)\nVarY1 &lt;- VarY1[1,]; VarY1  # Compare with 2nd row in Table 21.6\n\n# Extract residual variances for y1 from estimates\nResidVarY1 &lt;- sapply(lapply(estimates, \"[[\", \"theta\"), diag)\nResidVarY1 &lt;- ResidVarY1[1,]; ResidVarY1   # Compare with 2nd row in Table 21.6\n\n# Differences between y1 variances and y1 residual variances are latent error variances\nVarY1 - ResidVarY1\n\n# Compare with the latent error variances\nLatentVar\n\n\n\n\nModel that applies to the 3rd row in Table 21.6: “One measure - Y\\(_2\\)”\nThe selected indicator is the second - “y2”.\nThis is the same as before, except the constraints on the loadings and intercepts apply to the second indicator.\n\n# Model statements\ncommon &lt;- \n  \"# Measurement model\n   F =~ NA*c(l11,l21,l31)*y1 + 1*y2 + c(l13,l23,l33)*y3 + c(l14,l24,l34)*y4 \n\n   # Indicator intercepts \n   y1 ~ c(a11,a21,a31)*1\n   y2 ~ c(a2,a2,a2)*1\n   y3 ~ c(a13,a23,a33)*1\n   y4 ~ c(a14,a24,a34)*1\n\n   # Indicator residual variances\n   y1 ~~ c(e11,e21,e31)*y1\n   y2 ~~ c(e12,e22,e32)*y2\n   y3 ~~ c(e13,e23,e33)*y3\n   y4 ~~ c(e14,e24,e34)*y4\n\n   # Latent error variances\n   F ~~ c(d1,d2,d3)*F\"\n\nmodels &lt;- list(\n  \"Less Constrained\" =  c(\n    \"# Latent means\n     F ~ c(m1,m2,m3)*1\n\n     # Constraint\n     m1 == 0\",\n\n     common),\n\n  \"More Constrained\" = c(\n    \"# Latent means\n     F ~ c(m,m,m)*1\n\n     # Constraint\n     m == 0\",\n\n     common)\n)\n\nFit the models and get the latent means, latent error variances, and the \\(\\upchi\\)2 test.\n\n# Fit the models\nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n# Model summaries\nlapply(fit, summary)\n\n# Get the latent means and latent error variances for \"Less Constrained\" model\nestimates &lt;- lavInspect(fit[[\"Less Constrained\"]], \"est\"); estimates\nLatentMeans &lt;- sapply(estimates, \"[[\", \"alpha\"); LatentMeans\nLatentVar   &lt;- sapply(estimates, \"[[\", \"psi\"); LatentVar\n\n# Contrast model fits\nReduce(anova, fit)\n\nCompare with the latent means and error variances, and the \\(\\upchi\\)2 test in the 3rd row in Table 21.6.\nConsider the three columns of Table 21.6 dealing with means, variances and residual variances of one measure - in this case, “y2”.\nI need sample means and covariances - they can be extract from a list of sample statistics. I need estimated indicator intercepts and residual variances - they can be extracted from estimates. Also I need estimated latent means and error variances - they have already been extracted.\n\n# Get sample statistics\nsampstat &lt;- lavInspect(fit[[\"Less Constrained\"]], \"sampstat\"); sampstat\n   # Means are in element \"mean\"\n   # Variances are the diagonal elements in element \"cov\"\n\n# Get estimated model parameters\nestimates\n   # Residual variances for the measures are the diagonal elements in element \"theta\"\n   # Intercepts for the measures are in element \"nu\"\n\n\nThe means of the measures for each group (ie, the “y2” means).\n\nExtract the “y2” means from sampstats\nLatent means already extracted in LatentMeans\nThe differences between the “y2” means are the differences between the latent means\nAlternatively, the “y2” intercepts (which are constrained to equality) when added to the latent means give the “y2” means\n\n\n# Extract y2 Means from sampstats\nMeansY2 &lt;- sapply(sampstat, \"[[\", \"mean\")\nMeansY2 &lt;- MeansY2[2,]; MeansY2   # Compare with 3rd row in Table 21.6\n\n# Differences between y2 means are differencs between latent means\nMeansY2[2] - MeansY2[1]\nMeansY2[3] - MeansY2[1]\n\n# Compare with latent means\nLatentMeans\n\n# Alternatively, the y2 intercepts (which are constrained to equality)\n# added to the latent means give the Y2 means\nintercepts &lt;- sapply(estimates, \"[[\", \"nu\")[2,1]; intercepts\nintercepts + LatentMeans; MeansY2\n\n\n\nThe variances of the measure for each group (ie, “y2” variances)\n\nExtract the “y2” variances from sampstats\nExtract residual variances for “y2” from estimates\nLatent error variances already extracted in LatentVar\nDifferences between “y2” variances and “y2” residual variances are the latent error variances\n\n\n# Extract y2 variances from sampstats\nVarY2 &lt;- sapply(lapply(sampstat, \"[[\", \"cov\"), diag)\nVarY2 &lt;- VarY2[2,]; VarY2  # Compare with 3rd row in Table 21.6\n\n# Extract residual variances for y2 from estimates\nResidVarY2 &lt;- sapply(lapply(estimates, \"[[\", \"theta\"), diag)\nResidVarY2 &lt;- ResidVarY2[2, ]; ResidVarY2  # Compare with 3rd row in Table 21.6\n\n# Differences between y2 variances and y2 residual variances are latent error variances\nVarY2 - ResidVarY2\n\n# Compare with the latent error variances\nLatentVar\n\n\n\n\nR code with minimal commenting\n## One-way ANOVA of latent variable\n##\n## Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling\n## approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural\n## equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\n\n## Load package\nlibrary(lavaan)\n\n## Get the data\nsource(\"satisfactionII.r\")\nhead(df)\n\n## The models\ncommon &lt;- \"\n   #  Measurement model\n   F =~ y1 + c(l2,l2,l2)*y2 + c(l3,l3,l3)*y3 + c(l4,l4,l4)*y4\n\n   # Indicator intercepts\n   y1 ~ c(a1,a1,a1)*1\n   y2 ~ c(a2,a2,a2)*1\n   y3 ~ c(a3,a3,a3)*1\n   y4 ~ c(a4,a4,a4)*1\n\n   # Indicator residual variances\n   y1 ~~ c(e1,e1,e1)*y1\n   y2 ~~ c(e2,e2,e2)*y2\n   y3 ~~ c(e3,e3,e3)*y3\n   y4 ~~ c(e4,e4,e4)*y4\n\n   # Latent error variances\n   F ~~ c(d,d,d)*F\"\n\nmodels &lt;- list(\n  \"More Constrained\" = c(\n    \"# Latent means\n     F ~ c(m,m,m)*1\n\n     # Constraint\n     m == 0\",\n\n     common),\n\n  \"Less Constrained\" =  c(\n    \"# Latent means\n     F ~ c(m1,m2,m3)*1\n\n     # Constraint\n     m1 == 0\",\n\n     common)\n)\n\n## Fit the models and get the results\n## Check results in \"All measures\" row in Table 21.6\n## Fit the models\nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n## Get model summaries\nlapply(fit, summary)\n\n## Contrast model fits\nReduce(anova, fit)\n\n## Cut-and-paste means and variances to get effect sizes\n## Compare with values given on page 405\nd1 &lt;- (0.664 - 0) / sqrt(8.135); d1    # \"no strategy\" vs \"discussion\"\nd2 &lt;- (1.945 - 0) / sqrt(8.135); d2    # \"no strategy\" vs \"exercise\"\n\n## Extract latent means and error variances from \"Less Constrained\" model\n## Check with \"All measures\" row in Table 21.6\nestimates &lt;- lavInspect(fit[[\"Less Constrained\"]], \"est\"); estimates\n   # Note: latent means are in element \"alpha\"\n   #       latent error variances are in element \"psi\"\n\nLatentMeans &lt;- sapply(estimates, \"[[\", \"alpha\"); LatentMeans\nLatentVar   &lt;- sapply(estimates, \"[[\", \"psi\"); LatentVar\n\n## Effect sizes\n## Compare with values given on page 405\n   # \"no strategy\" vs \"discussion\"\nd1 &lt;- (LatentMeans[2] - LatentMeans[1]) / sqrt(LatentVar[1]); d1\n\n   # \"no strategy\" vs \"exercise\"\nd2 &lt;- (LatentMeans[3] - LatentMeans[1]) / sqrt(LatentVar[1]); d2\n\n## Relaxing some constraints\n## ANOVA model for 2nd row in Table 21.6\n# Model statements\ncommon &lt;-\n  \"# Measurement model\n   F =~ y1 + c(l12,l22,l32)*y2 + c(l13,l23,l33)*y3 + c(l14,l24,l34)*y4\n\n   # Indicator intercepts\n   y1 ~ c(a1,a1,a1)*1\n   y2 ~ c(a12,a22,a32)*1\n   y3 ~ c(a13,a23,a33)*1\n   y4 ~ c(a14,a24,a34)*1\n\n   # Indicator residual variances\n   y1 ~~ c(e11,e21,e31)*y1\n   y2 ~~ c(e12,e22,e32)*y2\n   y3 ~~ c(e13,e23,e33)*y3\n   y4 ~~ c(e14,e24,e34)*y4\n\n   # Latent error variances\n   F ~~ c(d1,d2,d3)*F\"\n\nmodels &lt;- list(\n  \"More Constrained\" = c(\n    \"# Latent means\n     F ~ c(m,m,m)*1\n\n     # Constraint\n     m == 0\",\n\n     common),\n\n  \"Less Constrained\" =  c(\n    \"# Latent means\n     F ~ c(m1,m2,m3)*1\n\n     # Constraint\n     m1 == 0\",\n\n     common)\n)\n\n## Fit the model and get the results\n## Check with means, error variance, and chi square in 2nd row in Table 21.6\n# Fit the models\nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n# Model summaries\nlapply(fit, summary)\n\n# Get the latent means and latent error variances for \"Less Constrained\" model\nestimates &lt;- lavInspect(fit[[\"Less Constrained\"]], \"est\"); estimates\nLatentMeans &lt;- sapply(estimates, \"[[\", \"alpha\"); LatentMeans\nLatentVar   &lt;- sapply(estimates, \"[[\", \"psi\"); LatentVar\n\n# Contrast model fits\nReduce(anova, fit)\n\n## Columns of Table 21.6 dealing with means, variances and residual variances of \"y1\"\n## Need sample statistics and model estimates\n# Get sample statistics\nsampstat &lt;- lavInspect(fit[[\"Less Constrained\"]], \"sampstat\"); sampstat\n   # Means are in element \"mean\"\n   # Variances are the diagonal elements in element \"cov\"\n\n# Get estimated model parameters\nestimates\n   # Residual variances for the measures are the diagonal elements in element \"theta\"\n   # Intercepts for the measures are in element \"nu\"\n\n# Extract y1 means from sampstats\nMeansY1 &lt;- sapply(sampstat, \"[[\", \"mean\")\nMeansY1 &lt;- MeansY1[1,]; MeansY1   # Compare with 2nd row in Table 21.6\n\n# Differences between y1 means are differencs between latent means\nMeansY1[2] - MeansY1[1]\nMeansY1[3] - MeansY1[1]\n\n# Compare with latent means\nLatentMeans\n\n# Alternatively, the y1 intercepts (which are constrained to equality)\n# added to the latent means give the y1 means\nintercepts &lt;- sapply(estimates, \"[[\", \"nu\")[1,1]; intercepts\nintercepts + LatentMeans; MeansY1\n\n# Extract y1 variances from sampstats\nVarY1 &lt;- sapply(lapply(sampstat, \"[[\", \"cov\"), diag)\nVarY1 &lt;- VarY1[1,]; VarY1  # Compare with 2nd row in Table 21.6\n\n# Extract residual variances for y1 from estimates\nResidVarY1 &lt;- sapply(lapply(estimates, \"[[\", \"theta\"), diag)\nResidVarY1 &lt;- ResidVarY1[1,]; ResidVarY1   # Compare with 2nd row in Table 21.6\n\n# Differences between y1 variances and y1 residual variances are latent error variances\nVarY1 - ResidVarY1\n\n# Compare with the latent error variances\nLatentVar\n\n## Relaxing some consyraints\n## ANOVA model for 3rd row in Table 21.6\n# Model statements\ncommon &lt;-\n  \"# Measurement model\n   F =~ NA*c(l11,l21,l31)*y1 + 1*y2 + c(l13,l23,l33)*y3 + c(l14,l24,l34)*y4\n\n   # Indicator intercepts\n   y1 ~ c(a11,a21,a31)*1\n   y2 ~ c(a2,a2,a2)*1\n   y3 ~ c(a13,a23,a33)*1\n   y4 ~ c(a14,a24,a34)*1\n\n   # Indicator residual variances\n   y1 ~~ c(e11,e21,e31)*y1\n   y2 ~~ c(e12,e22,e32)*y2\n   y3 ~~ c(e13,e23,e33)*y3\n   y4 ~~ c(e14,e24,e34)*y4\n\n   # Latent error variances\n   F ~~ c(d1,d2,d3)*F\"\n\nmodels &lt;- list(\n  \"Less Constrained\" =  c(\n    \"# Latent means\n     F ~ c(m1,m2,m3)*1\n\n     # Constraint\n     m1 == 0\",\n\n     common),\n\n  \"More Constrained\" = c(\n    \"# Latent means\n     F ~ c(m,m,m)*1\n\n     # Constraint\n     m == 0\",\n\n     common)\n)\n\n## Fit the model and get the results\n## Check with means, error variance, and chi square in 3rd row in Table 21.6\n# Fit the models\nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n# Model summaries\nlapply(fit, summary)\n\n# Get the latent means and latent error variances for \"Less Constrained\" model\nestimates &lt;- lavInspect(fit[[\"Less Constrained\"]], \"est\"); estimates\nLatentMeans &lt;- sapply(estimates, \"[[\", \"alpha\"); LatentMeans\nLatentVar   &lt;- sapply(estimates, \"[[\", \"psi\"); LatentVar\n\n# Contrast model fits\nReduce(anova, fit)\n\n## Columns of Table 21.6 dealing with means, variances and residual variances of \"y2\"\n## Need sample statistics and model estimates\n# Get sample statistics\nsampstat &lt;- lavInspect(fit[[\"Less Constrained\"]], \"sampstat\"); sampstat\n   # Means are in element \"mean\"\n   # Variances are the diagonal elements in element \"cov\"\n\n# Get estimated model parameters\nestimates\n   # Residual variances for the measures are the diagonal elements in element \"theta\"\n   # Intercepts for the measures are in element \"nu\"\n\n# Extract y2 Means from sampstats\nMeansY2 &lt;- sapply(sampstat, \"[[\", \"mean\")\nMeansY2 &lt;- MeansY2[2,]; MeansY2   # Compare with 3rd row in Table 21.6\n\n# Differences between y2 means are differencs between latent means\nMeansY2[2] - MeansY2[1]\nMeansY2[3] - MeansY2[1]\n\n# Compare with latent means\nLatentMeans\n\n# Alternatively, the y2 intercepts (which are constrained to equality)\n# added to the latent means give the Y2 means\nintercepts &lt;- sapply(estimates, \"[[\", \"nu\")[2,1]; intercepts\nintercepts + LatentMeans; MeansY2\n\n# Extract y2 variances from sampstats\nVarY2 &lt;- sapply(lapply(sampstat, \"[[\", \"cov\"), diag)\nVarY2 &lt;- VarY2[2,]; VarY2  # Compare with 3rd row in Table 21.6\n\n# Extract residual variances for y2 from estimates\nResidVarY2 &lt;- sapply(lapply(estimates, \"[[\", \"theta\"), diag)\nResidVarY2 &lt;- ResidVarY2[2, ]; ResidVarY2  # Compare with 3rd row in Table 21.6\n\n# Differences between y2 variances and y2 residual variances are latent error variances\nVarY2 - ResidVarY2\n\n# Compare with the latent error variances\nLatentVar\n\n\n\n\nR code to get data file - satisfactionII.r\n### Data for Tables 21.5 and 21.6 ###\n\ndf &lt;- structure(list(x = c(\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\"), x1 = c(1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L), x2 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L), x3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), y1 = c(18L, 24L, \n21L, 24L, 19L, 22L, 23L, 32L, 24L, 22L, 24L, 23L, 28L, 22L, 22L, \n23L, 19L, 28L, 25L, 25L, 27L, 21L, 33L, 24L, 23L, 28L, 29L, 24L, \n28L, 24L, 26L, 28L, 21L, 26L, 20L, 24L, 22L, 32L, 31L, 22L, 22L, \n27L, 22L, 26L, 24L, 24L, 25L, 27L, 26L, 24L, 22L, 18L, 25L, 27L, \n29L, 24L, 22L, 32L, 23L, 27L, 28L, 24L, 18L, 32L, 27L, 25L, 24L, \n25L, 29L, 21L, 29L, 25L, 25L, 25L, 19L, 32L, 29L, 22L, 18L, 26L, \n23L, 26L, 21L, 18L, 24L, 24L, 17L, 24L, 33L, 21L, 23L, 27L, 26L, \n28L, 20L, 27L, 25L, 25L, 25L, 18L, 27L, 25L, 22L, 23L, 26L, 23L, \n29L, 26L, 24L, 27L, 22L, 24L, 26L, 31L, 27L, 22L, 22L, 26L, 25L, \n21L, 26L, 25L, 24L, 26L, 28L, 27L, 26L, 26L, 19L, 22L, 25L, 26L, \n30L, 22L, 26L, 25L, 27L, 32L, 22L, 27L, 26L, 30L, 32L, 28L, 25L, \n23L, 21L, 14L, 26L, 28L, 29L, 25L, 27L, 25L, 26L, 21L, 23L, 25L, \n26L, 30L, 30L, 26L, 22L, 31L, 28L, 26L, 29L, 25L, 26L, 24L, 28L, \n22L, 35L, 26L, 34L, 29L, 26L, 27L, 32L, 16L, 26L, 22L, 25L, 30L, \n28L, 25L, 22L, 23L, 28L, 23L, 36L, 27L, 24L, 23L, 34L, 31L, 33L, \n26L, 27L, 22L), y2 = c(49L, 50L, 51L, 53L, 44L, 50L, 52L, 55L, \n53L, 48L, 48L, 51L, 57L, 51L, 48L, 51L, 48L, 53L, 59L, 55L, 51L, \n54L, 63L, 49L, 54L, 54L, 52L, 47L, 50L, 49L, 54L, 57L, 51L, 53L, \n49L, 53L, 53L, 57L, 58L, 49L, 53L, 55L, 59L, 57L, 55L, 53L, 55L, \n54L, 47L, 54L, 48L, 47L, 50L, 59L, 52L, 52L, 52L, 60L, 59L, 50L, \n55L, 59L, 55L, 59L, 61L, 48L, 55L, 55L, 60L, 50L, 62L, 54L, 56L, \n61L, 52L, 55L, 51L, 56L, 52L, 56L, 53L, 49L, 59L, 51L, 57L, 55L, \n48L, 54L, 56L, 53L, 47L, 54L, 52L, 54L, 50L, 54L, 52L, 54L, 59L, \n54L, 61L, 54L, 54L, 50L, 56L, 51L, 59L, 50L, 52L, 55L, 57L, 57L, \n62L, 55L, 53L, 51L, 50L, 60L, 51L, 52L, 52L, 56L, 52L, 55L, 56L, \n51L, 64L, 54L, 47L, 51L, 54L, 55L, 55L, 55L, 54L, 55L, 58L, 57L, \n56L, 60L, 55L, 54L, 61L, 55L, 50L, 53L, 60L, 49L, 58L, 61L, 55L, \n51L, 58L, 53L, 55L, 49L, 55L, 53L, 56L, 53L, 55L, 53L, 48L, 59L, \n56L, 52L, 55L, 58L, 54L, 54L, 59L, 49L, 60L, 62L, 57L, 59L, 57L, \n61L, 58L, 53L, 56L, 52L, 53L, 55L, 54L, 53L, 49L, 48L, 59L, 55L, \n61L, 59L, 50L, 55L, 58L, 63L, 53L, 56L, 55L, 54L), y3 = c(42L, \n42L, 46L, 39L, 39L, 37L, 38L, 43L, 36L, 37L, 40L, 45L, 46L, 39L, \n39L, 36L, 38L, 43L, 44L, 42L, 37L, 38L, 41L, 40L, 40L, 48L, 41L, \n37L, 42L, 32L, 38L, 43L, 38L, 41L, 45L, 39L, 40L, 41L, 49L, 40L, \n39L, 40L, 41L, 39L, 41L, 43L, 43L, 37L, 38L, 42L, 44L, 36L, 39L, \n44L, 41L, 38L, 40L, 49L, 41L, 39L, 46L, 45L, 40L, 50L, 45L, 43L, \n40L, 42L, 44L, 34L, 42L, 39L, 46L, 39L, 39L, 42L, 41L, 36L, 42L, \n46L, 39L, 39L, 37L, 36L, 42L, 32L, 37L, 43L, 42L, 42L, 46L, 47L, \n42L, 47L, 39L, 36L, 38L, 43L, 38L, 40L, 47L, 42L, 43L, 42L, 44L, \n42L, 45L, 41L, 39L, 45L, 42L, 41L, 46L, 44L, 43L, 38L, 42L, 44L, \n36L, 37L, 45L, 45L, 37L, 41L, 38L, 42L, 42L, 40L, 35L, 46L, 40L, \n42L, 48L, 42L, 42L, 44L, 44L, 48L, 38L, 43L, 42L, 40L, 48L, 39L, \n40L, 32L, 46L, 34L, 45L, 43L, 42L, 38L, 42L, 35L, 46L, 38L, 42L, \n39L, 43L, 43L, 50L, 41L, 42L, 43L, 44L, 35L, 44L, 42L, 41L, 47L, \n48L, 40L, 46L, 44L, 51L, 43L, 39L, 47L, 51L, 37L, 42L, 38L, 37L, \n38L, 43L, 40L, 36L, 40L, 46L, 43L, 50L, 42L, 42L, 40L, 43L, 46L, \n43L, 40L, 42L, 41L), y4 = c(29L, 31L, 34L, 36L, 26L, 30L, 34L, \n38L, 37L, 31L, 37L, 30L, 38L, 26L, 36L, 27L, 30L, 39L, 37L, 35L, \n39L, 33L, 35L, 32L, 34L, 40L, 32L, 31L, 38L, 38L, 34L, 42L, 30L, \n32L, 27L, 33L, 32L, 35L, 40L, 27L, 31L, 35L, 32L, 37L, 38L, 31L, \n29L, 28L, 33L, 35L, 31L, 22L, 34L, 37L, 27L, 33L, 35L, 47L, 30L, \n39L, 38L, 40L, 29L, 43L, 34L, 34L, 32L, 41L, 34L, 33L, 34L, 34L, \n32L, 32L, 30L, 34L, 32L, 38L, 25L, 35L, 34L, 24L, 34L, 33L, 26L, \n31L, 30L, 35L, 37L, 35L, 35L, 40L, 34L, 33L, 28L, 35L, 36L, 35L, \n40L, 34L, 39L, 33L, 28L, 34L, 31L, 29L, 39L, 40L, 35L, 37L, 36L, \n34L, 38L, 33L, 32L, 26L, 33L, 36L, 30L, 25L, 33L, 35L, 35L, 38L, \n36L, 39L, 32L, 34L, 35L, 34L, 36L, 28L, 35L, 30L, 31L, 38L, 35L, \n40L, 31L, 40L, 37L, 32L, 42L, 35L, 34L, 34L, 35L, 23L, 35L, 41L, \n39L, 37L, 34L, 26L, 35L, 34L, 35L, 33L, 31L, 40L, 38L, 32L, 29L, \n37L, 39L, 34L, 35L, 35L, 28L, 40L, 37L, 35L, 40L, 35L, 42L, 40L, \n42L, 37L, 39L, 32L, 38L, 31L, 34L, 39L, 38L, 35L, 32L, 33L, 39L, \n36L, 43L, 36L, 30L, 36L, 42L, 35L, 32L, 32L, 33L, 35L)), class = \"data.frame\", row.names = c(NA, \n-200L))\n\n\n\nhead(df)\n\n## x - Coping Strategy (a - No strategy; b - Discussion; c - Exercise)\n## y1, y2, y3, y4 - Multiple dependent variables (life-satisfaction scores)",
    "crumbs": [
      "SEMs with lavaan",
      "Means",
      "One-Way LATENT"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Green_2023/index.html",
    "href": "SEMs_with_lavaan/Green_2023/index.html",
    "title": "Means",
    "section": "",
    "text": "Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\nThompson, Liu & Green (TLG) show an ordinary least squares (OLS) regression approach and a structural equation modeling (SEM) approach to:\n\nOne-way ANOVA\nOne-way ANCOVA\nTwo-way ANOVA\nOne-way MANOVA\nOne-way ANOVA of a latent variable\n\nThese examples show the SEM approaches only.",
    "crumbs": [
      "SEMs with lavaan",
      "Means"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Green_2023/one_way_MANOVA.html",
    "href": "SEMs_with_lavaan/Green_2023/one_way_MANOVA.html",
    "title": "One-Way MANOVA",
    "section": "",
    "text": "Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\nThis example shows the SEM approach to a one-way MANOVA. Results are reported in Table 21.5 (p. 399).\nThe data are described on pages 397 and 398.\n\nLoad package and get the data\nLoad the lavaan package, and run satisfactionII.r to get the data (satisfactionII.r is available at the end of this post).\n\nlibrary(lavaan)\n\nsource(\"satisfactionII.r\")\nhead(df)\n\nThe variables used in this example are:\n\nx - Coping Strategy (“a” - no strategy; “b” - discussion; “c” - exercise)\ny1, y2, y3, y4 - Multiple dependent variables (Life-Satisfaction scores)\n\n\n\nThe models\nThe SEM model for the one-way MANOVA is shown in Fig 21.2 (p. 400), and is reproduced below. The diagram shows the “Less Constrained” model. The means are represented by the labels on the arrows connecting the “1” to the dependent variables. The means for each variable are allowed to differ across the groups. The residual variances and covariances are constrained to equality.\n\n\n\n\n\nThe model statements are shown below. The “More Constrained” model constrains the means to equality. The “Less Constrained” model allows the means to differ across the groups. In both cases the residual variances and covariances are constrained to equality. The variancs and covariances can be set up separately - see vcov below. Then, vcov is added back into each model. Saves a little typing.\n\n# Variances and covariances (for both models)\nvcov &lt;-\n   \"y1 ~~ c(e1, e1, e1)*y1\n    y2 ~~ c(e2, e2, e2)*y2\n    y3 ~~ c(e3, e3, e3)*y3\n    y4 ~~ c(e4, e4, e4)*y4\n\n    y1 ~~ c(e12, e12, e12)*y2\n    y1 ~~ c(e13, e13, e13)*y3\n    y1 ~~ c(e14, e14, e14)*y4\n    y2 ~~ c(e23, e23, e23)*y3\n    y2 ~~ c(e24, e24, e24)*y4\n    y3 ~~ c(e34, e34, e34)*y4\"\n\nmodels &lt;- list(\n  \"More Constrained\" = c(\n    # Means\n    \"y1 ~ c(a1, a1, a1)*1\n     y2 ~ c(a2, a2, a2)*1\n     y3 ~ c(a3, a3, a3)*1\n     y4 ~ c(a4, a4, a4)*1\",\n     vcov),\n\n  \"Less Constrained\" =  c(\n    # Means\n    \"y1 ~ c(a1, b1, c1)*1\n     y2 ~ c(a2, b2, c2)*1\n     y3 ~ c(a3, b3, c3)*1\n     y4 ~ c(a4, b4, c4)*1\",\n     vcov)\n)\n\n\n\nFit the models and get the results\n\n# Fit the models \nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n# Get model summaries\nlapply(fit, summary)\n\n# Contrast model fits\nReduce(anova, fit)\n\nThe “SEM” section of Table 21.5 shows the \\(\\upchi\\)2 test.\nScroll through the summaries to find the “Intercepts”, or extract them from the list of estimates of model parameter.\n\n## Get list of estimates\nestimates &lt;- lapply(fit, lavInspect, \"est\"); estimates\n\n## Extract means - in element \"nu\"\nmeans &lt;- list()\nfor (i in names(models)) {\n   means[[i]] = estimates[[i]] |&gt;\n      sapply(\"[[\", \"nu\") |&gt;\n      round(2)\n   row.names(means[[i]]) = c(\"Y1\", \"Y2\", \"Y3\", \"Y4\")\n}\nmeans\n\nCompare with the means in Table 21.5.\nBy way of completeness, get the error SSCP matrices. (TLG state that, “the error SSCP matrices were perfectly reproduced by multiplying the variances and covariances in the SEM output by the total sample size” p. 398).\n\n# Note: In the list of estimates, co/variances are in element \"theta\"\nE &lt;- estimates |&gt;\n  lapply(\"[[\", \"a\") |&gt;           # Extract estimates for group \"a\"\n  lapply(\"[[\", \"theta\") |&gt;       # Extract \"theta\" element\n  lapply(matrix, nrow = 4) |&gt;    # Get the full matrix\n  lapply(\"*\", 200)               # Multiply by sample size\nE\n\n\n\nRelax homogeneity of variances and covariances assumption\nTowards the end of the section headed “Avoiding OLS assumptions for ANOVA/MANOVA designs using SEM” (pp. 398-401), TGL present the results for models in which the assumptions of homogeneity and normality are relaxed. That is, variances and covariances are not constrained to equality, and a robust ML method of estimation (MLM) is employed. Again, the variances and covariances are set up separately, then added back into each model. This time, there are no labels for the variances and covariances, meaning that lavaan will estimate each variance and covariance for each group.\n\n## Model statements\n# Variances and covariances (for both models)\nvcov &lt;- \n  \"y1 ~~ y1 + y2 + y3 + y4\n   y2 ~~ y2 + y3 + y4\n   y3 ~~ y3 + y4\n   y4 ~~ y4\" \n\nmodels &lt;- list(\n  \"Less Constrained\" =  c(\n    # Means\n    \"y1 ~ c(a1, b1, c1)*1\n     y2 ~ c(a2, b2, c2)*1\n     y3 ~ c(a3, b3, c3)*1\n     y4 ~ c(a4, b4, c4)*1\",\n     vcov),\n\n  \"More Constrained\" = c(\n    # Means\n    \"y1 ~ c(a1, a1, a1)*1\n     y2 ~ c(a2, a2, a2)*1\n     y3 ~ c(a3, a3, a3)*1\n     y4 ~ c(a4, a4, a4)*1\",\n     vcov)\n)\n\n## Fit the models\nfit &lt;- lapply(models, sem, data = df, estimator = \"mlm\", group = \"x\")\n\n## Get model summaries\nlapply(fit, summary)\n\n## Contrast model fits\nReduce(anova, fit)\n\nCompare with the \\(\\upchi\\)2 test on page 401.\n\n\n\nR code with minimal commenting\n## One-way MANOVA\n##\n## Thompson, M., Lie, Y. & Green, S. (2023). Flexible structural equation modeling\n## approaches for analyzing means. In R. Hoyle (Ed.), Handbook of structural\n## equation modeling (2nd ed., pp. 385-408). New York, NY: Guilford Press.\n\n## Load package\nlibrary(lavaan)\n\n## Get the data\nsource(\"satisfactionII.r\")\nhead(df)\n\n## The models\n# Variances and covariances (for both models)\nvcov &lt;-\n   \"y1 ~~ c(e1, e1, e1)*y1\n    y2 ~~ c(e2, e2, e2)*y2\n    y3 ~~ c(e3, e3, e3)*y3\n    y4 ~~ c(e4, e4, e4)*y4\n\n    y1 ~~ c(e12, e12, e12)*y2\n    y1 ~~ c(e13, e13, e13)*y3\n    y1 ~~ c(e14, e14, e14)*y4\n    y2 ~~ c(e23, e23, e23)*y3\n    y2 ~~ c(e24, e24, e24)*y4\n    y3 ~~ c(e34, e34, e34)*y4\"\n\nmodels &lt;- list(\n  \"More Constrained\" = c(\n    # Means\n    \"y1 ~ c(a1, a1, a1)*1\n     y2 ~ c(a2, a2, a2)*1\n     y3 ~ c(a3, a3, a3)*1\n     y4 ~ c(a4, a4, a4)*1\",\n     vcov),\n\n  \"Less Constrained\" =  c(\n    # Means\n    \"y1 ~ c(a1, b1, c1)*1\n     y2 ~ c(a2, b2, c2)*1\n     y3 ~ c(a3, b3, c3)*1\n     y4 ~ c(a4, b4, c4)*1\",\n     vcov)\n)\n\n## Fit the models and get the results\n## Check means and chi square test in Table 21.5\n# Fit the models\nfit &lt;- lapply(models, sem, data = df, group = \"x\")\n\n# Get model summaries\nlapply(fit, summary)\n\n# Contrast model fits\nReduce(anova, fit)\n\n## Extract means from list of estimates\n## Get list of estimates\nestimates &lt;- lapply(fit, lavInspect, \"est\"); estimates\n\n## Extract means - in element \"nu\"\nmeans &lt;- list()\nfor (i in names(models)) {\n   means[[i]] = estimates[[i]] |&gt;\n      sapply(\"[[\", \"nu\") |&gt;\n      round(2)\n   row.names(means[[i]]) = c(\"Y1\", \"Y2\", \"Y3\", \"Y4\")\n}\nmeans\n\n## Get the error SSCP matrices by hand\n# Note: In the list of estimates, co/variances are in element \"theta\"\nE &lt;- estimates |&gt;\n  lapply(\"[[\", \"a\") |&gt;           # Extract estimates for group \"a\"\n  lapply(\"[[\", \"theta\") |&gt;       # Extract \"theta\" element\n  lapply(matrix, nrow = 4) |&gt;    # Get the full matrix\n  lapply(\"*\", 200)               # Multiply by sample size\nE\n\n## Relax homogeneity of variances and covariances assumption\n## Check chi square on page 401\n## Model statements\n# Variances and covariances (for both models)\nvcov &lt;-\n  \"y1 ~~ y1 + y2 + y3 + y4\n   y2 ~~ y2 + y3 + y4\n   y3 ~~ y3 + y4\n   y4 ~~ y4\"\n\nmodels &lt;- list(\n  \"Less Constrained\" =  c(\n    # Means\n    \"y1 ~ c(a1, b1, c1)*1\n     y2 ~ c(a2, b2, c2)*1\n     y3 ~ c(a3, b3, c3)*1\n     y4 ~ c(a4, b4, c4)*1\",\n     vcov),\n\n  \"More Constrained\" = c(\n    # Means\n    \"y1 ~ c(a1, a1, a1)*1\n     y2 ~ c(a2, a2, a2)*1\n     y3 ~ c(a3, a3, a3)*1\n     y4 ~ c(a4, a4, a4)*1\",\n     vcov)\n)\n\n## Fit the models\nfit &lt;- lapply(models, sem, data = df, estimator = \"mlm\", group = \"x\")\n\n## Get model summaries\nlapply(fit, summary)\n\n## Contrast model fits\nReduce(anova, fit)\n\n\n\n\nR code to get data file - satisfactionII.r\n### Data for Tables 21.5 and 21.6 ###\n\ndf &lt;- structure(list(x = c(\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \n\"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \n\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\"), x1 = c(1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L), x2 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L), x3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), y1 = c(18L, 24L, \n21L, 24L, 19L, 22L, 23L, 32L, 24L, 22L, 24L, 23L, 28L, 22L, 22L, \n23L, 19L, 28L, 25L, 25L, 27L, 21L, 33L, 24L, 23L, 28L, 29L, 24L, \n28L, 24L, 26L, 28L, 21L, 26L, 20L, 24L, 22L, 32L, 31L, 22L, 22L, \n27L, 22L, 26L, 24L, 24L, 25L, 27L, 26L, 24L, 22L, 18L, 25L, 27L, \n29L, 24L, 22L, 32L, 23L, 27L, 28L, 24L, 18L, 32L, 27L, 25L, 24L, \n25L, 29L, 21L, 29L, 25L, 25L, 25L, 19L, 32L, 29L, 22L, 18L, 26L, \n23L, 26L, 21L, 18L, 24L, 24L, 17L, 24L, 33L, 21L, 23L, 27L, 26L, \n28L, 20L, 27L, 25L, 25L, 25L, 18L, 27L, 25L, 22L, 23L, 26L, 23L, \n29L, 26L, 24L, 27L, 22L, 24L, 26L, 31L, 27L, 22L, 22L, 26L, 25L, \n21L, 26L, 25L, 24L, 26L, 28L, 27L, 26L, 26L, 19L, 22L, 25L, 26L, \n30L, 22L, 26L, 25L, 27L, 32L, 22L, 27L, 26L, 30L, 32L, 28L, 25L, \n23L, 21L, 14L, 26L, 28L, 29L, 25L, 27L, 25L, 26L, 21L, 23L, 25L, \n26L, 30L, 30L, 26L, 22L, 31L, 28L, 26L, 29L, 25L, 26L, 24L, 28L, \n22L, 35L, 26L, 34L, 29L, 26L, 27L, 32L, 16L, 26L, 22L, 25L, 30L, \n28L, 25L, 22L, 23L, 28L, 23L, 36L, 27L, 24L, 23L, 34L, 31L, 33L, \n26L, 27L, 22L), y2 = c(49L, 50L, 51L, 53L, 44L, 50L, 52L, 55L, \n53L, 48L, 48L, 51L, 57L, 51L, 48L, 51L, 48L, 53L, 59L, 55L, 51L, \n54L, 63L, 49L, 54L, 54L, 52L, 47L, 50L, 49L, 54L, 57L, 51L, 53L, \n49L, 53L, 53L, 57L, 58L, 49L, 53L, 55L, 59L, 57L, 55L, 53L, 55L, \n54L, 47L, 54L, 48L, 47L, 50L, 59L, 52L, 52L, 52L, 60L, 59L, 50L, \n55L, 59L, 55L, 59L, 61L, 48L, 55L, 55L, 60L, 50L, 62L, 54L, 56L, \n61L, 52L, 55L, 51L, 56L, 52L, 56L, 53L, 49L, 59L, 51L, 57L, 55L, \n48L, 54L, 56L, 53L, 47L, 54L, 52L, 54L, 50L, 54L, 52L, 54L, 59L, \n54L, 61L, 54L, 54L, 50L, 56L, 51L, 59L, 50L, 52L, 55L, 57L, 57L, \n62L, 55L, 53L, 51L, 50L, 60L, 51L, 52L, 52L, 56L, 52L, 55L, 56L, \n51L, 64L, 54L, 47L, 51L, 54L, 55L, 55L, 55L, 54L, 55L, 58L, 57L, \n56L, 60L, 55L, 54L, 61L, 55L, 50L, 53L, 60L, 49L, 58L, 61L, 55L, \n51L, 58L, 53L, 55L, 49L, 55L, 53L, 56L, 53L, 55L, 53L, 48L, 59L, \n56L, 52L, 55L, 58L, 54L, 54L, 59L, 49L, 60L, 62L, 57L, 59L, 57L, \n61L, 58L, 53L, 56L, 52L, 53L, 55L, 54L, 53L, 49L, 48L, 59L, 55L, \n61L, 59L, 50L, 55L, 58L, 63L, 53L, 56L, 55L, 54L), y3 = c(42L, \n42L, 46L, 39L, 39L, 37L, 38L, 43L, 36L, 37L, 40L, 45L, 46L, 39L, \n39L, 36L, 38L, 43L, 44L, 42L, 37L, 38L, 41L, 40L, 40L, 48L, 41L, \n37L, 42L, 32L, 38L, 43L, 38L, 41L, 45L, 39L, 40L, 41L, 49L, 40L, \n39L, 40L, 41L, 39L, 41L, 43L, 43L, 37L, 38L, 42L, 44L, 36L, 39L, \n44L, 41L, 38L, 40L, 49L, 41L, 39L, 46L, 45L, 40L, 50L, 45L, 43L, \n40L, 42L, 44L, 34L, 42L, 39L, 46L, 39L, 39L, 42L, 41L, 36L, 42L, \n46L, 39L, 39L, 37L, 36L, 42L, 32L, 37L, 43L, 42L, 42L, 46L, 47L, \n42L, 47L, 39L, 36L, 38L, 43L, 38L, 40L, 47L, 42L, 43L, 42L, 44L, \n42L, 45L, 41L, 39L, 45L, 42L, 41L, 46L, 44L, 43L, 38L, 42L, 44L, \n36L, 37L, 45L, 45L, 37L, 41L, 38L, 42L, 42L, 40L, 35L, 46L, 40L, \n42L, 48L, 42L, 42L, 44L, 44L, 48L, 38L, 43L, 42L, 40L, 48L, 39L, \n40L, 32L, 46L, 34L, 45L, 43L, 42L, 38L, 42L, 35L, 46L, 38L, 42L, \n39L, 43L, 43L, 50L, 41L, 42L, 43L, 44L, 35L, 44L, 42L, 41L, 47L, \n48L, 40L, 46L, 44L, 51L, 43L, 39L, 47L, 51L, 37L, 42L, 38L, 37L, \n38L, 43L, 40L, 36L, 40L, 46L, 43L, 50L, 42L, 42L, 40L, 43L, 46L, \n43L, 40L, 42L, 41L), y4 = c(29L, 31L, 34L, 36L, 26L, 30L, 34L, \n38L, 37L, 31L, 37L, 30L, 38L, 26L, 36L, 27L, 30L, 39L, 37L, 35L, \n39L, 33L, 35L, 32L, 34L, 40L, 32L, 31L, 38L, 38L, 34L, 42L, 30L, \n32L, 27L, 33L, 32L, 35L, 40L, 27L, 31L, 35L, 32L, 37L, 38L, 31L, \n29L, 28L, 33L, 35L, 31L, 22L, 34L, 37L, 27L, 33L, 35L, 47L, 30L, \n39L, 38L, 40L, 29L, 43L, 34L, 34L, 32L, 41L, 34L, 33L, 34L, 34L, \n32L, 32L, 30L, 34L, 32L, 38L, 25L, 35L, 34L, 24L, 34L, 33L, 26L, \n31L, 30L, 35L, 37L, 35L, 35L, 40L, 34L, 33L, 28L, 35L, 36L, 35L, \n40L, 34L, 39L, 33L, 28L, 34L, 31L, 29L, 39L, 40L, 35L, 37L, 36L, \n34L, 38L, 33L, 32L, 26L, 33L, 36L, 30L, 25L, 33L, 35L, 35L, 38L, \n36L, 39L, 32L, 34L, 35L, 34L, 36L, 28L, 35L, 30L, 31L, 38L, 35L, \n40L, 31L, 40L, 37L, 32L, 42L, 35L, 34L, 34L, 35L, 23L, 35L, 41L, \n39L, 37L, 34L, 26L, 35L, 34L, 35L, 33L, 31L, 40L, 38L, 32L, 29L, \n37L, 39L, 34L, 35L, 35L, 28L, 40L, 37L, 35L, 40L, 35L, 42L, 40L, \n42L, 37L, 39L, 32L, 38L, 31L, 34L, 39L, 38L, 35L, 32L, 33L, 39L, \n36L, 43L, 36L, 30L, 36L, 42L, 35L, 32L, 32L, 33L, 35L)), class = \"data.frame\", row.names = c(NA, \n-200L))\n\n\n\nhead(df)\n\n## x - Coping Strategy (a - No strategy; b - Discussion; c - Exercise)\n## y1, y2, y3, y4 - Multiple dependent variables (life-satisfaction scores)",
    "crumbs": [
      "SEMs with lavaan",
      "Means",
      "One-Way MANOVA"
    ]
  },
  {
    "objectID": "SEMs_with_lavaan/Jose_2013/Jose_2013.html",
    "href": "SEMs_with_lavaan/Jose_2013/Jose_2013.html",
    "title": "Mediation",
    "section": "",
    "text": "Jose, P. (2013). Doing statistical mediation and moderation. New York, NY: Guilford Press.\nThis example shows how to obtain a basic three-variable mediation analysis using lavaan, including how to obtain indirect and total effects. In Chapter 3 (Basic Mediation, pp. 43-92), Jose describes a basic mediation model involving three variables: Positive Life Events; Happiness; and Gratitude. Positive Life Events has a direct effect on Happiness, but also Positive Life Events has an indirect effect on Happiness via Gratitude.\n\nLoad relevant packages\nLoad the lavaan and haven packages.\n\nlibrary(lavaan)\nlibrary(haven)   # To read SPSS data files\n\n\n\nGet the data\nThe data are available at the Guilford Press site (note: the url on page 48 is no longer a valid link). The data are contained in an SPSS data file. I use the haven package to read SPSS data files. Examine the file structure, in particular, noting the variable names. These will be needed by lavaan.\n\nurl &lt;- \"http://www.guilford.com/add/jose/mediation_example.sav\"\ndataset &lt;- data.frame(haven::read_spss(url))\n\nstr(dataset)\nhead(dataset)\nsummary(dataset)\n\nThe names for the three variables are:\n\nple - Positive Life Events\ngrat - Gratitude\nshs - Happiness\n\n\n\nThe model\nThe model is given in Figure 3.3 (p. 46), reproduced below.\n\n\n\n\n\nIn lavaan, mediation effects can be estimated using the := operator. In the diagram, the effects are labelled a, b, and c\\('\\); in the model statement, they are labelled a, b, and cpr. The labels can then be used to obtain the indirect and total effects.\n\nmodel &lt;- \"\n  # direct effect\n  shs ~ cpr * ple\n\n  # effects via the mediator\n  grat ~ a * ple\n  shs ~ b * grat\n\n  # indirect effect (a*b)\n  indirect := a * b\n\n  # total effect\n  total := cpr + (a * b) \n\"\n\n\n\nFit the model and get the results\nI’ve requested unstandardised and standardised effects, and R2 values. For the standardised effects, see the “std.all” column in the output.\n\nfit &lt;- sem(model, data = dataset)\nsummary(fit, rsquare = TRUE, standardized = TRUE)   # Check with Tables 3.2-3.5\n\nJose conducts mediation analysis using regressions. The results are presented in Tables 3.2 to 3.5 (pp. 49-52). The unstandardised and standardised coefficients in the tables agree with the lavaan output.\nThe regression summary tables show the constants (that is, the intercepts). If intercepts are required, include meanstructure = TRUE in the sem() function.\n\nfit_intercepts &lt;- sem(model, data = dataset, meanstructure = TRUE)\nsummary(fit_intercepts, rsquare = TRUE, standardized = TRUE)\n\nOn pages 53 and 54, Jose shows how to calculate and test the statistical significance of Sobel’s z-value (that is, testing the significance of the indirect effect). Do not rely on that test. Also, do not rely of the t-test for the indirect effect given in the lavaan output. It is better to calculate confidence intervals, although the symmetric confidence interval presented in Table 3.7 (p. 55) is no better than the test for Sobel’s z-value. The asymmetric CI presented in Table 3.8 (p. 56) is possibly better. In lavaan, bootstrap CIs can be calculated.\n\nfit_boot &lt;- sem(model, data = dataset, se = \"bootstrap\", bootstrap = 2000)\nsummary(fit_boot, standardized = TRUE, ci = TRUE)\nparameterEstimates(fit_boot, boot.ci.type = \"perc\")\n\n\n\n\nR code with minimal commenting\n## Chapter 3 (Basic Mediation, pp. 43-92) in:\n##   Jose, P. (2013). Doing statistical mediation and moderation.\n##   New York, NY: Guilford Press.\n\n## Load packages\nlibrary(lavaan)\nlibrary(haven)   # To read SPSS data files\n\n## Get the data from Guilford Press web site\nurl &lt;- \"http://www.guilford.com/add/jose/mediation_example.sav\"\ndataset &lt;- data.frame(haven::read_spss(url))\n\nstr(dataset)\nhead(dataset)\nsummary(dataset)\n\n## The model\nmodel &lt;- \"\n  # direct effect\n  shs ~ cpr * ple\n\n  # effects via the mediator\n  grat ~ a * ple\n  shs ~ b * grat\n\n  # indirect effect (a*b)\n  indirect := a * b\n\n  # total effect\n  total := cpr + (a * b)\n\"\n\n## Fit the model and get the summary\nfit &lt;- sem(model, data = dataset)\nsummary(fit, rsquare = TRUE, standardized = TRUE)   # Check with Tables 3.2-3.5\n\n## To get intercepts\nfit_intercepts &lt;- sem(model, data = dataset, meanstructure = TRUE)\nsummary(fit_intercepts, rsquare = TRUE, standardized = TRUE)\n\n## To get bootstrap CIs\nfit_boot &lt;- sem(model, data = dataset, se = \"bootstrap\", bootstrap = 2000)\nsummary(fit_boot, standardized = TRUE, ci = TRUE)\nparameterEstimates(fit_boot, boot.ci.type = \"perc\")",
    "crumbs": [
      "SEMs with lavaan",
      "Mediation I"
    ]
  },
  {
    "objectID": "Drawing_SEMs/index.html",
    "href": "Drawing_SEMs/index.html",
    "title": "",
    "section": "",
    "text": "Drawing Structural Equation Models with TikZ\n\n\n\n\n\n\n\nThis post presents TikZ scripts to draw diagrams of Structural Equation Models.",
    "crumbs": [
      "Drawing SEMs"
    ]
  }
]